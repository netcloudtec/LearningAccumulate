<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="zh">
<head>
<!-- Generated by javadoc (1.8.0_144) on Mon Sep 17 17:47:54 CST 2018 -->
<title>HadoopWriteConfigUtil (Spark 2.3.1 JavaDoc)</title>
<meta name="date" content="2018-09-17">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="HadoopWriteConfigUtil (Spark 2.3.1 JavaDoc)";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":6,"i1":6,"i2":6,"i3":6,"i4":6,"i5":6,"i6":6,"i7":6};
var tabs = {65535:["t0","所有方法"],2:["t2","实例方法"],4:["t3","抽象方法"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>您的浏览器已禁用 JavaScript。</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="跳过导航链接">跳过导航链接</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="导航">
<li><a href="../../../../../overview-summary.html">概览</a></li>
<li><a href="package-summary.html">程序包</a></li>
<li class="navBarCell1Rev">类</li>
<li><a href="package-tree.html">树</a></li>
<li><a href="../../../../../deprecated-list.html">已过时</a></li>
<li><a href="../../../../../index-all.html">索引</a></li>
<li><a href="../../../../../help-doc.html">帮助</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.html" title="org.apache.spark.internal.io中的类"><span class="typeNameLink">上一个类</span></a></li>
<li><a href="../../../../../org/apache/spark/internal/io/SparkHadoopWriter.html" title="org.apache.spark.internal.io中的类"><span class="typeNameLink">下一个类</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/internal/io/HadoopWriteConfigUtil.html" target="_top">框架</a></li>
<li><a href="HadoopWriteConfigUtil.html" target="_top">无框架</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../allclasses-noframe.html">所有类</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>概要:&nbsp;</li>
<li>嵌套&nbsp;|&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">构造器</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">方法</a></li>
</ul>
<ul class="subNavList">
<li>详细资料:&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">构造器</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">方法</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.internal.io</div>
<h2 title="类 HadoopWriteConfigUtil" class="title">类 HadoopWriteConfigUtil&lt;K,V&gt;</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.internal.io.HadoopWriteConfigUtil&lt;K,V&gt;</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>所有已实现的接口:</dt>
<dd>java.io.Serializable</dd>
</dl>
<hr>
<br>
<pre>public abstract class <span class="typeNameLabel">HadoopWriteConfigUtil&lt;K,V&gt;</span>
extends Object
implements scala.Serializable</pre>
<div class="block">Interface for create output format/committer/writer used during saving an RDD using a Hadoop
 OutputFormat (both from the old mapred API and the new mapreduce API)
 <p>
 Notes:
 1. Implementations should throw <code>IllegalArgumentException</code> when wrong hadoop API is
    referenced;
 2. Implementations must be serializable, as the instance instantiated on the driver
    will be used for tasks on executors;
 3. Implementations should have a constructor with exactly one argument:
    (conf: SerializableConfiguration) or (conf: SerializableJobConf).</div>
<dl>
<dt><span class="seeLabel">另请参阅:</span></dt>
<dd><a href="../../../../../serialized-form.html#org.apache.spark.internal.io.HadoopWriteConfigUtil">序列化表格</a></dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.summary">
<!--   -->
</a>
<h3>构造器概要</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="构造器概要表, 列表构造器和解释">
<caption><span>构造器</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">构造器和说明</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopWriteConfigUtil.html#HadoopWriteConfigUtil-scala.reflect.ClassTag-">HadoopWriteConfigUtil</a></span>(scala.reflect.ClassTag&lt;<a href="../../../../../org/apache/spark/internal/io/HadoopWriteConfigUtil.html" title="HadoopWriteConfigUtil中的类型参数">V</a>&gt;&nbsp;evidence$1)</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>方法概要</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="方法概要表, 列表方法和解释">
<caption><span id="t0" class="activeTableTab"><span>所有方法</span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">实例方法</a></span><span class="tabEnd">&nbsp;</span></span><span id="t3" class="tableTab"><span><a href="javascript:show(4);">抽象方法</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">限定符和类型</th>
<th class="colLast" scope="col">方法和说明</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>abstract void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopWriteConfigUtil.html#assertConf-org.apache.hadoop.mapreduce.JobContext-org.apache.spark.SparkConf-">assertConf</a></span>(org.apache.hadoop.mapreduce.JobContext&nbsp;jobContext,
          <a href="../../../../../org/apache/spark/SparkConf.html" title="org.apache.spark中的类">SparkConf</a>&nbsp;conf)</code>&nbsp;</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>abstract void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopWriteConfigUtil.html#closeWriter-org.apache.hadoop.mapreduce.TaskAttemptContext-">closeWriter</a></span>(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext)</code>&nbsp;</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>abstract <a href="../../../../../org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.html" title="org.apache.spark.internal.io中的类">HadoopMapReduceCommitProtocol</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopWriteConfigUtil.html#createCommitter-int-">createCommitter</a></span>(int&nbsp;jobId)</code>&nbsp;</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>abstract org.apache.hadoop.mapreduce.JobContext</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopWriteConfigUtil.html#createJobContext-java.lang.String-int-">createJobContext</a></span>(String&nbsp;jobTrackerId,
                int&nbsp;jobId)</code>&nbsp;</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>abstract org.apache.hadoop.mapreduce.TaskAttemptContext</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopWriteConfigUtil.html#createTaskAttemptContext-java.lang.String-int-int-int-">createTaskAttemptContext</a></span>(String&nbsp;jobTrackerId,
                        int&nbsp;jobId,
                        int&nbsp;splitId,
                        int&nbsp;taskAttemptId)</code>&nbsp;</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>abstract void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopWriteConfigUtil.html#initOutputFormat-org.apache.hadoop.mapreduce.JobContext-">initOutputFormat</a></span>(org.apache.hadoop.mapreduce.JobContext&nbsp;jobContext)</code>&nbsp;</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>abstract void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopWriteConfigUtil.html#initWriter-org.apache.hadoop.mapreduce.TaskAttemptContext-int-">initWriter</a></span>(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext,
          int&nbsp;splitId)</code>&nbsp;</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>abstract void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopWriteConfigUtil.html#write-scala.Tuple2-">write</a></span>(scala.Tuple2&lt;<a href="../../../../../org/apache/spark/internal/io/HadoopWriteConfigUtil.html" title="HadoopWriteConfigUtil中的类型参数">K</a>,<a href="../../../../../org/apache/spark/internal/io/HadoopWriteConfigUtil.html" title="HadoopWriteConfigUtil中的类型参数">V</a>&gt;&nbsp;pair)</code>&nbsp;</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.Object">
<!--   -->
</a>
<h3>从类继承的方法&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.detail">
<!--   -->
</a>
<h3>构造器详细资料</h3>
<a name="HadoopWriteConfigUtil-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>HadoopWriteConfigUtil</h4>
<pre>public&nbsp;HadoopWriteConfigUtil(scala.reflect.ClassTag&lt;<a href="../../../../../org/apache/spark/internal/io/HadoopWriteConfigUtil.html" title="HadoopWriteConfigUtil中的类型参数">V</a>&gt;&nbsp;evidence$1)</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>方法详细资料</h3>
<a name="createJobContext-java.lang.String-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createJobContext</h4>
<pre>public abstract&nbsp;org.apache.hadoop.mapreduce.JobContext&nbsp;createJobContext(String&nbsp;jobTrackerId,
                                                                        int&nbsp;jobId)</pre>
</li>
</ul>
<a name="createTaskAttemptContext-java.lang.String-int-int-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createTaskAttemptContext</h4>
<pre>public abstract&nbsp;org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;createTaskAttemptContext(String&nbsp;jobTrackerId,
                                                                                        int&nbsp;jobId,
                                                                                        int&nbsp;splitId,
                                                                                        int&nbsp;taskAttemptId)</pre>
</li>
</ul>
<a name="createCommitter-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createCommitter</h4>
<pre>public abstract&nbsp;<a href="../../../../../org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.html" title="org.apache.spark.internal.io中的类">HadoopMapReduceCommitProtocol</a>&nbsp;createCommitter(int&nbsp;jobId)</pre>
</li>
</ul>
<a name="initWriter-org.apache.hadoop.mapreduce.TaskAttemptContext-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initWriter</h4>
<pre>public abstract&nbsp;void&nbsp;initWriter(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext,
                                int&nbsp;splitId)</pre>
</li>
</ul>
<a name="write-scala.Tuple2-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>write</h4>
<pre>public abstract&nbsp;void&nbsp;write(scala.Tuple2&lt;<a href="../../../../../org/apache/spark/internal/io/HadoopWriteConfigUtil.html" title="HadoopWriteConfigUtil中的类型参数">K</a>,<a href="../../../../../org/apache/spark/internal/io/HadoopWriteConfigUtil.html" title="HadoopWriteConfigUtil中的类型参数">V</a>&gt;&nbsp;pair)</pre>
</li>
</ul>
<a name="closeWriter-org.apache.hadoop.mapreduce.TaskAttemptContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>closeWriter</h4>
<pre>public abstract&nbsp;void&nbsp;closeWriter(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext)</pre>
</li>
</ul>
<a name="initOutputFormat-org.apache.hadoop.mapreduce.JobContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initOutputFormat</h4>
<pre>public abstract&nbsp;void&nbsp;initOutputFormat(org.apache.hadoop.mapreduce.JobContext&nbsp;jobContext)</pre>
</li>
</ul>
<a name="assertConf-org.apache.hadoop.mapreduce.JobContext-org.apache.spark.SparkConf-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>assertConf</h4>
<pre>public abstract&nbsp;void&nbsp;assertConf(org.apache.hadoop.mapreduce.JobContext&nbsp;jobContext,
                                <a href="../../../../../org/apache/spark/SparkConf.html" title="org.apache.spark中的类">SparkConf</a>&nbsp;conf)</pre>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="跳过导航链接">跳过导航链接</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="导航">
<li><a href="../../../../../overview-summary.html">概览</a></li>
<li><a href="package-summary.html">程序包</a></li>
<li class="navBarCell1Rev">类</li>
<li><a href="package-tree.html">树</a></li>
<li><a href="../../../../../deprecated-list.html">已过时</a></li>
<li><a href="../../../../../index-all.html">索引</a></li>
<li><a href="../../../../../help-doc.html">帮助</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.html" title="org.apache.spark.internal.io中的类"><span class="typeNameLink">上一个类</span></a></li>
<li><a href="../../../../../org/apache/spark/internal/io/SparkHadoopWriter.html" title="org.apache.spark.internal.io中的类"><span class="typeNameLink">下一个类</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/internal/io/HadoopWriteConfigUtil.html" target="_top">框架</a></li>
<li><a href="HadoopWriteConfigUtil.html" target="_top">无框架</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../allclasses-noframe.html">所有类</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>概要:&nbsp;</li>
<li>嵌套&nbsp;|&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">构造器</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">方法</a></li>
</ul>
<ul class="subNavList">
<li>详细资料:&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">构造器</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">方法</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../../lib/api-javadocs.js"></script></body>
</html>
