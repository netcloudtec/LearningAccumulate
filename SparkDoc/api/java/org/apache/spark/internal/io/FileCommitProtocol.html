<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="zh">
<head>
<!-- Generated by javadoc (1.8.0_144) on Mon Sep 17 17:47:54 CST 2018 -->
<title>FileCommitProtocol (Spark 2.3.1 JavaDoc)</title>
<meta name="date" content="2018-09-17">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="FileCommitProtocol (Spark 2.3.1 JavaDoc)";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":6,"i1":6,"i2":6,"i3":6,"i4":10,"i5":9,"i6":6,"i7":6,"i8":10,"i9":6,"i10":6};
var tabs = {65535:["t0","所有方法"],1:["t1","静态方法"],2:["t2","实例方法"],4:["t3","抽象方法"],8:["t4","具体方法"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>您的浏览器已禁用 JavaScript。</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="跳过导航链接">跳过导航链接</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="导航">
<li><a href="../../../../../overview-summary.html">概览</a></li>
<li><a href="package-summary.html">程序包</a></li>
<li class="navBarCell1Rev">类</li>
<li><a href="package-tree.html">树</a></li>
<li><a href="../../../../../deprecated-list.html">已过时</a></li>
<li><a href="../../../../../index-all.html">索引</a></li>
<li><a href="../../../../../help-doc.html">帮助</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>上一个类</li>
<li><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.EmptyTaskCommitMessage$.html" title="org.apache.spark.internal.io中的类"><span class="typeNameLink">下一个类</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/internal/io/FileCommitProtocol.html" target="_top">框架</a></li>
<li><a href="FileCommitProtocol.html" target="_top">无框架</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../allclasses-noframe.html">所有类</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>概要:&nbsp;</li>
<li><a href="#nested.class.summary">嵌套</a>&nbsp;|&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">构造器</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">方法</a></li>
</ul>
<ul class="subNavList">
<li>详细资料:&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">构造器</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">方法</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.internal.io</div>
<h2 title="类 FileCommitProtocol" class="title">类 FileCommitProtocol</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.internal.io.FileCommitProtocol</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>直接已知子类:</dt>
<dd><a href="../../../../../org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.html" title="org.apache.spark.internal.io中的类">HadoopMapReduceCommitProtocol</a></dd>
</dl>
<hr>
<br>
<pre>public abstract class <span class="typeNameLabel">FileCommitProtocol</span>
extends Object</pre>
<div class="block">An interface to define how a single Spark job commits its outputs. Three notes:
 <p>
 1. Implementations must be serializable, as the committer instance instantiated on the driver
    will be used for tasks on executors.
 2. Implementations should have a constructor with 2 or 3 arguments:
      (jobId: String, path: String) or
      (jobId: String, path: String, dynamicPartitionOverwrite: Boolean)
 3. A committer should not be reused across multiple Spark jobs.
 <p>
 The proper call sequence is:
 <p>
 1. Driver calls setupJob.
 2. As part of each task's execution, executor calls setupTask and then commitTask
    (or abortTask if task failed).
 3. When all necessary tasks completed successfully, the driver calls commitJob. If the job
    failed to execute (e.g. too many failed tasks), the job should call abortJob.</div>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested.class.summary">
<!--   -->
</a>
<h3>嵌套类概要</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="嵌套类概要表, 列表嵌套类和解释">
<caption><span>嵌套类</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">限定符和类型</th>
<th class="colLast" scope="col">类和说明</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.EmptyTaskCommitMessage$.html" title="org.apache.spark.internal.io中的类">FileCommitProtocol.EmptyTaskCommitMessage$</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.TaskCommitMessage.html" title="org.apache.spark.internal.io中的类">FileCommitProtocol.TaskCommitMessage</a></span></code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.summary">
<!--   -->
</a>
<h3>构造器概要</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="构造器概要表, 列表构造器和解释">
<caption><span>构造器</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">构造器和说明</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#FileCommitProtocol--">FileCommitProtocol</a></span>()</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>方法概要</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="方法概要表, 列表方法和解释">
<caption><span id="t0" class="activeTableTab"><span>所有方法</span><span class="tabEnd">&nbsp;</span></span><span id="t1" class="tableTab"><span><a href="javascript:show(1);">静态方法</a></span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">实例方法</a></span><span class="tabEnd">&nbsp;</span></span><span id="t3" class="tableTab"><span><a href="javascript:show(4);">抽象方法</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">具体方法</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">限定符和类型</th>
<th class="colLast" scope="col">方法和说明</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>abstract void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#abortJob-org.apache.hadoop.mapreduce.JobContext-">abortJob</a></span>(org.apache.hadoop.mapreduce.JobContext&nbsp;jobContext)</code>
<div class="block">Aborts a job after the writes fail.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>abstract void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#abortTask-org.apache.hadoop.mapreduce.TaskAttemptContext-">abortTask</a></span>(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext)</code>
<div class="block">Aborts a task after the writes have failed.</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>abstract void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#commitJob-org.apache.hadoop.mapreduce.JobContext-scala.collection.Seq-">commitJob</a></span>(org.apache.hadoop.mapreduce.JobContext&nbsp;jobContext,
         scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.TaskCommitMessage.html" title="org.apache.spark.internal.io中的类">FileCommitProtocol.TaskCommitMessage</a>&gt;&nbsp;taskCommits)</code>
<div class="block">Commits a job after the writes succeed.</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>abstract <a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.TaskCommitMessage.html" title="org.apache.spark.internal.io中的类">FileCommitProtocol.TaskCommitMessage</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#commitTask-org.apache.hadoop.mapreduce.TaskAttemptContext-">commitTask</a></span>(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext)</code>
<div class="block">Commits a task after the writes succeed.</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#deleteWithJob-org.apache.hadoop.fs.FileSystem-org.apache.hadoop.fs.Path-boolean-">deleteWithJob</a></span>(org.apache.hadoop.fs.FileSystem&nbsp;fs,
             org.apache.hadoop.fs.Path&nbsp;path,
             boolean&nbsp;recursive)</code>
<div class="block">Specifies that a file should be deleted with the commit of this job.</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html" title="org.apache.spark.internal.io中的类">FileCommitProtocol</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#instantiate-java.lang.String-java.lang.String-java.lang.String-boolean-">instantiate</a></span>(String&nbsp;className,
           String&nbsp;jobId,
           String&nbsp;outputPath,
           boolean&nbsp;dynamicPartitionOverwrite)</code>
<div class="block">Instantiates a FileCommitProtocol using the given className.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>abstract String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#newTaskTempFile-org.apache.hadoop.mapreduce.TaskAttemptContext-scala.Option-java.lang.String-">newTaskTempFile</a></span>(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext,
               scala.Option&lt;String&gt;&nbsp;dir,
               String&nbsp;ext)</code>
<div class="block">Notifies the commit protocol to add a new file, and gets back the full path that should be
 used.</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>abstract String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#newTaskTempFileAbsPath-org.apache.hadoop.mapreduce.TaskAttemptContext-java.lang.String-java.lang.String-">newTaskTempFileAbsPath</a></span>(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext,
                      String&nbsp;absoluteDir,
                      String&nbsp;ext)</code>
<div class="block">Similar to newTaskTempFile(), but allows files to committed to an absolute output location.</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#onTaskCommit-org.apache.spark.internal.io.FileCommitProtocol.TaskCommitMessage-">onTaskCommit</a></span>(<a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.TaskCommitMessage.html" title="org.apache.spark.internal.io中的类">FileCommitProtocol.TaskCommitMessage</a>&nbsp;taskCommit)</code>
<div class="block">Called on the driver after a task commits.</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code>abstract void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#setupJob-org.apache.hadoop.mapreduce.JobContext-">setupJob</a></span>(org.apache.hadoop.mapreduce.JobContext&nbsp;jobContext)</code>
<div class="block">Setups up a job.</div>
</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code>abstract void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#setupTask-org.apache.hadoop.mapreduce.TaskAttemptContext-">setupTask</a></span>(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext)</code>
<div class="block">Sets up a task within a job.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.Object">
<!--   -->
</a>
<h3>从类继承的方法&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.detail">
<!--   -->
</a>
<h3>构造器详细资料</h3>
<a name="FileCommitProtocol--">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>FileCommitProtocol</h4>
<pre>public&nbsp;FileCommitProtocol()</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>方法详细资料</h3>
<a name="instantiate-java.lang.String-java.lang.String-java.lang.String-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>instantiate</h4>
<pre>public static&nbsp;<a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html" title="org.apache.spark.internal.io中的类">FileCommitProtocol</a>&nbsp;instantiate(String&nbsp;className,
                                             String&nbsp;jobId,
                                             String&nbsp;outputPath,
                                             boolean&nbsp;dynamicPartitionOverwrite)</pre>
<div class="block">Instantiates a FileCommitProtocol using the given className.</div>
<dl>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>className</code> - (undocumented)</dd>
<dd><code>jobId</code> - (undocumented)</dd>
<dd><code>outputPath</code> - (undocumented)</dd>
<dd><code>dynamicPartitionOverwrite</code> - (undocumented)</dd>
<dt><span class="returnLabel">返回:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="setupJob-org.apache.hadoop.mapreduce.JobContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setupJob</h4>
<pre>public abstract&nbsp;void&nbsp;setupJob(org.apache.hadoop.mapreduce.JobContext&nbsp;jobContext)</pre>
<div class="block">Setups up a job. Must be called on the driver before any other methods can be invoked.</div>
<dl>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>jobContext</code> - (undocumented)</dd>
</dl>
</li>
</ul>
<a name="commitJob-org.apache.hadoop.mapreduce.JobContext-scala.collection.Seq-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>commitJob</h4>
<pre>public abstract&nbsp;void&nbsp;commitJob(org.apache.hadoop.mapreduce.JobContext&nbsp;jobContext,
                               scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.TaskCommitMessage.html" title="org.apache.spark.internal.io中的类">FileCommitProtocol.TaskCommitMessage</a>&gt;&nbsp;taskCommits)</pre>
<div class="block">Commits a job after the writes succeed. Must be called on the driver.</div>
<dl>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>jobContext</code> - (undocumented)</dd>
<dd><code>taskCommits</code> - (undocumented)</dd>
</dl>
</li>
</ul>
<a name="abortJob-org.apache.hadoop.mapreduce.JobContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>abortJob</h4>
<pre>public abstract&nbsp;void&nbsp;abortJob(org.apache.hadoop.mapreduce.JobContext&nbsp;jobContext)</pre>
<div class="block">Aborts a job after the writes fail. Must be called on the driver.
 <p>
 Calling this function is a best-effort attempt, because it is possible that the driver
 just crashes (or killed) before it can call abort.</div>
<dl>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>jobContext</code> - (undocumented)</dd>
</dl>
</li>
</ul>
<a name="setupTask-org.apache.hadoop.mapreduce.TaskAttemptContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setupTask</h4>
<pre>public abstract&nbsp;void&nbsp;setupTask(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext)</pre>
<div class="block">Sets up a task within a job.
 Must be called before any other task related methods can be invoked.</div>
<dl>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>taskContext</code> - (undocumented)</dd>
</dl>
</li>
</ul>
<a name="newTaskTempFile-org.apache.hadoop.mapreduce.TaskAttemptContext-scala.Option-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>newTaskTempFile</h4>
<pre>public abstract&nbsp;String&nbsp;newTaskTempFile(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext,
                                       scala.Option&lt;String&gt;&nbsp;dir,
                                       String&nbsp;ext)</pre>
<div class="block">Notifies the commit protocol to add a new file, and gets back the full path that should be
 used. Must be called on the executors when running tasks.
 <p>
 Note that the returned temp file may have an arbitrary path. The commit protocol only
 promises that the file will be at the location specified by the arguments after job commit.
 <p>
 A full file path consists of the following parts:
  1. the base path
  2. some sub-directory within the base path, used to specify partitioning
  3. file prefix, usually some unique job id with the task id
  4. bucket id
  5. source specific file extension, e.g. ".snappy.parquet"
 <p>
 The "dir" parameter specifies 2, and "ext" parameter specifies both 4 and 5, and the rest
 are left to the commit protocol implementation to decide.
 <p>
 Important: it is the caller's responsibility to add uniquely identifying content to "ext"
 if a task is going to write out multiple files to the same dir. The file commit protocol only
 guarantees that files written by different tasks will not conflict.</div>
<dl>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>taskContext</code> - (undocumented)</dd>
<dd><code>dir</code> - (undocumented)</dd>
<dd><code>ext</code> - (undocumented)</dd>
<dt><span class="returnLabel">返回:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="newTaskTempFileAbsPath-org.apache.hadoop.mapreduce.TaskAttemptContext-java.lang.String-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>newTaskTempFileAbsPath</h4>
<pre>public abstract&nbsp;String&nbsp;newTaskTempFileAbsPath(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext,
                                              String&nbsp;absoluteDir,
                                              String&nbsp;ext)</pre>
<div class="block">Similar to newTaskTempFile(), but allows files to committed to an absolute output location.
 Depending on the implementation, there may be weaker guarantees around adding files this way.
 <p>
 Important: it is the caller's responsibility to add uniquely identifying content to "ext"
 if a task is going to write out multiple files to the same dir. The file commit protocol only
 guarantees that files written by different tasks will not conflict.</div>
<dl>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>taskContext</code> - (undocumented)</dd>
<dd><code>absoluteDir</code> - (undocumented)</dd>
<dd><code>ext</code> - (undocumented)</dd>
<dt><span class="returnLabel">返回:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="commitTask-org.apache.hadoop.mapreduce.TaskAttemptContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>commitTask</h4>
<pre>public abstract&nbsp;<a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.TaskCommitMessage.html" title="org.apache.spark.internal.io中的类">FileCommitProtocol.TaskCommitMessage</a>&nbsp;commitTask(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext)</pre>
<div class="block">Commits a task after the writes succeed. Must be called on the executors when running tasks.</div>
<dl>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>taskContext</code> - (undocumented)</dd>
<dt><span class="returnLabel">返回:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="abortTask-org.apache.hadoop.mapreduce.TaskAttemptContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>abortTask</h4>
<pre>public abstract&nbsp;void&nbsp;abortTask(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext)</pre>
<div class="block">Aborts a task after the writes have failed. Must be called on the executors when running tasks.
 <p>
 Calling this function is a best-effort attempt, because it is possible that the executor
 just crashes (or killed) before it can call abort.</div>
<dl>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>taskContext</code> - (undocumented)</dd>
</dl>
</li>
</ul>
<a name="deleteWithJob-org.apache.hadoop.fs.FileSystem-org.apache.hadoop.fs.Path-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>deleteWithJob</h4>
<pre>public&nbsp;boolean&nbsp;deleteWithJob(org.apache.hadoop.fs.FileSystem&nbsp;fs,
                             org.apache.hadoop.fs.Path&nbsp;path,
                             boolean&nbsp;recursive)</pre>
<div class="block">Specifies that a file should be deleted with the commit of this job. The default
 implementation deletes the file immediately.</div>
<dl>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>fs</code> - (undocumented)</dd>
<dd><code>path</code> - (undocumented)</dd>
<dd><code>recursive</code> - (undocumented)</dd>
<dt><span class="returnLabel">返回:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="onTaskCommit-org.apache.spark.internal.io.FileCommitProtocol.TaskCommitMessage-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>onTaskCommit</h4>
<pre>public&nbsp;void&nbsp;onTaskCommit(<a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.TaskCommitMessage.html" title="org.apache.spark.internal.io中的类">FileCommitProtocol.TaskCommitMessage</a>&nbsp;taskCommit)</pre>
<div class="block">Called on the driver after a task commits. This can be used to access task commit messages
 before the job has finished. These same task commit messages will be passed to commitJob()
 if the entire job succeeds.</div>
<dl>
<dt><span class="paramLabel">参数:</span></dt>
<dd><code>taskCommit</code> - (undocumented)</dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="跳过导航链接">跳过导航链接</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="导航">
<li><a href="../../../../../overview-summary.html">概览</a></li>
<li><a href="package-summary.html">程序包</a></li>
<li class="navBarCell1Rev">类</li>
<li><a href="package-tree.html">树</a></li>
<li><a href="../../../../../deprecated-list.html">已过时</a></li>
<li><a href="../../../../../index-all.html">索引</a></li>
<li><a href="../../../../../help-doc.html">帮助</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>上一个类</li>
<li><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.EmptyTaskCommitMessage$.html" title="org.apache.spark.internal.io中的类"><span class="typeNameLink">下一个类</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/internal/io/FileCommitProtocol.html" target="_top">框架</a></li>
<li><a href="FileCommitProtocol.html" target="_top">无框架</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../allclasses-noframe.html">所有类</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>概要:&nbsp;</li>
<li><a href="#nested.class.summary">嵌套</a>&nbsp;|&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">构造器</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">方法</a></li>
</ul>
<ul class="subNavList">
<li>详细资料:&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">构造器</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">方法</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../../lib/api-javadocs.js"></script></body>
</html>
