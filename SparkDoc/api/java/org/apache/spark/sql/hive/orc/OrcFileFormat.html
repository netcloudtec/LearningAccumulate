<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="zh">
<head>
<!-- Generated by javadoc (1.8.0_144) on Mon Sep 17 17:47:58 CST 2018 -->
<title>OrcFileFormat (Spark 2.3.1 JavaDoc)</title>
<meta name="date" content="2018-09-17">
<link rel="stylesheet" type="text/css" href="../../../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="OrcFileFormat (Spark 2.3.1 JavaDoc)";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":10,"i1":9,"i2":9,"i3":10,"i4":10,"i5":10,"i6":9,"i7":10,"i8":9,"i9":10,"i10":9,"i11":9};
var tabs = {65535:["t0","所有方法"],1:["t1","静态方法"],2:["t2","实例方法"],8:["t4","具体方法"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>您的浏览器已禁用 JavaScript。</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="跳过导航链接">跳过导航链接</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="导航">
<li><a href="../../../../../../overview-summary.html">概览</a></li>
<li><a href="package-summary.html">程序包</a></li>
<li class="navBarCell1Rev">类</li>
<li><a href="package-tree.html">树</a></li>
<li><a href="../../../../../../deprecated-list.html">已过时</a></li>
<li><a href="../../../../../../index-all.html">索引</a></li>
<li><a href="../../../../../../help-doc.html">帮助</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>上一个类</li>
<li><a href="../../../../../../org/apache/spark/sql/hive/orc/OrcFileOperator.html" title="org.apache.spark.sql.hive.orc中的类"><span class="typeNameLink">下一个类</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../../index.html?org/apache/spark/sql/hive/orc/OrcFileFormat.html" target="_top">框架</a></li>
<li><a href="OrcFileFormat.html" target="_top">无框架</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../../allclasses-noframe.html">所有类</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>概要:&nbsp;</li>
<li>嵌套&nbsp;|&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">构造器</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">方法</a></li>
</ul>
<ul class="subNavList">
<li>详细资料:&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">构造器</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">方法</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql.hive.orc</div>
<h2 title="类 OrcFileFormat" class="title">类 OrcFileFormat</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.hive.orc.OrcFileFormat</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>所有已实现的接口:</dt>
<dd>java.io.Serializable, org.apache.spark.sql.execution.datasources.FileFormat, <a href="../../../../../../org/apache/spark/sql/sources/DataSourceRegister.html" title="org.apache.spark.sql.sources中的接口">DataSourceRegister</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="typeNameLabel">OrcFileFormat</span>
extends Object
implements org.apache.spark.sql.execution.datasources.FileFormat, <a href="../../../../../../org/apache/spark/sql/sources/DataSourceRegister.html" title="org.apache.spark.sql.sources中的接口">DataSourceRegister</a>, scala.Serializable</pre>
<div class="block"><code>FileFormat</code> for reading ORC files. If this is moved or renamed, please update
 <code>DataSource</code>'s backwardCompatibilityMap.</div>
<dl>
<dt><span class="seeLabel">另请参阅:</span></dt>
<dd><a href="../../../../../../serialized-form.html#org.apache.spark.sql.hive.orc.OrcFileFormat">序列化表格</a></dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.summary">
<!--   -->
</a>
<h3>构造器概要</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="构造器概要表, 列表构造器和解释">
<caption><span>构造器</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">构造器和说明</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/orc/OrcFileFormat.html#OrcFileFormat--">OrcFileFormat</a></span>()</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>方法概要</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="方法概要表, 列表方法和解释">
<caption><span id="t0" class="activeTableTab"><span>所有方法</span><span class="tabEnd">&nbsp;</span></span><span id="t1" class="tableTab"><span><a href="javascript:show(1);">静态方法</a></span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">实例方法</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">具体方法</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">限定符和类型</th>
<th class="colLast" scope="col">方法和说明</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>scala.Function1&lt;org.apache.spark.sql.execution.datasources.PartitionedFile,scala.collection.Iterator&lt;org.apache.spark.sql.catalyst.InternalRow&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/orc/OrcFileFormat.html#buildReader-org.apache.spark.sql.SparkSession-org.apache.spark.sql.types.StructType-org.apache.spark.sql.types.StructType-org.apache.spark.sql.types.StructType-scala.collection.Seq-scala.collection.immutable.Map-org.apache.hadoop.conf.Configuration-">buildReader</a></span>(<a href="../../../../../../org/apache/spark/sql/SparkSession.html" title="org.apache.spark.sql中的类">SparkSession</a>&nbsp;sparkSession,
           <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;dataSchema,
           <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;partitionSchema,
           <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;requiredSchema,
           scala.collection.Seq&lt;<a href="../../../../../../org/apache/spark/sql/sources/Filter.html" title="org.apache.spark.sql.sources中的类">Filter</a>&gt;&nbsp;filters,
           scala.collection.immutable.Map&lt;String,String&gt;&nbsp;options,
           org.apache.hadoop.conf.Configuration&nbsp;hadoopConf)</code>&nbsp;</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>static scala.Function1&lt;org.apache.spark.sql.execution.datasources.PartitionedFile,scala.collection.Iterator&lt;org.apache.spark.sql.catalyst.InternalRow&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/orc/OrcFileFormat.html#buildReaderWithPartitionValues-org.apache.spark.sql.SparkSession-org.apache.spark.sql.types.StructType-org.apache.spark.sql.types.StructType-org.apache.spark.sql.types.StructType-scala.collection.Seq-scala.collection.immutable.Map-org.apache.hadoop.conf.Configuration-">buildReaderWithPartitionValues</a></span>(<a href="../../../../../../org/apache/spark/sql/SparkSession.html" title="org.apache.spark.sql中的类">SparkSession</a>&nbsp;sparkSession,
                              <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;dataSchema,
                              <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;partitionSchema,
                              <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;requiredSchema,
                              scala.collection.Seq&lt;<a href="../../../../../../org/apache/spark/sql/sources/Filter.html" title="org.apache.spark.sql.sources中的类">Filter</a>&gt;&nbsp;filters,
                              scala.collection.immutable.Map&lt;String,String&gt;&nbsp;options,
                              org.apache.hadoop.conf.Configuration&nbsp;hadoopConf)</code>&nbsp;</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>static scala.collection.immutable.Map&lt;String,String&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/orc/OrcFileFormat.html#extensionsForCompressionCodecNames--">extensionsForCompressionCodecNames</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>scala.Option&lt;<a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/orc/OrcFileFormat.html#inferSchema-org.apache.spark.sql.SparkSession-scala.collection.immutable.Map-scala.collection.Seq-">inferSchema</a></span>(<a href="../../../../../../org/apache/spark/sql/SparkSession.html" title="org.apache.spark.sql中的类">SparkSession</a>&nbsp;sparkSession,
           scala.collection.immutable.Map&lt;String,String&gt;&nbsp;options,
           scala.collection.Seq&lt;org.apache.hadoop.fs.FileStatus&gt;&nbsp;files)</code>&nbsp;</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/orc/OrcFileFormat.html#isSplitable-org.apache.spark.sql.SparkSession-scala.collection.immutable.Map-org.apache.hadoop.fs.Path-">isSplitable</a></span>(<a href="../../../../../../org/apache/spark/sql/SparkSession.html" title="org.apache.spark.sql中的类">SparkSession</a>&nbsp;sparkSession,
           scala.collection.immutable.Map&lt;String,String&gt;&nbsp;options,
           org.apache.hadoop.fs.Path&nbsp;path)</code>&nbsp;</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>org.apache.spark.sql.execution.datasources.OutputWriterFactory</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/orc/OrcFileFormat.html#prepareWrite-org.apache.spark.sql.SparkSession-org.apache.hadoop.mapreduce.Job-scala.collection.immutable.Map-org.apache.spark.sql.types.StructType-">prepareWrite</a></span>(<a href="../../../../../../org/apache/spark/sql/SparkSession.html" title="org.apache.spark.sql中的类">SparkSession</a>&nbsp;sparkSession,
            org.apache.hadoop.mapreduce.Job&nbsp;job,
            scala.collection.immutable.Map&lt;String,String&gt;&nbsp;options,
            <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;dataSchema)</code>&nbsp;</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/orc/OrcFileFormat.html#setRequiredColumns-org.apache.hadoop.conf.Configuration-org.apache.spark.sql.types.StructType-org.apache.spark.sql.types.StructType-">setRequiredColumns</a></span>(org.apache.hadoop.conf.Configuration&nbsp;conf,
                  <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;dataSchema,
                  <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;requestedSchema)</code>&nbsp;</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/orc/OrcFileFormat.html#shortName--">shortName</a></span>()</code>
<div class="block">The string that represents the format that this data source provider uses.</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/orc/OrcFileFormat.html#supportBatch-org.apache.spark.sql.SparkSession-org.apache.spark.sql.types.StructType-">supportBatch</a></span>(<a href="../../../../../../org/apache/spark/sql/SparkSession.html" title="org.apache.spark.sql中的类">SparkSession</a>&nbsp;sparkSession,
            <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;dataSchema)</code>&nbsp;</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/orc/OrcFileFormat.html#toString--">toString</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code>static scala.collection.Iterator&lt;org.apache.spark.sql.catalyst.InternalRow&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/orc/OrcFileFormat.html#unwrapOrcStructs-org.apache.hadoop.conf.Configuration-org.apache.spark.sql.types.StructType-org.apache.spark.sql.types.StructType-scala.Option-scala.collection.Iterator-">unwrapOrcStructs</a></span>(org.apache.hadoop.conf.Configuration&nbsp;conf,
                <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;dataSchema,
                <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;requiredSchema,
                scala.Option&lt;org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector&gt;&nbsp;maybeStructOI,
                scala.collection.Iterator&lt;org.apache.hadoop.io.Writable&gt;&nbsp;iterator)</code>&nbsp;</td>
</tr>
<tr id="i11" class="rowColor">
<td class="colFirst"><code>static scala.Option&lt;scala.collection.Seq&lt;String&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/orc/OrcFileFormat.html#vectorTypes-org.apache.spark.sql.types.StructType-org.apache.spark.sql.types.StructType-org.apache.spark.sql.internal.SQLConf-">vectorTypes</a></span>(<a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;requiredSchema,
           <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;partitionSchema,
           org.apache.spark.sql.internal.SQLConf&nbsp;sqlConf)</code>&nbsp;</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.Object">
<!--   -->
</a>
<h3>从类继承的方法&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.org.apache.spark.sql.execution.datasources.FileFormat">
<!--   -->
</a>
<h3>从接口继承的方法&nbsp;org.apache.spark.sql.execution.datasources.FileFormat</h3>
<code>buildReaderWithPartitionValues, supportBatch, vectorTypes</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.detail">
<!--   -->
</a>
<h3>构造器详细资料</h3>
<a name="OrcFileFormat--">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>OrcFileFormat</h4>
<pre>public&nbsp;OrcFileFormat()</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>方法详细资料</h3>
<a name="extensionsForCompressionCodecNames--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>extensionsForCompressionCodecNames</h4>
<pre>public static&nbsp;scala.collection.immutable.Map&lt;String,String&gt;&nbsp;extensionsForCompressionCodecNames()</pre>
</li>
</ul>
<a name="unwrapOrcStructs-org.apache.hadoop.conf.Configuration-org.apache.spark.sql.types.StructType-org.apache.spark.sql.types.StructType-scala.Option-scala.collection.Iterator-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>unwrapOrcStructs</h4>
<pre>public static&nbsp;scala.collection.Iterator&lt;org.apache.spark.sql.catalyst.InternalRow&gt;&nbsp;unwrapOrcStructs(org.apache.hadoop.conf.Configuration&nbsp;conf,
                                                                                                    <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;dataSchema,
                                                                                                    <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;requiredSchema,
                                                                                                    scala.Option&lt;org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector&gt;&nbsp;maybeStructOI,
                                                                                                    scala.collection.Iterator&lt;org.apache.hadoop.io.Writable&gt;&nbsp;iterator)</pre>
</li>
</ul>
<a name="setRequiredColumns-org.apache.hadoop.conf.Configuration-org.apache.spark.sql.types.StructType-org.apache.spark.sql.types.StructType-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setRequiredColumns</h4>
<pre>public static&nbsp;void&nbsp;setRequiredColumns(org.apache.hadoop.conf.Configuration&nbsp;conf,
                                      <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;dataSchema,
                                      <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;requestedSchema)</pre>
</li>
</ul>
<a name="supportBatch-org.apache.spark.sql.SparkSession-org.apache.spark.sql.types.StructType-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>supportBatch</h4>
<pre>public static&nbsp;boolean&nbsp;supportBatch(<a href="../../../../../../org/apache/spark/sql/SparkSession.html" title="org.apache.spark.sql中的类">SparkSession</a>&nbsp;sparkSession,
                                   <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;dataSchema)</pre>
</li>
</ul>
<a name="vectorTypes-org.apache.spark.sql.types.StructType-org.apache.spark.sql.types.StructType-org.apache.spark.sql.internal.SQLConf-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>vectorTypes</h4>
<pre>public static&nbsp;scala.Option&lt;scala.collection.Seq&lt;String&gt;&gt;&nbsp;vectorTypes(<a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;requiredSchema,
                                                                     <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;partitionSchema,
                                                                     org.apache.spark.sql.internal.SQLConf&nbsp;sqlConf)</pre>
</li>
</ul>
<a name="buildReaderWithPartitionValues-org.apache.spark.sql.SparkSession-org.apache.spark.sql.types.StructType-org.apache.spark.sql.types.StructType-org.apache.spark.sql.types.StructType-scala.collection.Seq-scala.collection.immutable.Map-org.apache.hadoop.conf.Configuration-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>buildReaderWithPartitionValues</h4>
<pre>public static&nbsp;scala.Function1&lt;org.apache.spark.sql.execution.datasources.PartitionedFile,scala.collection.Iterator&lt;org.apache.spark.sql.catalyst.InternalRow&gt;&gt;&nbsp;buildReaderWithPartitionValues(<a href="../../../../../../org/apache/spark/sql/SparkSession.html" title="org.apache.spark.sql中的类">SparkSession</a>&nbsp;sparkSession,
                                                                                                                                                                                              <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;dataSchema,
                                                                                                                                                                                              <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;partitionSchema,
                                                                                                                                                                                              <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;requiredSchema,
                                                                                                                                                                                              scala.collection.Seq&lt;<a href="../../../../../../org/apache/spark/sql/sources/Filter.html" title="org.apache.spark.sql.sources中的类">Filter</a>&gt;&nbsp;filters,
                                                                                                                                                                                              scala.collection.immutable.Map&lt;String,String&gt;&nbsp;options,
                                                                                                                                                                                              org.apache.hadoop.conf.Configuration&nbsp;hadoopConf)</pre>
</li>
</ul>
<a name="shortName--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>shortName</h4>
<pre>public&nbsp;String&nbsp;shortName()</pre>
<div class="block"><span class="descfrmTypeLabel">从接口复制的说明:&nbsp;<code><a href="../../../../../../org/apache/spark/sql/sources/DataSourceRegister.html#shortName--">DataSourceRegister</a></code></span></div>
<div class="block">The string that represents the format that this data source provider uses. This is
 overridden by children to provide a nice alias for the data source. For example:
 <p>
 <pre><code>
   override def shortName(): String = "parquet"
 </code></pre>
 <p></div>
<dl>
<dt><span class="overrideSpecifyLabel">指定者:</span></dt>
<dd><code><a href="../../../../../../org/apache/spark/sql/sources/DataSourceRegister.html#shortName--">shortName</a></code>&nbsp;在接口中&nbsp;<code><a href="../../../../../../org/apache/spark/sql/sources/DataSourceRegister.html" title="org.apache.spark.sql.sources中的接口">DataSourceRegister</a></code></dd>
<dt><span class="returnLabel">返回:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="toString--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toString</h4>
<pre>public&nbsp;String&nbsp;toString()</pre>
<dl>
<dt><span class="overrideSpecifyLabel">覆盖:</span></dt>
<dd><code>toString</code>&nbsp;在类中&nbsp;<code>Object</code></dd>
</dl>
</li>
</ul>
<a name="inferSchema-org.apache.spark.sql.SparkSession-scala.collection.immutable.Map-scala.collection.Seq-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>inferSchema</h4>
<pre>public&nbsp;scala.Option&lt;<a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&gt;&nbsp;inferSchema(<a href="../../../../../../org/apache/spark/sql/SparkSession.html" title="org.apache.spark.sql中的类">SparkSession</a>&nbsp;sparkSession,
                                            scala.collection.immutable.Map&lt;String,String&gt;&nbsp;options,
                                            scala.collection.Seq&lt;org.apache.hadoop.fs.FileStatus&gt;&nbsp;files)</pre>
<dl>
<dt><span class="overrideSpecifyLabel">指定者:</span></dt>
<dd><code>inferSchema</code>&nbsp;在接口中&nbsp;<code>org.apache.spark.sql.execution.datasources.FileFormat</code></dd>
</dl>
</li>
</ul>
<a name="prepareWrite-org.apache.spark.sql.SparkSession-org.apache.hadoop.mapreduce.Job-scala.collection.immutable.Map-org.apache.spark.sql.types.StructType-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>prepareWrite</h4>
<pre>public&nbsp;org.apache.spark.sql.execution.datasources.OutputWriterFactory&nbsp;prepareWrite(<a href="../../../../../../org/apache/spark/sql/SparkSession.html" title="org.apache.spark.sql中的类">SparkSession</a>&nbsp;sparkSession,
                                                                                   org.apache.hadoop.mapreduce.Job&nbsp;job,
                                                                                   scala.collection.immutable.Map&lt;String,String&gt;&nbsp;options,
                                                                                   <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;dataSchema)</pre>
<dl>
<dt><span class="overrideSpecifyLabel">指定者:</span></dt>
<dd><code>prepareWrite</code>&nbsp;在接口中&nbsp;<code>org.apache.spark.sql.execution.datasources.FileFormat</code></dd>
</dl>
</li>
</ul>
<a name="isSplitable-org.apache.spark.sql.SparkSession-scala.collection.immutable.Map-org.apache.hadoop.fs.Path-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isSplitable</h4>
<pre>public&nbsp;boolean&nbsp;isSplitable(<a href="../../../../../../org/apache/spark/sql/SparkSession.html" title="org.apache.spark.sql中的类">SparkSession</a>&nbsp;sparkSession,
                           scala.collection.immutable.Map&lt;String,String&gt;&nbsp;options,
                           org.apache.hadoop.fs.Path&nbsp;path)</pre>
<dl>
<dt><span class="overrideSpecifyLabel">指定者:</span></dt>
<dd><code>isSplitable</code>&nbsp;在接口中&nbsp;<code>org.apache.spark.sql.execution.datasources.FileFormat</code></dd>
</dl>
</li>
</ul>
<a name="buildReader-org.apache.spark.sql.SparkSession-org.apache.spark.sql.types.StructType-org.apache.spark.sql.types.StructType-org.apache.spark.sql.types.StructType-scala.collection.Seq-scala.collection.immutable.Map-org.apache.hadoop.conf.Configuration-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>buildReader</h4>
<pre>public&nbsp;scala.Function1&lt;org.apache.spark.sql.execution.datasources.PartitionedFile,scala.collection.Iterator&lt;org.apache.spark.sql.catalyst.InternalRow&gt;&gt;&nbsp;buildReader(<a href="../../../../../../org/apache/spark/sql/SparkSession.html" title="org.apache.spark.sql中的类">SparkSession</a>&nbsp;sparkSession,
                                                                                                                                                                    <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;dataSchema,
                                                                                                                                                                    <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;partitionSchema,
                                                                                                                                                                    <a href="../../../../../../org/apache/spark/sql/types/StructType.html" title="org.apache.spark.sql.types中的类">StructType</a>&nbsp;requiredSchema,
                                                                                                                                                                    scala.collection.Seq&lt;<a href="../../../../../../org/apache/spark/sql/sources/Filter.html" title="org.apache.spark.sql.sources中的类">Filter</a>&gt;&nbsp;filters,
                                                                                                                                                                    scala.collection.immutable.Map&lt;String,String&gt;&nbsp;options,
                                                                                                                                                                    org.apache.hadoop.conf.Configuration&nbsp;hadoopConf)</pre>
<dl>
<dt><span class="overrideSpecifyLabel">指定者:</span></dt>
<dd><code>buildReader</code>&nbsp;在接口中&nbsp;<code>org.apache.spark.sql.execution.datasources.FileFormat</code></dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="跳过导航链接">跳过导航链接</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="导航">
<li><a href="../../../../../../overview-summary.html">概览</a></li>
<li><a href="package-summary.html">程序包</a></li>
<li class="navBarCell1Rev">类</li>
<li><a href="package-tree.html">树</a></li>
<li><a href="../../../../../../deprecated-list.html">已过时</a></li>
<li><a href="../../../../../../index-all.html">索引</a></li>
<li><a href="../../../../../../help-doc.html">帮助</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>上一个类</li>
<li><a href="../../../../../../org/apache/spark/sql/hive/orc/OrcFileOperator.html" title="org.apache.spark.sql.hive.orc中的类"><span class="typeNameLink">下一个类</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../../index.html?org/apache/spark/sql/hive/orc/OrcFileFormat.html" target="_top">框架</a></li>
<li><a href="OrcFileFormat.html" target="_top">无框架</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../../allclasses-noframe.html">所有类</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>概要:&nbsp;</li>
<li>嵌套&nbsp;|&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">构造器</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">方法</a></li>
</ul>
<ul class="subNavList">
<li>详细资料:&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">构造器</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">方法</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../../../lib/api-javadocs.js"></script></body>
</html>
