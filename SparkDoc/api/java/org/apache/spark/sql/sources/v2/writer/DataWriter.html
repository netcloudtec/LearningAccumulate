<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="zh">
<head>
<!-- Generated by javadoc (1.8.0_144) on Mon Sep 17 17:48:04 CST 2018 -->
<title>DataWriter (Spark 2.3.1 JavaDoc)</title>
<meta name="date" content="2018-09-17">
<link rel="stylesheet" type="text/css" href="../../../../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="DataWriter (Spark 2.3.1 JavaDoc)";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":6,"i1":6,"i2":6};
var tabs = {65535:["t0","所有方法"],2:["t2","实例方法"],4:["t3","抽象方法"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>您的浏览器已禁用 JavaScript。</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="跳过导航链接">跳过导航链接</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="导航">
<li><a href="../../../../../../../overview-summary.html">概览</a></li>
<li><a href="package-summary.html">程序包</a></li>
<li class="navBarCell1Rev">类</li>
<li><a href="package-tree.html">树</a></li>
<li><a href="../../../../../../../deprecated-list.html">已过时</a></li>
<li><a href="../../../../../../../index-all.html">索引</a></li>
<li><a href="../../../../../../../help-doc.html">帮助</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataSourceWriter.html" title="org.apache.spark.sql.sources.v2.writer中的接口"><span class="typeNameLink">上一个类</span></a></li>
<li><a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataWriterFactory.html" title="org.apache.spark.sql.sources.v2.writer中的接口"><span class="typeNameLink">下一个类</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../../../index.html?org/apache/spark/sql/sources/v2/writer/DataWriter.html" target="_top">框架</a></li>
<li><a href="DataWriter.html" target="_top">无框架</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../../../allclasses-noframe.html">所有类</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>概要:&nbsp;</li>
<li>嵌套&nbsp;|&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li>构造器&nbsp;|&nbsp;</li>
<li><a href="#method.summary">方法</a></li>
</ul>
<ul class="subNavList">
<li>详细资料:&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li>构造器&nbsp;|&nbsp;</li>
<li><a href="#method.detail">方法</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql.sources.v2.writer</div>
<h2 title="接口 DataWriter" class="title">接口 DataWriter&lt;T&gt;</h2>
</div>
<div class="contentContainer">
<div class="description">
<ul class="blockList">
<li class="blockList">
<hr>
<br>
<pre>@InterfaceStability.Evolving
public interface <span class="typeNameLabel">DataWriter&lt;T&gt;</span></pre>
<div class="block">A data writer returned by <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataWriterFactory.html#createDataWriter-int-int-"><code>DataWriterFactory.createDataWriter(int, int)</code></a> and is
 responsible for writing data for an input RDD partition.

 One Spark task has one exclusive data writer, so there is no thread-safe concern.

 <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataWriter.html#write-T-"><code>write(Object)</code></a> is called for each record in the input RDD partition. If one record fails
 the <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataWriter.html#write-T-"><code>write(Object)</code></a>, <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataWriter.html#abort--"><code>abort()</code></a> is called afterwards and the remaining records will
 not be processed. If all records are successfully written, <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataWriter.html#commit--"><code>commit()</code></a> is called.

 If this data writer succeeds(all records are successfully written and <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataWriter.html#commit--"><code>commit()</code></a>
 succeeds), a <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/WriterCommitMessage.html" title="org.apache.spark.sql.sources.v2.writer中的接口"><code>WriterCommitMessage</code></a> will be sent to the driver side and pass to
 <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataSourceWriter.html#commit-org.apache.spark.sql.sources.v2.writer.WriterCommitMessage:A-"><code>DataSourceWriter.commit(WriterCommitMessage[])</code></a> with commit messages from other data
 writers. If this data writer fails(one record fails to write or <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataWriter.html#commit--"><code>commit()</code></a> fails), an
 exception will be sent to the driver side, and Spark will retry this writing task for some times,
 each time <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataWriterFactory.html#createDataWriter-int-int-"><code>DataWriterFactory.createDataWriter(int, int)</code></a> gets a different `attemptNumber`,
 and finally call <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataSourceWriter.html#abort-org.apache.spark.sql.sources.v2.writer.WriterCommitMessage:A-"><code>DataSourceWriter.abort(WriterCommitMessage[])</code></a> if all retry fail.

 Besides the retry mechanism, Spark may launch speculative tasks if the existing writing task
 takes too long to finish. Different from retried tasks, which are launched one by one after the
 previous one fails, speculative tasks are running simultaneously. It's possible that one input
 RDD partition has multiple data writers with different `attemptNumber` running at the same time,
 and data sources should guarantee that these data writers don't conflict and can work together.
 Implementations can coordinate with driver during <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataWriter.html#commit--"><code>commit()</code></a> to make sure only one of
 these data writers can commit successfully. Or implementations can allow all of them to commit
 successfully, and have a way to revert committed data writers without the commit message, because
 Spark only accepts the commit message that arrives first and ignore others.

 Note that, Currently the type `T` can only be <a href="../../../../../../../org/apache/spark/sql/Row.html" title="org.apache.spark.sql中的接口"><code>Row</code></a> for normal data
 source writers, or <code>InternalRow</code> for data source writers
 that mix in <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/SupportsWriteInternalRow.html" title="org.apache.spark.sql.sources.v2.writer中的接口"><code>SupportsWriteInternalRow</code></a>.</div>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>方法概要</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="方法概要表, 列表方法和解释">
<caption><span id="t0" class="activeTableTab"><span>所有方法</span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">实例方法</a></span><span class="tabEnd">&nbsp;</span></span><span id="t3" class="tableTab"><span><a href="javascript:show(4);">抽象方法</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">限定符和类型</th>
<th class="colLast" scope="col">方法和说明</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataWriter.html#abort--">abort</a></span>()</code>
<div class="block">Aborts this writer if it is failed.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code><a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/WriterCommitMessage.html" title="org.apache.spark.sql.sources.v2.writer中的接口">WriterCommitMessage</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataWriter.html#commit--">commit</a></span>()</code>
<div class="block">Commits this writer after all records are written successfully, returns a commit message which
 will be sent back to driver side and passed to
 <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataSourceWriter.html#commit-org.apache.spark.sql.sources.v2.writer.WriterCommitMessage:A-"><code>DataSourceWriter.commit(WriterCommitMessage[])</code></a>.</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataWriter.html#write-T-">write</a></span>(<a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataWriter.html" title="DataWriter中的类型参数">T</a>&nbsp;record)</code>
<div class="block">Writes one record.</div>
</td>
</tr>
</table>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>方法详细资料</h3>
<a name="write-java.lang.Object-">
<!--   -->
</a><a name="write-T-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>write</h4>
<pre>void&nbsp;write(<a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataWriter.html" title="DataWriter中的类型参数">T</a>&nbsp;record)
    throws java.io.IOException</pre>
<div class="block">Writes one record.

 If this method fails (by throwing an exception), <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataWriter.html#abort--"><code>abort()</code></a> will be called and this
 data writer is considered to have been failed.</div>
<dl>
<dt><span class="throwsLabel">抛出:</span></dt>
<dd><code>java.io.IOException</code> - if failure happens during disk/network IO like writing files.</dd>
</dl>
</li>
</ul>
<a name="commit--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>commit</h4>
<pre><a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/WriterCommitMessage.html" title="org.apache.spark.sql.sources.v2.writer中的接口">WriterCommitMessage</a>&nbsp;commit()
                    throws java.io.IOException</pre>
<div class="block">Commits this writer after all records are written successfully, returns a commit message which
 will be sent back to driver side and passed to
 <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataSourceWriter.html#commit-org.apache.spark.sql.sources.v2.writer.WriterCommitMessage:A-"><code>DataSourceWriter.commit(WriterCommitMessage[])</code></a>.

 The written data should only be visible to data source readers after
 <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataSourceWriter.html#commit-org.apache.spark.sql.sources.v2.writer.WriterCommitMessage:A-"><code>DataSourceWriter.commit(WriterCommitMessage[])</code></a> succeeds, which means this method
 should still "hide" the written data and ask the <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataSourceWriter.html" title="org.apache.spark.sql.sources.v2.writer中的接口"><code>DataSourceWriter</code></a> at driver side to
 do the final commit via <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/WriterCommitMessage.html" title="org.apache.spark.sql.sources.v2.writer中的接口"><code>WriterCommitMessage</code></a>.

 If this method fails (by throwing an exception), <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataWriter.html#abort--"><code>abort()</code></a> will be called and this
 data writer is considered to have been failed.</div>
<dl>
<dt><span class="throwsLabel">抛出:</span></dt>
<dd><code>java.io.IOException</code> - if failure happens during disk/network IO like writing files.</dd>
</dl>
</li>
</ul>
<a name="abort--">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>abort</h4>
<pre>void&nbsp;abort()
    throws java.io.IOException</pre>
<div class="block">Aborts this writer if it is failed. Implementations should clean up the data for already
 written records.

 This method will only be called if there is one record failed to write, or <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataWriter.html#commit--"><code>commit()</code></a>
 failed.

 If this method fails(by throwing an exception), the underlying data source may have garbage
 that need to be cleaned by <a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataSourceWriter.html#abort-org.apache.spark.sql.sources.v2.writer.WriterCommitMessage:A-"><code>DataSourceWriter.abort(WriterCommitMessage[])</code></a> or manually,
 but these garbage should not be visible to data source readers.</div>
<dl>
<dt><span class="throwsLabel">抛出:</span></dt>
<dd><code>java.io.IOException</code> - if failure happens during disk/network IO like writing files.</dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="跳过导航链接">跳过导航链接</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="导航">
<li><a href="../../../../../../../overview-summary.html">概览</a></li>
<li><a href="package-summary.html">程序包</a></li>
<li class="navBarCell1Rev">类</li>
<li><a href="package-tree.html">树</a></li>
<li><a href="../../../../../../../deprecated-list.html">已过时</a></li>
<li><a href="../../../../../../../index-all.html">索引</a></li>
<li><a href="../../../../../../../help-doc.html">帮助</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataSourceWriter.html" title="org.apache.spark.sql.sources.v2.writer中的接口"><span class="typeNameLink">上一个类</span></a></li>
<li><a href="../../../../../../../org/apache/spark/sql/sources/v2/writer/DataWriterFactory.html" title="org.apache.spark.sql.sources.v2.writer中的接口"><span class="typeNameLink">下一个类</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../../../index.html?org/apache/spark/sql/sources/v2/writer/DataWriter.html" target="_top">框架</a></li>
<li><a href="DataWriter.html" target="_top">无框架</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../../../allclasses-noframe.html">所有类</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>概要:&nbsp;</li>
<li>嵌套&nbsp;|&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li>构造器&nbsp;|&nbsp;</li>
<li><a href="#method.summary">方法</a></li>
</ul>
<ul class="subNavList">
<li>详细资料:&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li>构造器&nbsp;|&nbsp;</li>
<li><a href="#method.detail">方法</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../../../../lib/api-javadocs.js"></script></body>
</html>
