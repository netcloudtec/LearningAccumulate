

<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Extracting, transforming and selecting features - Spark 2.4.0 Documentation</title>




    <link rel="stylesheet" href="css/bootstrap.min.css">
    <style>
        body {
            padding-top: 60px;
            padding-bottom: 40px;
        }
    </style>
    <meta name="viewport" content="width=device-width">
    <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
    <link rel="stylesheet" href="css/main.css">

    <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

    <link rel="stylesheet" href="css/pygments-default.css">


    <!-- Google analytics script -->
    <script type="text/javascript">
        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-32518208-2']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>


</head>
<body>
<!--[if lt IE 7]>
<p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
<![endif]-->

<!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

<div class="navbar navbar-fixed-top" id="topbar">
    <div class="navbar-inner">
        <div class="container">
            <div class="brand"><a href="index.html">
                <img src="img/spark-logo-hd.png" style="height:50px;"/></a><span class="version">2.4.0</span>
            </div>
            <ul class="nav">
                <!--TODO(andyk): Add class="active" attribute to li some how.-->
                <li><a href="index.html">Overview</a></li>

                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Programming Guides<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        <li><a href="quick-start.html">Quick Start</a></li>
                        <li><a href="rdd-programming-guide.html">RDDs, Accumulators, Broadcasts Vars</a></li>
                        <li><a href="sql-programming-guide.html">SQL, DataFrames, and Datasets</a></li>
                        <li><a href="structured-streaming-programming-guide.html">Structured Streaming</a></li>
                        <li><a href="streaming-programming-guide.html">Spark Streaming (DStreams)</a></li>
                        <li><a href="ml-guide.html">MLlib (Machine Learning)</a></li>
                        <li><a href="graphx-programming-guide.html">GraphX (Graph Processing)</a></li>
                        <li><a href="sparkr.html">SparkR (R on Spark)</a></li>
                    </ul>
                </li>

                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">API Docs<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        <li><a href="api/scala/index.html#org.apache.spark.package">Scala</a></li>
                        <li><a href="api/java/index.html">Java</a></li>
                        <li><a href="api/python/index.html">Python</a></li>
                        <li><a href="api/R/index.html">R</a></li>
                        <li><a href="api/sql/index.html">SQL, Built-in Functions</a></li>
                    </ul>
                </li>

                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Deploying<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        <li><a href="cluster-overview.html">Overview</a></li>
                        <li><a href="submitting-applications.html">Submitting Applications</a></li>
                        <li class="divider"></li>
                        <li><a href="spark-standalone.html">Spark Standalone</a></li>
                        <li><a href="running-on-mesos.html">Mesos</a></li>
                        <li><a href="running-on-yarn.html">YARN</a></li>
                        <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                    </ul>
                </li>

                <li class="dropdown">
                    <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">More<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        <li><a href="configuration.html">Configuration</a></li>
                        <li><a href="monitoring.html">Monitoring</a></li>
                        <li><a href="tuning.html">Tuning Guide</a></li>
                        <li><a href="job-scheduling.html">Job Scheduling</a></li>
                        <li><a href="security.html">Security</a></li>
                        <li><a href="hardware-provisioning.html">Hardware Provisioning</a></li>
                        <li class="divider"></li>
                        <li><a href="building-spark.html">Building Spark</a></li>
                        <li><a href="https://spark.apache.org/contributing.html">Contributing to Spark</a></li>
                        <li><a href="https://spark.apache.org/third-party-projects.html">Third Party Projects</a></li>
                    </ul>
                </li>
            </ul>
            <!--<p class="navbar-text pull-right"><span class="version-text">v2.4.0</span></p>-->
        </div>
    </div>
</div>

<div class="container-wrapper">

    <div class="left-menu-wrapper">
        <div class="left-menu">
            <h3><a href="ml-guide.html">机器学习库(MLlib) 指南</a></h3>

            <ul>

                <li>
                    <a href="ml-statistics.html">

                        基本统计

                    </a>
                </li>



                <li>
                    <a href="ml-datasource.html">

                        数据源

                    </a>
                </li>



                <li>
                    <a href="ml-pipeline.html">

                        Pipelines (管道)

                    </a>
                </li>



                <li>
                    <a href="ml-features.html">

                        特征提取, 转换和选择

                    </a>
                </li>



                <li>
                    <a href="ml-classification-regression.html">

                        分类和回归

                    </a>
                </li>



                <li>
                    <a href="ml-clustering.html">

                        聚类

                    </a>
                </li>



                <li>
                    <a href="ml-collaborative-filtering.html">

                        协同过滤

                    </a>
                </li>



                <li>
                    <a href="ml-frequent-pattern-mining.html">

                        频繁模式挖掘

                    </a>
                </li>



                <li>
                    <a href="ml-tuning.html">

                        模型选择和调整

                    </a>
                </li>



                <li>
                    <a href="ml-advanced.html">

                        高级主题

                    </a>
                </li>



            </ul>

            <h3><a href="mllib-guide.html">MLlib：基于RDD的API指南</a></h3>

            <ul>

                <li>
                    <a href="mllib-data-types.html">

                        数据类型

                    </a>
                </li>



                <li>
                    <a href="mllib-statistics.html">

                        基本统计

                    </a>
                </li>



                <li>
                    <a href="mllib-classification-regression.html">

                        分类和回归

                    </a>
                </li>



                <li>
                    <a href="mllib-collaborative-filtering.html">

                        协同过滤

                    </a>
                </li>



                <li>
                    <a href="mllib-clustering.html">

                        聚类

                    </a>
                </li>



                <li>
                    <a href="mllib-dimensionality-reduction.html">

                        降维

                    </a>
                </li>



                <li>
                    <a href="mllib-feature-extraction.html">

                        特征提取,转换和选择

                    </a>
                </li>



                <li>
                    <a href="mllib-frequent-pattern-mining.html">

                        频繁模式数据挖掘

                    </a>
                </li>



                <li>
                    <a href="mllib-evaluation-metrics.html">

                        评估指标

                    </a>
                </li>



                <li>
                    <a href="mllib-pmml-model-export.html">

                        PMML 模型导出

                    </a>
                </li>



                <li>
                    <a href="mllib-optimization.html">

                        优化 (开发人员)

                    </a>
                </li>



            </ul>

        </div>
    </div>

    <input id="nav-trigger" class="nav-trigger" checked type="checkbox">
    <label for="nav-trigger"></label>
    <div class="content-with-sidebar" id="content">

        <h1 class="title">特征的提取,转换和选择</h1>


        <p>本节介绍使用功能的算法，大致分为以下几类：</p>

        <ul>
            <li>提取：从“原始”数据中提取特征</li>
            <li>转换：缩放，转换或修改特征</li>
            <li>选择：从较大的一组特征中选择一个子集</li>
            <li>局部敏感哈希（LSH）：这类算法将特征变换的方面与其他算法相结合。</li>
        </ul>

        <p><strong>目录</strong></p>

        <ul id="markdown-toc">
            <li><a href="#feature-extractors" id="markdown-toc-feature-extractors">Feature Extractors (特征提取)</a>    <ul>
                <li><a href="#tf-idf" id="markdown-toc-tf-idf">TF-IDF（词频-逆向文档频率）</a></li>
                <li><a href="#word2vec" id="markdown-toc-word2vec">Word2Vec</a></li>
                <li><a href="#countvectorizer" id="markdown-toc-countvectorizer">CountVectorizer</a></li>
                <li><a href="#featurehasher" id="markdown-toc-featurehasher">FeatureHasher (特征散列)</a></li>
            </ul>
            </li>
            <li><a href="#feature-transformers" id="markdown-toc-feature-transformers">Feature Transformers (特征变换)</a>    <ul>
                <li><a href="#tokenizer" id="markdown-toc-tokenizer">Tokenizer (分词器)</a></li>
                <li><a href="#stopwordsremover" id="markdown-toc-stopwordsremover">StopWordsRemover (去停用词)</a></li>
                <li><a href="#n-gram" id="markdown-toc-n-gram">n-gram (N元模型)</a></li>
                <li><a href="#binarizer" id="markdown-toc-binarizer">Binarizer (二值化)</a></li>
                <li><a href="#pca" id="markdown-toc-pca">PCA (主成分分析)</a></li>
                <li><a href="#polynomialexpansion" id="markdown-toc-polynomialexpansion">PolynomialExpansion (多项式扩展)</a></li>
                <li><a href="#discrete-cosine-transform-dct" id="markdown-toc-discrete-cosine-transform-dct">Discrete Cosine Transform (DCT 离散余弦变换)</a></li>
                <li><a href="#stringindexer" id="markdown-toc-stringindexer">StringIndexer (字符串-索引变换)</a></li>
                <li><a href="#indextostring" id="markdown-toc-indextostring">IndexToString (索引-字符串变换)</a></li>
                <li><a href="#onehotencoder-deprecated-since-230" id="markdown-toc-onehotencoder-deprecated-since-230">OneHotEncoder (独热编码 从2.3.0开始弃用))</a></li>
                <li><a href="#onehotencoderestimator" id="markdown-toc-onehotencoderestimator">OneHotEncoderEstimator (独热编码模型学习器)</a></li>
                <li><a href="#vectorindexer" id="markdown-toc-vectorindexer">VectorIndexer (向量类型索引化)</a></li>
                <li><a href="#interaction" id="markdown-toc-interaction">Interaction (相互作用)</a></li>
                <li><a href="#normalizer" id="markdown-toc-normalizer">Normalizer (范数p-norm规范化)</a></li>
                <li><a href="#standardscaler" id="markdown-toc-standardscaler">StandardScaler (标准缩放)</a></li>
                <li><a href="#minmaxscaler" id="markdown-toc-minmaxscaler">MinMaxScaler (最大-最小缩放)</a></li>
                <li><a href="#maxabsscaler" id="markdown-toc-maxabsscaler">MaxAbsScaler (绝对值规范化)</a></li>
                <li><a href="#bucketizer" id="markdown-toc-bucketizer">Bucketizer (分箱器)</a></li>
                <li><a href="#elementwiseproduct" id="markdown-toc-elementwiseproduct">ElementwiseProduct (Hadamard乘积)</a></li>
                <li><a href="#sqltransformer" id="markdown-toc-sqltransformer">SQLTransformer (SQL变换器)</a></li>
                <li><a href="#vectorassembler" id="markdown-toc-vectorassembler">VectorAssembler (特征向量合并)</a></li>
                <li><a href="#vectorsizehint" id="markdown-toc-vectorsizehint">VectorSizeHint</a></li>
                <li><a href="#quantilediscretizer" id="markdown-toc-quantilediscretizer">QuantileDiscretizer (分位数离散化)</a></li>
                <li><a href="#imputer" id="markdown-toc-imputer">Imputer</a></li>
            </ul>
            </li>
            <li><a href="#feature-selectors" id="markdown-toc-feature-selectors">Feature Selectors (特征选择)</a>    <ul>
                <li><a href="#vectorslicer" id="markdown-toc-vectorslicer">VectorSlicer (向量切片机)</a></li>
                <li><a href="#rformula" id="markdown-toc-rformula">RFormula (R模型公式)</a></li>
                <li><a href="#chisqselector" id="markdown-toc-chisqselector">ChiSqSelector (卡方特征选择器)</a></li>
            </ul>
            </li>
            <li><a href="#locality-sensitive-hashing" id="markdown-toc-locality-sensitive-hashing">Locality Sensitive Hashing (局部敏感哈希)</a>    <ul>
                <li><a href="#lsh-operations" id="markdown-toc-lsh-operations">LSH Operations (LSH运算)</a>        <ul>
                    <li><a href="#feature-transformation" id="markdown-toc-feature-transformation">Feature Transformation (特征变换)</a></li>
                    <li><a href="#approximate-similarity-join" id="markdown-toc-approximate-similarity-join">Approximate Similarity Join (近似相似度连接)</a></li>
                    <li><a href="#approximate-nearest-neighbor-search" id="markdown-toc-approximate-nearest-neighbor-search">Approximate Nearest Neighbor Search (近似最邻近搜索)</a></li>
                </ul>
                </li>
                <li><a href="#lsh-algorithms" id="markdown-toc-lsh-algorithms">LSH Algorithms (LSH算法)</a>        <ul>
                    <li><a href="#bucketed-random-projection-for-euclidean-distance" id="markdown-toc-bucketed-random-projection-for-euclidean-distance">Bucketed Random Projection for Euclidean Distance (欧几里得度量的随机投影)</a></li>
                    <li><a href="#minhash-for-jaccard-distance" id="markdown-toc-minhash-for-jaccard-distance">MinHash for Jaccard Distance</a></li>
                </ul>
                </li>
            </ul>
            </li>
        </ul>

        <h1 id="feature-extractors">特征抽取</h1>

        <h2 id="tf-idf">TF-IDF (词频-逆向文档频率)</h2>

        <p><a href="http://en.wikipedia.org/wiki/Tf%E2%80%93idf">词频 (Term frequency)-逆文档频率 (inverse document frequency)</a>
            是一种在文本挖掘中广泛使用的特征向量化方法，它可以体现一个文档中词语在语料库中的重要程度。
            词语由<code>$t$</code>表示, 文档由<code>$d$</code>表示, 语料库由<code>$D$</code>表示。
            词频<code>$TF(t, d)$</code>是词语 <code>$t$</code>在文档<code>$d$</code>中出现的次数。
            而文档频率 <code>$DF(t, D)$</code>表示包含单词<code>$t$</code>的文档次数。
            如果我们只使用词频来衡量重要性，很容易过度强调在文档中经常出现，却没有太多实际信息的词语
           比如： &#8220;a&#8221;, &#8220;the&#8221;, 和 &#8220;of&#8221;
            如果一个单词在整个语料库中出现的非常频繁，这意味着它并没有携带特定文档的某些特殊信息（换句话说，该单词对整个文档的重要程度低）。
            逆向文档频率是一个数字量度，表示一个单词提供了多少信息：
            <code>\[
                IDF(t, D) = \log \frac{|D| + 1}{DF(t, D) + 1},
                \]</code>
            其中，<code>$|D|$</code>是在语料库中文档总数。 由于使用对数，所以如果一个单词出现在所有的文件，其IDF值变为0。
            注意，应用平滑项以避免在语料库之外的项除以零（为了防止分母为0，分母需要加1）。
            因此，TF-IDF测量只是TF和IDF的产物：（对TF-IDF定义为TF和IDF的乘积）
            <code>\[
                TFIDF(t, d, D) = TF(t, d) \cdot IDF(t, D).
                \]</code>
            关于词频TF和文档频率DF的定义有多种形式。在MLlib，我们分离TF和IDF，使其灵活。
        </p>

        <p><strong>TF （词频Term Frequency）</strong>: <code>HashingTF</code> 和<code>CountVectorizer</code> 都可以用于生成词频TF向量。</p>

        <p><code>HashingTF</code> 是一个需要特征词集的转换器 <code>（Transformer）</code>
            ，它可以将这些集合转换成固定长度的特征向量。在文本处理中，“特征词集”有一系列的特征词构成。
            <code>HashingTF</code> 利用 <a href="http://en.wikipedia.org/wiki/Feature_hashing">hashing trick</a>。
            原始特征（raw feature）通过应用哈希函数映射到索引（术语）中。这里使用的哈希函数是<a href="https://en.wikipedia.org/wiki/MurmurHash">MurmurHash 3</a>
            然后根据映射的索引计算词频。这种方法避免了计算全局特征词对索引映射的需要，这对于大型语料库来说可能是昂贵的，但是它具有潜在的哈希冲突，其中不同的原始特征可以在散列之后变成相同的特征词。为了减少碰撞的机会，我们可以增加目标特征维度，即哈希表的桶数。
            由于使用简单的模数将散列函数转换为列索引，建议使用两个幂作为特征维，否则不会将特征均匀地映射到列。
            默认功能维度为 <code>$2^{18} = 262,144$</code>。
            可选的二进制切换参数控制词频计数。当设置为true时，所有非零频率计数设置为1。这对于模拟二进制而不是整数的离散概率模型尤其有用。</p>

        <p><code>CountVectorizer</code> 将文本文档转换为关键词计数的向量。有关详细信息，请参阅 <a href="ml-features.html#countvectorizer">CountVectorizer
        </a> 。</p>

        <p><strong>IDF（逆向文档频率）</strong>: <code>IDF</code> 是一个<code>Estimator</code>在一个数据集上应用它的fit（）方法，产生一个<code>IDFModel</code>  。

            <code>IDFModel</code> 获取特征向量(通常由<code>HashingTF</code> 或 <code>CountVectorizer</code>创建)然后计算每一个词在文档中出现的频次。<IDF会减少那些在语料库中出现频率较高的词的权重></IDF会减少那些在语料库中出现频率较高的词的权重>。</p>

        <p><strong>注意: </strong> <code>spark.ml</code> 不提供文本分割的工具。我们推荐用户参考<a href="http://nlp.stanford.edu/">Stanford NLP Group</a> 和
            <a href="https://github.com/scalanlp/chalk">scalanlp/chalk</a>。</p>

        <p><strong>示例</strong></p>

        <p>在下面的代码段中，我们从一组句子开始。我们使用
           <code>Tokenizer</code>将每个句子分成单词。对于每个句子（词袋，词集：bag of words），我们使用<code>HashingTF</code> 将该句子哈希成特征向量。最后使用<code>IDF</code>
            来重新缩放特征向量；这种转换通常可以提高使用文本特征的性能。然后，我们的特征向量可以被传递给学习算法。</p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.HashingTF">HashingTF Scala 文档</a> and
                    the <a href="api/scala/index.html#org.apache.spark.ml.feature.IDF">IDF Scala 文档</a>。</p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.</span><span class="o">{</span><span class="nc">HashingTF</span><span class="o">,</span> <span class="nc">IDF</span><span class="o">,</span> <span class="nc">Tokenizer</span><span class="o">}</span>
<span class="c1">// 创建一个集合，每一个句子代表一个文件。</span>
<span class="k">val</span> <span class="n">sentenceData</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="s">&quot;Hi I heard about Spark&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="s">&quot;I wish Java could use case classes&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="s">&quot;Logistic regression models are neat&quot;</span><span class="o">)</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;label&quot;</span><span class="o">,</span> <span class="s">&quot;sentence&quot;</span><span class="o">)</span>

<span class="c1">// 设置分词器的属性 输入列和输出列名称。</span>
<span class="c1">// 用tokenizer分词器把每个句子分解成单词；tokenizer的transform（）方法把每个句子拆分成了一个个单词。</span>
<span class="k">val</span> <span class="n">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">().</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">).</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">wordsData</span> <span class="k">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">sentenceData</span><span class="o">)</span>

<span class="c1">// 用HashingTF的transform（）方法把句子哈希成特征向量。我们这里设置哈希表的桶数为20。</span>
<span class="c1">// 词频将每行句子中的单词转为稀疏向量。</span>
<span class="k">val</span> <span class="n">hashingTF</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">HashingTF</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">).</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;rawFeatures&quot;</span><span class="o">).</span><span class="n">setNumFeatures</span><span class="o">(</span><span class="mi">20</span><span class="o">)</span>

<span class="k">val</span> <span class="n">featurizedData</span> <span class="k">=</span> <span class="n">hashingTF</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">wordsData</span><span class="o">)</span>
<span class="c1">// alternatively, CountVectorizer can also be used to get term frequency vectors</span>

<span class="c1">// 用IDF方法来重新构造特征向量的规模，生成的idf是一个Estimator。</span>
<span class="c1">// 在特征向量上应用它的fit（）方法，会产生一个IDFModel。</span>
<span class="k">val</span> <span class="n">idf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">IDF</span><span class="o">().</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;rawFeatures&quot;</span><span class="o">).</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">idfModel</span> <span class="k">=</span> <span class="n">idf</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">featurizedData</span><span class="o">)</span>

<span class="c1">// 同时，调用IDFModel的transform方法，可以得到每一个单词对应的TF-IDF 度量值。</span>
<span class="k">val</span> <span class="n">rescaledData</span> <span class="k">=</span> <span class="n">idfModel</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">featurizedData</span><span class="o">)</span>
<span class="n">rescaledData</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;label&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
                <div><small>在Spark repo中的"examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala" 中找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/HashingTF.html">HashingTF Java docs</a> and the
                    <a href="api/java/org/apache/spark/ml/feature/IDF.html">IDF Java docs</a> for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.HashingTF</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.IDF</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.IDFModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.Tokenizer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="s">&quot;Hi I heard about Spark&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="s">&quot;I wish Java could use case classes&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="s">&quot;Logistic regression models are neat&quot;</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;label&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">sentenceData</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">Tokenizer</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Tokenizer</span><span class="o">().</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">).</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">wordsData</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">sentenceData</span><span class="o">);</span>

<span class="kt">int</span> <span class="n">numFeatures</span> <span class="o">=</span> <span class="mi">20</span><span class="o">;</span>
<span class="n">HashingTF</span> <span class="n">hashingTF</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashingTF</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;rawFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setNumFeatures</span><span class="o">(</span><span class="n">numFeatures</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">featurizedData</span> <span class="o">=</span> <span class="n">hashingTF</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">wordsData</span><span class="o">);</span>
<span class="c1">// alternatively, CountVectorizer can also be used to get term frequency vectors</span>

<span class="n">IDF</span> <span class="n">idf</span> <span class="o">=</span> <span class="k">new</span> <span class="n">IDF</span><span class="o">().</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;rawFeatures&quot;</span><span class="o">).</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">);</span>
<span class="n">IDFModel</span> <span class="n">idfModel</span> <span class="o">=</span> <span class="n">idf</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">featurizedData</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">rescaledData</span> <span class="o">=</span> <span class="n">idfModel</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">featurizedData</span><span class="o">);</span>
<span class="n">rescaledData</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;label&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.HashingTF">HashingTF Python docs</a> and
                    the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.IDF">IDF Python docs</a> for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">HashingTF</span><span class="p">,</span> <span class="n">IDF</span><span class="p">,</span> <span class="n">Tokenizer</span>

<span class="n">sentenceData</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="s2">&quot;Hi I heard about Spark&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="s2">&quot;I wish Java could use case classes&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="s2">&quot;Logistic regression models are neat&quot;</span><span class="p">)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="s2">&quot;sentence&quot;</span><span class="p">])</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;sentence&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;words&quot;</span><span class="p">)</span>
<span class="n">wordsData</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">sentenceData</span><span class="p">)</span>

<span class="n">hashingTF</span> <span class="o">=</span> <span class="n">HashingTF</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;words&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;rawFeatures&quot;</span><span class="p">,</span> <span class="n">numFeatures</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">featurizedData</span> <span class="o">=</span> <span class="n">hashingTF</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">wordsData</span><span class="p">)</span>
<span class="c1"># alternatively, CountVectorizer can also be used to get term frequency vectors</span>

<span class="n">idf</span> <span class="o">=</span> <span class="n">IDF</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;rawFeatures&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">)</span>
<span class="n">idfModel</span> <span class="o">=</span> <span class="n">idf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">featurizedData</span><span class="p">)</span>
<span class="n">rescaledData</span> <span class="o">=</span> <span class="n">idfModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">featurizedData</span><span class="p">)</span>

<span class="n">rescaledData</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/tf_idf_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="word2vec">Word2Vec (词向量)</h2>

        <p><code>Word2Vec</code> 是一个 <code>Estimator (评估器)</code> 它采用表示文档的单词序列，并训练一个
            <code>Word2VecModel</code>。 该模型将每个单词映射到一个唯一的固定大小向量。 <code>Word2VecModel</code>
            使用文档中所有单词的平均值将每个文档转换为向量; 该向量然后可用作预测，文档相似性计算等功能。有关更多详细信息，请参阅有关<a href="mllib-feature-extraction.html#word2vec">Word2Vec 的MLlib用户指南。</a>
            </p>

        <p><strong>示例</strong></p>

        <p>在下面的代码段中，我们从一组文档开始，每一个文档都用一个单词序列表示。 对于每个文档，我们将其转换为特征向量。 然后可以将该特征向量传递给学习算法。   </p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.Word2Vec">Word2Vec Scala 文档</a>
                   。</p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.Word2Vec</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vector</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.Row</span>

<span class="c1">// 每行数据代表一个文档。</span>
<span class="k">val</span> <span class="n">documentDF</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="s">&quot;Hi I heard about Spark&quot;</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">),</span>
  <span class="s">&quot;I wish Java could use case classes&quot;</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">),</span>
  <span class="s">&quot;Logistic regression models are neat&quot;</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">)</span>
<span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="nc">Tuple1</span><span class="o">.</span><span class="n">apply</span><span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;text&quot;</span><span class="o">)</span>

<span class="c1">// 单词映射为一个向量</span>
<span class="k">val</span> <span class="n">word2Vec</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Word2Vec</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;text&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;result&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setVectorSize</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setMinCount</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">word2Vec</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">documentDF</span><span class="o">)</span>

<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">documentDF</span><span class="o">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">collect</span><span class="o">().</span><span class="n">foreach</span> <span class="o">{</span> <span class="k">case</span> <span class="nc">Row</span><span class="o">(</span><span class="n">text</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="k">_</span><span class="o">],</span> <span class="n">features</span><span class="k">:</span> <span class="kt">Vector</span><span class="o">)</span> <span class="k">=&gt;</span>
  <span class="n">println</span><span class="o">(</span><span class="s">s&quot;Text: [</span><span class="si">${</span><span class="n">text</span><span class="o">.</span><span class="n">mkString</span><span class="o">(</span><span class="s">&quot;, &quot;</span><span class="o">)</span><span class="si">}</span><span class="s">] =&gt; \nVector: </span><span class="si">$features</span><span class="s">\n&quot;</span><span class="o">)</span> <span class="o">}</span>
</pre></div>
                <div><small>在Spark repo中的"examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala" 中找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/Word2Vec.html">Word2Vec Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.Word2Vec</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.Word2VecModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.*</span><span class="o">;</span>

<span class="c1">// Input data: Each row is a bag of words from a sentence or document.</span>
<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;Hi I heard about Spark&quot;</span><span class="o">.</span><span class="na">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">))),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;I wish Java could use case classes&quot;</span><span class="o">.</span><span class="na">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">))),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;Logistic regression models are neat&quot;</span><span class="o">.</span><span class="na">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">)))</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;text&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">ArrayType</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">,</span> <span class="kc">true</span><span class="o">),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">documentDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="c1">// Learn a mapping from words to Vectors.</span>
<span class="n">Word2Vec</span> <span class="n">word2Vec</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Word2Vec</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;text&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;result&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setVectorSize</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setMinCount</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span>

<span class="n">Word2VecModel</span> <span class="n">model</span> <span class="o">=</span> <span class="n">word2Vec</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">documentDF</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">documentDF</span><span class="o">);</span>

<span class="k">for</span> <span class="o">(</span><span class="n">Row</span> <span class="n">row</span> <span class="o">:</span> <span class="n">result</span><span class="o">.</span><span class="na">collectAsList</span><span class="o">())</span> <span class="o">{</span>
  <span class="n">List</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="na">getList</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span>
  <span class="n">Vector</span> <span class="n">vector</span> <span class="o">=</span> <span class="o">(</span><span class="n">Vector</span><span class="o">)</span> <span class="n">row</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span>
  <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Text: &quot;</span> <span class="o">+</span> <span class="n">text</span> <span class="o">+</span> <span class="s">&quot; =&gt; \nVector: &quot;</span> <span class="o">+</span> <span class="n">vector</span> <span class="o">+</span> <span class="s">&quot;\n&quot;</span><span class="o">);</span>
<span class="o">}</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.Word2Vec">Word2Vec Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">Word2Vec</span>

<span class="c1"># Input data: Each row is a bag of words from a sentence or document.</span>
<span class="n">documentDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;Hi I heard about Spark&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">),</span> <span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;I wish Java could use case classes&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">),</span> <span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Logistic regression models are neat&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">),</span> <span class="p">)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>

<span class="c1"># Learn a mapping from words to Vectors.</span>
<span class="n">word2Vec</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">vectorSize</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">minCount</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;result&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">word2Vec</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">documentDF</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">documentDF</span><span class="p">)</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">collect</span><span class="p">():</span>
    <span class="n">text</span><span class="p">,</span> <span class="n">vector</span> <span class="o">=</span> <span class="n">row</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Text: [</span><span class="si">%s</span><span class="s2">] =&gt; </span><span class="se">\n</span><span class="s2">Vector: </span><span class="si">%s</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">vector</span><span class="p">)))</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/word2vec_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="countvectorizer">CountVectorizer (计数向量)</h2>

        <p><code>CountVectorizer</code> 和 <code>CountVectorizerModel</code>
            旨在通过计数来将一个文档转换为向量。当不存在先验字典时，<code>CountVectorizer</code> 作为
            <code>Estimator</code>提取词汇进行训练，并生成一个<code>CountVectorizerModel</code>， 用于存储相应的词汇向量空间。
            该模型通过词汇生成文档的稀疏表示，然后可以将其传递给其他算法，如LDA。</p>

        <p>在拟合过程中， <code>CountVectorizer</code> 将根据语料库中的词频排序从高到低进行选择，词汇表的最大含量由<code>vocabSize</code> 超参数来指定， 可选参数
           <code>minDF</code> 还通过指定术语必须出现以包含在词汇表中的文档的最小数量（或小于1.0）来影响拟合过程。 另一个可选的二进制切换参数控制输出向量。 如果设置为true，则所有非零计数都设置为1.对于模拟二进制而不是整数的离散概率模型，这是非常有用的。</p>

        <p><strong>示例</strong></p>

        <p>假设我们有如下的DataFrame包含 <code>id</code> 和 <code>texts</code>两列:</p>

        <pre><code> id | texts
----|----------
 0  | Array("a", "b", "c")
 1  | Array("a", "b", "b", "c", "a")
</code></pre>

        <p>在 <code>texts</code>中每一行都是Array[String]类型的文档。调用
           <code>CountVectorizer</code> 的拟合产生一个具有词汇表（a, b, c）的<code>CountVectorizerModel</code>
            然后转换后的输出列 包含"vector"这一列:</p>

        <pre><code> id | texts                           | vector
----|---------------------------------|---------------
 0  | Array("a", "b", "c")            | (3,[0,1,2],[1.0,1.0,1.0])
 1  | Array("a", "b", "b", "c", "a")  | (3,[0,1,2],[2.0,2.0,1.0])
</code></pre>

        <p>每个向量表示文档在词汇表上的标记数。</p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.CountVectorizer">CountVectorizer Scala 文档</a>
                    and the <a href="api/scala/index.html#org.apache.spark.ml.feature.CountVectorizerModel">CountVectorizerModel Scala 文档</a>
                    </p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.</span><span class="o">{</span><span class="nc">CountVectorizer</span><span class="o">,</span> <span class="nc">CountVectorizerModel</span><span class="o">}</span>

<span class="c1">// 可以看成是一个包含两个文档的迷你语料库。</span>
<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;words&quot;</span><span class="o">)</span>

<span class="c1">// 从语料库中拟合一个CountVectorizerModel</span>
<span class="k">val</span> <span class="n">cvModel</span><span class="k">:</span> <span class="kt">CountVectorizerModel</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">CountVectorizer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setVocabSize</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setMinDF</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
  <span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>

<span class="c1">// 或者，使用先验词汇表定义CountVectorizerModel</span>
<span class="k">val</span> <span class="n">cvm</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">CountVectorizerModel</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="n">cvModel</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
                <div><small>在Spark repo中的 "examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala" 查看完整的代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/CountVectorizer.html">CountVectorizer Java docs</a>
                    and the <a href="api/java/org/apache/spark/ml/feature/CountVectorizerModel.html">CountVectorizerModel Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.CountVectorizer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.CountVectorizerModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.*</span><span class="o">;</span>

<span class="c1">// Input data: Each row is a bag of words from a sentence or document.</span>
<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">))</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span> <span class="o">[]</span> <span class="o">{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;text&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">ArrayType</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">,</span> <span class="kc">true</span><span class="o">),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="c1">// fit a CountVectorizerModel from the corpus</span>
<span class="n">CountVectorizerModel</span> <span class="n">cvModel</span> <span class="o">=</span> <span class="k">new</span> <span class="n">CountVectorizer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;text&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;feature&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setVocabSize</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setMinDF</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
  <span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>

<span class="c1">// alternatively, define CountVectorizerModel with a-priori vocabulary</span>
<span class="n">CountVectorizerModel</span> <span class="n">cvm</span> <span class="o">=</span> <span class="k">new</span> <span class="n">CountVectorizerModel</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">})</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;text&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;feature&quot;</span><span class="o">);</span>

<span class="n">cvModel</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.CountVectorizer">CountVectorizer Python docs</a>
                    and the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.CountVectorizerModel">CountVectorizerModel Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="c1"># Input data: Each row is a bag of words with a ID.</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;a b c&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;a b b c a&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">))</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;words&quot;</span><span class="p">])</span>

<span class="c1"># fit a CountVectorizerModel from the corpus.</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;words&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">vocabSize</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">minDF</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/count_vectorizer_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="featurehasher">FeatureHasher (特征散列)</h2>

        <p>特征散列将一组分类或数字特征投影到指定尺寸的特征向量中（通常远小于原始特征空间的特征向量）。 这是使用<a href="https://en.wikipedia.org/wiki/Feature_hashing">hashing trick</a>
            将特征映射到特征向量中的索引来完成的。</p>

        <p><code>FeatureHasher</code> 转换器在多列上操作。每列可能包含数字或分类特征。列数据类型的行为和处理如下：</p>

        <ul>
            <li>数字列: 对于数字特征, 列名称的哈希值用于将特征值映射到特征向量中的索引. 默认情况下，数字特征不被视为分类（即使它们是整数）。要将它们视为分类，请使用<code>categoricalCols</code> 参数指定相关列。</li>
            <li>符串列: 对于分类特征, 字符串“column_name = value”的哈希值用于映射到矢量索引，指示符值为1.0. 因此，类别特征是"one-hot"编码 (类似于使用<a href="ml-features.html#onehotencoder">OneHotEncoder</a> 用 <code>dropLast=false</code>)。</li>
            <li>布尔列: 布尔值的处理方式与字符串列相同。也就是说，布尔特征表示为“column_name = true”或“column_name = false”，指示符值为 <code>1.0</code>。</li>
        </ul>

        <p>忽略Null(缺失)值(在结果特征向量中隐式为零)。</p>

        <p>这里使用的哈希函数也是在 <a href="ml-features.html#tf-idf">HashingTF</a> 中使用的 <a href="https://en.wikipedia.org/wiki/MurmurHash">MurmurHash 3</a>
            由于散列值的简单模数用于确定向量索引，因此建议使用2的幂作为numFeatures参数; 否则，特征将不会均匀地映射到矢量索引。</p>

        <p><strong>示例</strong></p>

        <p>假设我们有4个输入列的DataFrame <code>real</code>, <code>bool</code>, <code>stringNum</code>, 和 <code>string</code>.
            这些不同的数据类型作为输入将说明变换的行为以产生一列特征向量。</p>

        <pre><code>real| bool|stringNum|string
----|-----|---------|------
 2.2| true|        1|   foo
 3.3|false|        2|   bar
 4.4|false|        3|   baz
 5.5|false|        4|   foo
</code></pre>

        <p>那 <code>FeatureHasher.transform</code>这个DataFrame 的输出是：</p>

        <pre><code>real|bool |stringNum|string|features
----|-----|---------|------|-------------------------------------------------------
2.2 |true |1        |foo   |(262144,[51871, 63643,174475,253195],[1.0,1.0,2.2,1.0])
3.3 |false|2        |bar   |(262144,[6031,  80619,140467,174475],[1.0,1.0,1.0,3.3])
4.4 |false|3        |baz   |(262144,[24279,140467,174475,196810],[1.0,1.0,4.4,1.0])
5.5 |false|4        |foo   |(262144,[63643,140467,168512,174475],[1.0,1.0,1.0,5.5])
</code></pre>

        <p>然后可以将得到的特征向量传递给学习算法</p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>有关API的更多详细信息，请参阅 <a href="api/scala/index.html#org.apache.spark.ml.feature.FeatureHasher">FeatureHasher Scala 文档。</a>
                    </p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.FeatureHasher</span>

<span class="k">val</span> <span class="n">dataset</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mf">2.2</span><span class="o">,</span> <span class="kc">true</span><span class="o">,</span> <span class="s">&quot;1&quot;</span><span class="o">,</span> <span class="s">&quot;foo&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">3.3</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="s">&quot;2&quot;</span><span class="o">,</span> <span class="s">&quot;bar&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">4.4</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="s">&quot;3&quot;</span><span class="o">,</span> <span class="s">&quot;baz&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">5.5</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="s">&quot;4&quot;</span><span class="o">,</span> <span class="s">&quot;foo&quot;</span><span class="o">)</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;real&quot;</span><span class="o">,</span> <span class="s">&quot;bool&quot;</span><span class="o">,</span> <span class="s">&quot;stringNum&quot;</span><span class="o">,</span> <span class="s">&quot;string&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">hasher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FeatureHasher</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCols</span><span class="o">(</span><span class="s">&quot;real&quot;</span><span class="o">,</span> <span class="s">&quot;bool&quot;</span><span class="o">,</span> <span class="s">&quot;stringNum&quot;</span><span class="o">,</span> <span class="s">&quot;string&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">featurized</span> <span class="k">=</span> <span class="n">hasher</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
<span class="n">featurized</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
                <div><small>在Spark repo中的"examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala" 中找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/FeatureHasher.html">FeatureHasher Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.FeatureHasher</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">2.2</span><span class="o">,</span> <span class="kc">true</span><span class="o">,</span> <span class="s">&quot;1&quot;</span><span class="o">,</span> <span class="s">&quot;foo&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">3.3</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="s">&quot;2&quot;</span><span class="o">,</span> <span class="s">&quot;bar&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">4.4</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="s">&quot;3&quot;</span><span class="o">,</span> <span class="s">&quot;baz&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">5.5</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="s">&quot;4&quot;</span><span class="o">,</span> <span class="s">&quot;foo&quot;</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;real&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;bool&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">BooleanType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;stringNum&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;string&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">FeatureHasher</span> <span class="n">hasher</span> <span class="o">=</span> <span class="k">new</span> <span class="n">FeatureHasher</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;real&quot;</span><span class="o">,</span> <span class="s">&quot;bool&quot;</span><span class="o">,</span> <span class="s">&quot;stringNum&quot;</span><span class="o">,</span> <span class="s">&quot;string&quot;</span><span class="o">})</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">featurized</span> <span class="o">=</span> <span class="n">hasher</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">);</span>

<span class="n">featurized</span><span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.FeatureHasher">FeatureHasher Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">FeatureHasher</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mf">2.2</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;foo&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">3.3</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="s2">&quot;2&quot;</span><span class="p">,</span> <span class="s2">&quot;bar&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">4.4</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="s2">&quot;3&quot;</span><span class="p">,</span> <span class="s2">&quot;baz&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">5.5</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="s2">&quot;4&quot;</span><span class="p">,</span> <span class="s2">&quot;foo&quot;</span><span class="p">)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;real&quot;</span><span class="p">,</span> <span class="s2">&quot;bool&quot;</span><span class="p">,</span> <span class="s2">&quot;stringNum&quot;</span><span class="p">,</span> <span class="s2">&quot;string&quot;</span><span class="p">])</span>

<span class="n">hasher</span> <span class="o">=</span> <span class="n">FeatureHasher</span><span class="p">(</span><span class="n">inputCols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;real&quot;</span><span class="p">,</span> <span class="s2">&quot;bool&quot;</span><span class="p">,</span> <span class="s2">&quot;stringNum&quot;</span><span class="p">,</span> <span class="s2">&quot;string&quot;</span><span class="p">],</span>
                       <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">)</span>

<span class="n">featurized</span> <span class="o">=</span> <span class="n">hasher</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">featurized</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/feature_hasher_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h1 id="feature-transformers">Feature Transformers (特征变换)</h1>

        <h2 id="tokenizer">Tokenizer (分词器)</h2>

        <p><a href="http://en.wikipedia.org/wiki/Lexical_analysis#Tokenization">Tokenization (英文文本分词)</a> 将文本（例如句子）分解为单个术语（通常是单词）的过程。一个简单的 <a href="api/scala/index.html#org.apache.spark.ml.feature.Tokenizer">Tokenizer</a> 类提供此功能。下面的示例显示了如何将句子拆分为单词序列。</p>

        <p><a href="api/scala/index.html#org.apache.spark.ml.feature.RegexTokenizer">RegexTokenizer (正则分词)</a>使用正则表达式拆分文本。提供了（更高级的）基于正则表达式 (regex) 匹配的（对句子或文本的）单词拆分。
            默认情况下，参数“pattern”(正则表达式, 默认为: "\\s+" 空格) 作为分隔符用于拆分输入的文本。或者，用户可以将参数“gaps”设置为false，指示正则表达式“pattern”表示“tokens”而不是分隔符，这样作为划分结果找到的所有匹配项。</p>

        <p><strong>示例</strong></p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.Tokenizer">Tokenizer Scala 文档</a>
                    and the <a href="api/scala/index.html#org.apache.spark.ml.feature.RegexTokenizer">RegexTokenizer Scala 文档</a>
                    。</p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.</span><span class="o">{</span><span class="nc">RegexTokenizer</span><span class="o">,</span> <span class="nc">Tokenizer</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.functions._</span>

<span class="k">val</span> <span class="n">sentenceDataFrame</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="s">&quot;Hi I heard about Spark&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="s">&quot;I wish Java could use case classes&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="s">&quot;Logistic,regression,models,are,neat&quot;</span><span class="o">)</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;sentence&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">().</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">).</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">regexTokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RegexTokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setPattern</span><span class="o">(</span><span class="s">&quot;\\W&quot;</span><span class="o">)</span>
<span class="c1">// alternatively .setPattern(&quot;\\w+&quot;).setGaps(false) 默认Gaps是true 表示按照正则表达式匹配的字符分割。\W 表示匹配任何非单词字符。等价于“[^A-Za-z0-9_]”。</span>

<span class="k">val</span> <span class="n">countTokens</span> <span class="k">=</span> <span class="n">udf</span> <span class="o">{</span> <span class="o">(</span><span class="n">words</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span> <span class="k">=&gt;</span> <span class="n">words</span><span class="o">.</span><span class="n">length</span> <span class="o">}</span>

<span class="k">val</span> <span class="n">tokenized</span> <span class="k">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">sentenceDataFrame</span><span class="o">)</span>
<span class="n">tokenized</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">,</span> <span class="s">&quot;words&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">withColumn</span><span class="o">(</span><span class="s">&quot;tokens&quot;</span><span class="o">,</span> <span class="n">countTokens</span><span class="o">(</span><span class="n">col</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">))).</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="n">regexTokenized</span> <span class="k">=</span> <span class="n">regexTokenizer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">sentenceDataFrame</span><span class="o">)</span>
<span class="n">regexTokenized</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">,</span> <span class="s">&quot;words&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">withColumn</span><span class="o">(</span><span class="s">&quot;tokens&quot;</span><span class="o">,</span> <span class="n">countTokens</span><span class="o">(</span><span class="n">col</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">))).</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
                <div><small>在Spark repo中的"examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala"中找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/Tokenizer.html">Tokenizer Java docs</a>
                    and the <a href="api/java/org/apache/spark/ml/feature/RegexTokenizer.html">RegexTokenizer Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">scala.collection.mutable.WrappedArray</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.RegexTokenizer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.Tokenizer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="c1">// col(&quot;...&quot;) is preferable to df.col(&quot;...&quot;)</span>
<span class="kn">import static</span> <span class="nn">org.apache.spark.sql.functions.callUDF</span><span class="o">;</span>
<span class="kn">import static</span> <span class="nn">org.apache.spark.sql.functions.col</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="s">&quot;Hi I heard about Spark&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="s">&quot;I wish Java could use case classes&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="s">&quot;Logistic,regression,models,are,neat&quot;</span><span class="o">)</span>
<span class="o">);</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">sentenceDataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">Tokenizer</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Tokenizer</span><span class="o">().</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">).</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">);</span>

<span class="n">RegexTokenizer</span> <span class="n">regexTokenizer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">RegexTokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="na">setPattern</span><span class="o">(</span><span class="s">&quot;\\W&quot;</span><span class="o">);</span>  <span class="c1">// alternatively .setPattern(&quot;\\w+&quot;).setGaps(false);</span>

<span class="n">spark</span><span class="o">.</span><span class="na">udf</span><span class="o">().</span><span class="na">register</span><span class="o">(</span>
  <span class="s">&quot;countTokens&quot;</span><span class="o">,</span> <span class="o">(</span><span class="n">WrappedArray</span><span class="o">&lt;?&gt;</span> <span class="n">words</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="n">words</span><span class="o">.</span><span class="na">size</span><span class="o">(),</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">tokenized</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">sentenceDataFrame</span><span class="o">);</span>
<span class="n">tokenized</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">,</span> <span class="s">&quot;words&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="na">withColumn</span><span class="o">(</span><span class="s">&quot;tokens&quot;</span><span class="o">,</span> <span class="n">callUDF</span><span class="o">(</span><span class="s">&quot;countTokens&quot;</span><span class="o">,</span> <span class="n">col</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">)))</span>
    <span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">regexTokenized</span> <span class="o">=</span> <span class="n">regexTokenizer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">sentenceDataFrame</span><span class="o">);</span>
<span class="n">regexTokenized</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">,</span> <span class="s">&quot;words&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="na">withColumn</span><span class="o">(</span><span class="s">&quot;tokens&quot;</span><span class="o">,</span> <span class="n">callUDF</span><span class="o">(</span><span class="s">&quot;countTokens&quot;</span><span class="o">,</span> <span class="n">col</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">)))</span>
    <span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.Tokenizer">Tokenizer Python docs</a> and
                    the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.RegexTokenizer">RegexTokenizer Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">Tokenizer</span><span class="p">,</span> <span class="n">RegexTokenizer</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span><span class="p">,</span> <span class="n">udf</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">IntegerType</span>

<span class="n">sentenceDataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Hi I heard about Spark&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;I wish Java could use case classes&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;Logistic,regression,models,are,neat&quot;</span><span class="p">)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;sentence&quot;</span><span class="p">])</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;sentence&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;words&quot;</span><span class="p">)</span>

<span class="n">regexTokenizer</span> <span class="o">=</span> <span class="n">RegexTokenizer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;sentence&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;words&quot;</span><span class="p">,</span> <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">W&quot;</span><span class="p">)</span>
<span class="c1"># alternatively, pattern=&quot;\\w+&quot;, gaps(False)</span>

<span class="n">countTokens</span> <span class="o">=</span> <span class="n">udf</span><span class="p">(</span><span class="k">lambda</span> <span class="n">words</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">),</span> <span class="n">IntegerType</span><span class="p">())</span>

<span class="n">tokenized</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">sentenceDataFrame</span><span class="p">)</span>
<span class="n">tokenized</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;sentence&quot;</span><span class="p">,</span> <span class="s2">&quot;words&quot;</span><span class="p">)</span>\
    <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="n">countTokens</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;words&quot;</span><span class="p">)))</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">regexTokenized</span> <span class="o">=</span> <span class="n">regexTokenizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">sentenceDataFrame</span><span class="p">)</span>
<span class="n">regexTokenized</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;sentence&quot;</span><span class="p">,</span> <span class="s2">&quot;words&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="n">countTokens</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;words&quot;</span><span class="p">)))</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/tokenizer_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="stopwordsremover">StopWordsRemover (英文停用词过滤)</h2>
        <p><a href="https://en.wikipedia.org/wiki/Stop_words">Stop words</a>是（在文档中）频繁出现，但未携带太多意义的词语，它们不应该参与算法运算。</p>

        <p><code>StopWordsRemover</code>将输入的字符串 (如分词器Tokenizer的输出)中的停用词删除（保留有意义的词）。停用字表由
            <code>stopWords</code>参数指定。对于某些语言的默认停止词是通过调用 <code>StopWordsRemover.loadDefaultStopWords(language)</code>设置的，可用的选项为"丹麦"，"荷兰语"、"英语"、"芬兰语"，"法国"，"德国"、"匈牙利"、"意大利"、"挪威"、"葡萄牙"、"俄罗斯"、"西班牙"、"瑞典"和"土耳其"。布尔型参数<code>caseSensitive</code>
            指示是否区分大小写（默认为否）</p>

        <p><strong>示例</strong></p>

        <p>假设有如下DataFrame，有<code>id</code> 和 <code>raw</code>两列:</p>

        <pre><code> id | raw
----|----------
 0  | [I, saw, the, red, baloon]
 1  | [Mary, had, a, little, lamb]
</code></pre>

        <p>通过对<code>raw</code>列调用<code>StopWordsRemover</code>，我们可以得到筛选出的结果列如下：
            </p>

        <pre><code> id | raw                         | filtered
----|-----------------------------|--------------------
 0  | [I, saw, the, red, baloon]  |  [saw, red, baloon]
 1  | [Mary, had, a, little, lamb]|[Mary, little, lamb]
</code></pre>

        <p>在 <code>filtered</code>列,停用词 "I", "the", "had", 和 "a" 被过滤掉了</p>

        <div class="codetabs">

            <div data-lang="scala">

                <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.StopWordsRemover">StopWordsRemover Scala 文档</a>。
                    </p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.StopWordsRemover</span>

<span class="k">val</span> <span class="n">remover</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StopWordsRemover</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;raw&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;filtered&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">dataSet</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">&quot;I&quot;</span><span class="o">,</span> <span class="s">&quot;saw&quot;</span><span class="o">,</span> <span class="s">&quot;the&quot;</span><span class="o">,</span> <span class="s">&quot;red&quot;</span><span class="o">,</span> <span class="s">&quot;balloon&quot;</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">&quot;Mary&quot;</span><span class="o">,</span> <span class="s">&quot;had&quot;</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;little&quot;</span><span class="o">,</span> <span class="s">&quot;lamb&quot;</span><span class="o">))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;raw&quot;</span><span class="o">)</span>

<span class="n">remover</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataSet</span><span class="o">).</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
                <div><small>在Spark repo中的"examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala" 中找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/StopWordsRemover.html">StopWordsRemover Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.StopWordsRemover</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">StopWordsRemover</span> <span class="n">remover</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StopWordsRemover</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;raw&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;filtered&quot;</span><span class="o">);</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;I&quot;</span><span class="o">,</span> <span class="s">&quot;saw&quot;</span><span class="o">,</span> <span class="s">&quot;the&quot;</span><span class="o">,</span> <span class="s">&quot;red&quot;</span><span class="o">,</span> <span class="s">&quot;balloon&quot;</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;Mary&quot;</span><span class="o">,</span> <span class="s">&quot;had&quot;</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;little&quot;</span><span class="o">,</span> <span class="s">&quot;lamb&quot;</span><span class="o">))</span>
<span class="o">);</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span>
    <span class="s">&quot;raw&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">createArrayType</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>
<span class="n">remover</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">).</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.StopWordsRemover">StopWordsRemover Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">StopWordsRemover</span>

<span class="n">sentenceData</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;I&quot;</span><span class="p">,</span> <span class="s2">&quot;saw&quot;</span><span class="p">,</span> <span class="s2">&quot;the&quot;</span><span class="p">,</span> <span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="s2">&quot;balloon&quot;</span><span class="p">]),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;Mary&quot;</span><span class="p">,</span> <span class="s2">&quot;had&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;little&quot;</span><span class="p">,</span> <span class="s2">&quot;lamb&quot;</span><span class="p">])</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;raw&quot;</span><span class="p">])</span>

<span class="n">remover</span> <span class="o">=</span> <span class="n">StopWordsRemover</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;raw&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;filtered&quot;</span><span class="p">)</span>
<span class="n">remover</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">sentenceData</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/stopwords_remover_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="n-gram">$n$-gram (N元模型)</h2>

        <p>一个<a href="https://en.wikipedia.org/wiki/N-gram">n-gram</a> 是一个长度为n（整数）的字符的序列。<code>NGram</code> 可用于将输入特征转换成n-grams。</p>

        <p><code>NGram</code> 的输入为一系列的字符串(例如:<a href="ml-features.html#tokenizer">Tokenizer</a>的输出)。  参数 <code>n</code> 表示每个n-gram 中单词（terms）的数量。
            输出将由n-grams序列组成，其中每个nn-gram由空格分隔的nn个连续词的字符串表示。如果输入的字符串序列少于 n个单词，NGram 输出为空。</p>


       <p> 将字符串数组转换为n-gram数组。输入数组中的Null值被忽略。每个n-gram都由一个空格分隔的字串表示。当输入为空时，返回一个空数组。当输入数组小于n(每n-gram的元素数)时，不会返回n-gram。</p>
        <p><strong>示例</strong></p>

        <div class="codetabs">

            <div data-lang="scala">

                <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.NGram">NGram Scala 文档</a>。
                    </p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.NGram</span>

<span class="k">val</span> <span class="n">wordDataFrame</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="s">&quot;Hi&quot;</span><span class="o">,</span> <span class="s">&quot;I&quot;</span><span class="o">,</span> <span class="s">&quot;heard&quot;</span><span class="o">,</span> <span class="s">&quot;about&quot;</span><span class="o">,</span> <span class="s">&quot;Spark&quot;</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="s">&quot;I&quot;</span><span class="o">,</span> <span class="s">&quot;wish&quot;</span><span class="o">,</span> <span class="s">&quot;Java&quot;</span><span class="o">,</span> <span class="s">&quot;could&quot;</span><span class="o">,</span> <span class="s">&quot;use&quot;</span><span class="o">,</span> <span class="s">&quot;case&quot;</span><span class="o">,</span> <span class="s">&quot;classes&quot;</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="s">&quot;Logistic&quot;</span><span class="o">,</span> <span class="s">&quot;regression&quot;</span><span class="o">,</span> <span class="s">&quot;models&quot;</span><span class="o">,</span> <span class="s">&quot;are&quot;</span><span class="o">,</span> <span class="s">&quot;neat&quot;</span><span class="o">))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;words&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">ngram</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NGram</span><span class="o">().</span><span class="n">setN</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">).</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;ngrams&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">ngramDataFrame</span> <span class="k">=</span> <span class="n">ngram</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">wordDataFrame</span><span class="o">)</span>
<span class="n">ngramDataFrame</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;ngrams&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
+------------------------------------------------------------------+
|ngrams                                                            |
+------------------------------------------------------------------+
|[Hi I, I heard, heard about, about Spark]                         |
|[I wish, wish Java, Java could, could use, use case, case classes]|
|[Logistic regression, regression models, models are, are neat]    |
+------------------------------------------------------------------+
                </pre></div>
                <div><small>在Spark repo中的 "examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala"中找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/NGram.html">NGram Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.NGram</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;Hi&quot;</span><span class="o">,</span> <span class="s">&quot;I&quot;</span><span class="o">,</span> <span class="s">&quot;heard&quot;</span><span class="o">,</span> <span class="s">&quot;about&quot;</span><span class="o">,</span> <span class="s">&quot;Spark&quot;</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;I&quot;</span><span class="o">,</span> <span class="s">&quot;wish&quot;</span><span class="o">,</span> <span class="s">&quot;Java&quot;</span><span class="o">,</span> <span class="s">&quot;could&quot;</span><span class="o">,</span> <span class="s">&quot;use&quot;</span><span class="o">,</span> <span class="s">&quot;case&quot;</span><span class="o">,</span> <span class="s">&quot;classes&quot;</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;Logistic&quot;</span><span class="o">,</span> <span class="s">&quot;regression&quot;</span><span class="o">,</span> <span class="s">&quot;models&quot;</span><span class="o">,</span> <span class="s">&quot;are&quot;</span><span class="o">,</span> <span class="s">&quot;neat&quot;</span><span class="o">))</span>
<span class="o">);</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span>
    <span class="s">&quot;words&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">createArrayType</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">wordDataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">NGram</span> <span class="n">ngramTransformer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">NGram</span><span class="o">().</span><span class="na">setN</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">).</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;ngrams&quot;</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">ngramDataFrame</span> <span class="o">=</span> <span class="n">ngramTransformer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">wordDataFrame</span><span class="o">);</span>
<span class="n">ngramDataFrame</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;ngrams&quot;</span><span class="o">).</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.NGram">NGram Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">NGram</span>

<span class="n">wordDataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;Hi&quot;</span><span class="p">,</span> <span class="s2">&quot;I&quot;</span><span class="p">,</span> <span class="s2">&quot;heard&quot;</span><span class="p">,</span> <span class="s2">&quot;about&quot;</span><span class="p">,</span> <span class="s2">&quot;Spark&quot;</span><span class="p">]),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;I&quot;</span><span class="p">,</span> <span class="s2">&quot;wish&quot;</span><span class="p">,</span> <span class="s2">&quot;Java&quot;</span><span class="p">,</span> <span class="s2">&quot;could&quot;</span><span class="p">,</span> <span class="s2">&quot;use&quot;</span><span class="p">,</span> <span class="s2">&quot;case&quot;</span><span class="p">,</span> <span class="s2">&quot;classes&quot;</span><span class="p">]),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;Logistic&quot;</span><span class="p">,</span> <span class="s2">&quot;regression&quot;</span><span class="p">,</span> <span class="s2">&quot;models&quot;</span><span class="p">,</span> <span class="s2">&quot;are&quot;</span><span class="p">,</span> <span class="s2">&quot;neat&quot;</span><span class="p">])</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;words&quot;</span><span class="p">])</span>

<span class="n">ngram</span> <span class="o">=</span> <span class="n">NGram</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;words&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;ngrams&quot;</span><span class="p">)</span>

<span class="n">ngramDataFrame</span> <span class="o">=</span> <span class="n">ngram</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">wordDataFrame</span><span class="p">)</span>
<span class="n">ngramDataFrame</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;ngrams&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/n_gram_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="binarizer">Binarizer (二值化)</h2>

        <p>Binarization （二值化）是将数值特征阈值化为二进制（0/1）特征的过程。</p>

        <p><code>Binarizer</code>（ML提供的二元化方法）二元化涉及的参数有 <code>inputCol</code> 和 <code>outputCol</code>, 以及 <code>threshold</code>
            （输入的）特征值大于阀值将二值化为1.0，特征值小于等于阀值将二值化为0。 <code>inputCol</code>支持向量（Vector）和双精度（Double）类型。</p>

        <p><strong>示例</strong></p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.Binarizer">Binarizer Scala 文档</a>。
                    </p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.Binarizer</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">((</span><span class="mi">0</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">),</span> <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mf">0.8</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mf">0.2</span><span class="o">))</span>
<span class="k">val</span> <span class="n">dataFrame</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;feature&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">binarizer</span><span class="k">:</span> <span class="kt">Binarizer</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Binarizer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;feature&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;binarized_feature&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setThreshold</span><span class="o">(</span><span class="mf">0.5</span><span class="o">)</span>

<span class="k">val</span> <span class="n">binarizedDataFrame</span> <span class="k">=</span> <span class="n">binarizer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>

<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Binarizer output with Threshold = </span><span class="si">${</span><span class="n">binarizer</span><span class="o">.</span><span class="n">getThreshold</span><span class="si">}</span><span class="s">&quot;</span><span class="o">)</span>
<span class="n">binarizedDataFrame</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
+---+-------+-----------------+
| id|feature|binarized_feature|
+---+-------+-----------------+
|  0|    0.1|              0.0|
|  1|    0.8|              1.0|
|  2|    0.2|              0.0|
+---+-------+-----------------+
</pre></div>
                <div><small>在Spark repo中的 "examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala"中找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/Binarizer.html">Binarizer Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.Binarizer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mf">0.8</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mf">0.2</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;feature&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">continuousDataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">Binarizer</span> <span class="n">binarizer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Binarizer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;feature&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;binarized_feature&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setThreshold</span><span class="o">(</span><span class="mf">0.5</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">binarizedDataFrame</span> <span class="o">=</span> <span class="n">binarizer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">continuousDataFrame</span><span class="o">);</span>

<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Binarizer output with Threshold = &quot;</span> <span class="o">+</span> <span class="n">binarizer</span><span class="o">.</span><span class="na">getThreshold</span><span class="o">());</span>
<span class="n">binarizedDataFrame</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.Binarizer">Binarizer Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">Binarizer</span>

<span class="n">continuousDataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;feature&quot;</span><span class="p">])</span>

<span class="n">binarizer</span> <span class="o">=</span> <span class="n">Binarizer</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;feature&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;binarized_feature&quot;</span><span class="p">)</span>

<span class="n">binarizedDataFrame</span> <span class="o">=</span> <span class="n">binarizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">continuousDataFrame</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Binarizer output with Threshold = </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">binarizer</span><span class="o">.</span><span class="n">getThreshold</span><span class="p">())</span>
<span class="n">binarizedDataFrame</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/binarizer_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="pca">PCA (主成分分析)</h2>

        <p><a href="http://en.wikipedia.org/wiki/Principal_component_analysis">PCA</a>是使用正交变换将可能相关变量的一组观察值转换为称为主成分的线性不相关变量的值的一组统计过程。
            <a href="api/scala/index.html#org.apache.spark.ml.feature.PCA">PCA</a>
            类训练使用 PCA 将向量投影到低维空间的模型。下面的例子显示了如何将5维特征向量投影到3维主成分中。
        </p>

        <p><strong>有关API的更多详细信息，请参阅</strong></p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.PCA">PCA Scala 文档</a>。
                    </p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.PCA</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span>
  <span class="nc">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mf">7.0</span><span class="o">))),</span>
  <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">,</span> <span class="mf">4.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">),</span>
  <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">6.0</span><span class="o">,</span> <span class="mf">7.0</span><span class="o">)</span>
<span class="o">)</span>
<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="nc">Tuple1</span><span class="o">.</span><span class="n">apply</span><span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">pca</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">PCA</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;pcaFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setK</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>

<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;pcaFeatures&quot;</span><span class="o">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
+-----------------------------------------------------------+
|pcaFeatures                                                |
+-----------------------------------------------------------+
|[1.6485728230883807,-4.013282700516296,-5.524543751369388] |
|[-4.645104331781534,-1.1167972663619026,-5.524543751369387]|
|[-6.428880535676489,-5.337951427775355,-5.524543751369389] |
+-----------------------------------------------------------+
 </pre></div>
                <div><small>在Spark repo中的"examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala" 中找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>在Spark repo中的<a href="api/java/org/apache/spark/ml/feature/PCA.html">PCA Java docs</a>
                    中找到完整的示例代码。</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.PCA</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.PCAModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">sparse</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">1</span><span class="o">,</span> <span class="mi">3</span><span class="o">},</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[]{</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">7.0</span><span class="o">})),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">,</span> <span class="mf">4.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">6.0</span><span class="o">,</span> <span class="mf">7.0</span><span class="o">))</span>
<span class="o">);</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
<span class="o">});</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">PCAModel</span> <span class="n">pca</span> <span class="o">=</span> <span class="k">new</span> <span class="n">PCA</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;pcaFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setK</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;pcaFeatures&quot;</span><span class="o">);</span>
<span class="n">result</span><span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.PCA">PCA Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">)]),),</span>
        <span class="p">(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">]),),</span>
        <span class="p">(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">]),)]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;pcaFeatures&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;pcaFeatures&quot;</span><span class="p">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/pca_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="polynomialexpansion">PolynomialExpansion (多项式扩展)</h2>

        <p><a href="http://en.wikipedia.org/wiki/Polynomial_expansion">Polynomial expansion</a>
            （多项式展开）是将特征扩展为多项式空间的过程，多项式空间由原始维度的n度组合组成。
            <a href="api/scala/index.html#org.apache.spark.ml.feature.PolynomialExpansion">PolynomialExpansion</a>
            类提供此功能。 下面的例子显示了如何将您的功能扩展到3度多项式空间;</p>
           <p> 设置度的大小 >=2 当设置为1时相当于和原来的那个向量列相同，没有展开。
            </p>

        <p><strong>有关API的更多详细信息，请参阅</strong></p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.PolynomialExpansion">PolynomialExpansion Scala 文档</a>。
                    </p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.PolynomialExpansion</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span>
  <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">3.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">)</span>
<span class="o">)</span>
<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="nc">Tuple1</span><span class="o">.</span><span class="n">apply</span><span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">polyExpansion</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">PolynomialExpansion</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;polyFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setDegree</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>

<span class="k">val</span> <span class="n">polyDF</span> <span class="k">=</span> <span class="n">polyExpansion</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>
<span class="n">polyDF</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
+----------+------------------------------------------+
|features  |polyFeatures                              |
+----------+------------------------------------------+
|[2.0,1.0] |[2.0,4.0,8.0,1.0,2.0,4.0,1.0,2.0,1.0]     |
|[0.0,0.0] |[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]     |
|[3.0,-1.0]|[3.0,9.0,27.0,-1.0,-3.0,-9.0,1.0,3.0,-1.0]|
+----------+------------------------------------------+

</pre></div>
                <div><small>在Spark repo中的"examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala" 中找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/PolynomialExpansion.html">PolynomialExpansion Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.PolynomialExpansion</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">PolynomialExpansion</span> <span class="n">polyExpansion</span> <span class="o">=</span> <span class="k">new</span> <span class="n">PolynomialExpansion</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;polyFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setDegree</span><span class="o">(</span><span class="mi">3</span><span class="o">);</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">3.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">))</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">polyDF</span> <span class="o">=</span> <span class="n">polyExpansion</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>
<span class="n">polyDF</span><span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.PolynomialExpansion">PolynomialExpansion Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">PolynomialExpansion</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">]),)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">polyExpansion</span> <span class="o">=</span> <span class="n">PolynomialExpansion</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;polyFeatures&quot;</span><span class="p">)</span>
<span class="n">polyDF</span> <span class="o">=</span> <span class="n">polyExpansion</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">polyDF</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/polynomial_expansion_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="discrete-cosine-transform-dct">Discrete Cosine Transform (DCT 离散余弦变换)</h2>

        <p><a href="https://en.wikipedia.org/wiki/Discrete_cosine_transform">Discrete Cosine
            Transform</a>
            对向量列应用离散余弦变换(DCT);是将时域的N维实数序列转换成频域的N维实数序列的过程（有点类似离散傅里叶变换）。
            <a href="api/scala/index.html#org.apache.spark.ml.feature.DCT">DCT</a>类提供了离散余弦变换
            <a href="https://en.wikipedia.org/wiki/Discrete_cosine_transform#DCT-II">DCT-II</a>
            的功能，将离散余弦变换后结果乘以 $1/\sqrt{2}$ 得到一个与时域矩阵长度一致的矩阵。没有偏移被应用于变换的序列（例如，变换的序列的第00个元素是第00个DCT系数，
            而不是第 $N/2$个)，即输入序列与输出之间是一一对应的。</p>

        <p><strong>示例</strong></p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.DCT">DCT Scala 文档</a>。
                    </p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.DCT</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">),</span>
  <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">4.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">7.0</span><span class="o">),</span>
  <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">14.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">5.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">))</span>

<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="nc">Tuple1</span><span class="o">.</span><span class="n">apply</span><span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">dct</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DCT</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;featuresDCT&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setInverse</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="n">dctDf</span> <span class="k">=</span> <span class="n">dct</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>
<span class="n">dctDf</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;featuresDCT&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
+----------------------------------------------------------------+
|featuresDCT                                                     |
+----------------------------------------------------------------+
|[1.0,-1.1480502970952693,2.0000000000000004,-2.7716385975338604]|
|[-1.0,3.378492794482933,-7.000000000000001,2.9301512653149677]  |
|[4.0,9.304453421915744,11.000000000000002,1.5579302036357163]   |
+----------------------------------------------------------------+
</pre></div>
                <div><small>在Spark repo中的 "examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala" 中找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/DCT.html">DCT Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.DCT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">4.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">7.0</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">14.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">5.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">))</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">DCT</span> <span class="n">dct</span> <span class="o">=</span> <span class="k">new</span> <span class="n">DCT</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;featuresDCT&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setInverse</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dctDf</span> <span class="o">=</span> <span class="n">dct</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>

<span class="n">dctDf</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;featuresDCT&quot;</span><span class="o">).</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.DCT">DCT Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">DCT</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">14.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),)],</span> <span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">dct</span> <span class="o">=</span> <span class="n">DCT</span><span class="p">(</span><span class="n">inverse</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;featuresDCT&quot;</span><span class="p">)</span>

<span class="n">dctDf</span> <span class="o">=</span> <span class="n">dct</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">dctDf</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;featuresDCT&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/dct_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="stringindexer">StringIndexer (字符索引转换)</h2>

        <p><code>StringIndexer</code>（字符串-索引变换）将标签的字符串列变成标签索引列。标签索引序列的取值范围是 <code>[0, numLabels)</code>
            ,并且支持四个排序选项：
            &#8220;frequencyDesc&#8221;: 按标签频率降序（最频繁标签分配0）,
            &#8220;frequencyAsc&#8221;:  按标签频率升序（最不频繁的标签分配0,
            &#8220;alphabetDesc&#8221;: 降序字母顺序和 &#8220;alphabetAsc&#8221;: 升序字母顺序（默认=“frequencyDesc”）。
            如果用户选择保留它们 (setHandleInvalid("keep"))，
            那么看不见的标签将被放在索引numLabels上。如果输入列是数字，我们将其转换为字符串并索引字符串值。当下游管道组件
            （例如<code>Estimator</code> 或
            <code>Transformer</code>使用此字符串索引标签）时，必须将组件的输入列设置为此字符串索引列名称。在许多情况下，
            您可以使用设置输入列<code>setInputCol</code>。</p>

        <p><strong>示例</strong></p>

        <p>假设我们有如下的 DataFrame ，包含有 <code>id</code> and <code>category</code>两列:</p>

        <pre><code> id | category
----|----------
 0  | a
 1  | b
 2  | c
 3  | a
 4  | a
 5  | c
</code></pre>

        <p><code>category</code>是一个字符串列有3种取值的标签: &#8220;a&#8221;, &#8220;b&#8221;, and &#8220;c&#8221;。
            使用 <code>category</code> 作为 <code>StringIndexer</code> 的输入列和 <code>categoryIndex</code> 作为输出列,我们可以得到以下结果:</p>

        <pre><code> id | category | categoryIndex
----|----------|---------------
 0  | a        | 0.0
 1  | b        | 2.0
 2  | c        | 1.0
 3  | a        | 0.0
 4  | a        | 0.0
 5  | c        | 1.0
</code></pre>

        <p>&#8220;a&#8221;因为出现的次数最多，所以得到为 0 的索引（index）, 第二多的"c"得到 1 的索引，"b"得到 2 的索引.

            </p>

        <p>另外,<code>StringIndexer</code>在一个数据集上拟合然后使用它来转换另一个数据集时 (indexer.fit(df).transform(df2))，有三种策略可以处理未知的标签：</p>
        <ul>
            <li>抛出异常（这是默认值）</li>
            <li>完全跳过包含未知的标签的行</li>
            <li>将未知的标签放在索引numLabels的附加存储桶中()</li>
        </ul>

        <p><strong>示例</strong></p>

        <p>让我们回到之前的示例，但这次重用我们之前
            <code>StringIndexer</code> 在以下数据集上定义的内容：</p>

        <pre><code> id | category
----|----------
 0  | a
 1  | b
 2  | c
 3  | d
 4  | e
</code></pre>

        <p>如果没有在<code>StringIndexer</code> 里面设置未训练过（unseen）的标签的处理或者设置为"error",运行时会遇到程序抛出异常.当然，也可以通过设置
            <code>setHandleInvalid("skip")</code>, 得到如下的结果:</p>

        <pre><code> id | category | categoryIndex
----|----------|---------------
 0  | a        | 0.0
 1  | b        | 2.0
 2  | c        | 1.0
</code></pre>

        <p>注意：输出里面没有出现 "d" 或者 "e"。</p>

        <p>如果我们调用<code>setHandleInvalid("keep")</code>, 则将生成以下数据集：</p>

        <pre><code> id | category | categoryIndex
----|----------|---------------
 0  | a        | 0.0
 1  | b        | 2.0
 2  | c        | 1.0
 3  | d        | 3.0
 4  | e        | 3.0
</code></pre>

        <p>请注意，包含"d"或"e"的行映射到索引"3.0"。</p>

        <div class="codetabs">

            <div data-lang="scala">

                <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.StringIndexer">StringIndexer Scala 文档</a>。
                    </p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.StringIndexer</span>

<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span>
  <span class="nc">Seq</span><span class="o">((</span><span class="mi">0</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span> <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">),</span> <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span> <span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span> <span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">))</span>
<span class="o">).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;category&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">indexer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StringIndexer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;category&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;categoryIndex&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">indexed</span> <span class="k">=</span> <span class="n">indexer</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>
<span class="n">indexed</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
+---+--------+-------------+
| id|category|categoryIndex|
+---+--------+-------------+
|  0|       a|          0.0|
|  1|       b|          2.0|
|  2|       c|          1.0|
|  3|       a|          0.0|
|  4|       a|          0.0|
|  5|       c|          1.0|
+---+--------+-------------+
</pre></div>
                <div><small>在Spark repo中的"examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala" 中找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/StringIndexer.html">StringIndexer Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.StringIndexer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="kn">import static</span> <span class="nn">org.apache.spark.sql.types.DataTypes.*</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;category&quot;</span><span class="o">,</span> <span class="n">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">StringIndexer</span> <span class="n">indexer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StringIndexer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;category&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;categoryIndex&quot;</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">indexed</span> <span class="o">=</span> <span class="n">indexer</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>
<span class="n">indexed</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.StringIndexer">StringIndexer Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">StringIndexer</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">)],</span>
    <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;category&quot;</span><span class="p">])</span>

<span class="n">indexer</span> <span class="o">=</span> <span class="n">StringIndexer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;category&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;categoryIndex&quot;</span><span class="p">)</span>
<span class="n">indexed</span> <span class="o">=</span> <span class="n">indexer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">indexed</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/string_indexer_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="indextostring">IndexToString (索引-字符串变换)</h2>

        <p>与 <code>StringIndexer</code> 对应, <code>IndexToString</code>将索引化标签还原成原始字符串.
            一个常用的场景是先通过<code>StringIndexer</code>产生索引化标签，然后使用索引化标签进行训练，最后再对预测结果使用<code>IndexToString</code>
            来获取其原始的标签字符串。
        </p>

        <p><strong>示例</strong></p>

        <p>在<code>StringIndexer</code> 示例的基础上，我们假设我们有以下DataFrame,包含 <code>id</code> 和 <code>categoryIndex</code>两列:</p>

        <pre><code> id | categoryIndex
----|---------------
 0  | 0.0
 1  | 2.0
 2  | 1.0
 3  | 0.0
 4  | 0.0
 5  | 1.0
</code></pre>

        <p><code>IndexToString</code> 使用 <code>categoryIndex</code> 作为输入列,
            <code>originalCategory</code> 作为输出列, 我们能找回我们原来的标签（它们将从列的元数据来推断）：</p>

        <pre><code> id | categoryIndex | originalCategory
----|---------------|-----------------
 0  | 0.0           | a
 1  | 2.0           | b
 2  | 1.0           | c
 3  | 0.0           | a
 4  | 0.0           | a
 5  | 1.0           | c
</code></pre>

        <div class="codetabs">
            <div data-lang="scala">

                <p>有关API的更多详细信息，请参阅 <a href="api/scala/index.html#org.apache.spark.ml.feature.IndexToString">IndexToString Scala 文档</a>。
                    </p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.attribute.Attribute</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.</span><span class="o">{</span><span class="nc">IndexToString</span><span class="o">,</span> <span class="nc">StringIndexer</span><span class="o">}</span>

<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="s">&quoquot;c&quot;</span><span class="o">)</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;category&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">indexer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StringIndexer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;category&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;categoryIndex&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>
<span class="k">val</span> <span class="n">indexed</span> <span class="k">=</span> <span class="n">indexer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>

<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Transformed string column &#39;</span><span class="si">${</span><span class="n">indexer</span><span class="o">.</span><span class="n">getInputCol</span><span class="si">}</span><span class="s">&#39; &quot;</span> <span class="o">+</span>
    <span class="s">s&quot;to indexed column &#39;</span><span class="si">${</span><span class="n">indexer</span><span class="o">.</span><span class="n">getOutputCol</span><span class="si">}</span><span class="s">&#39;&quot;</span><span class="o">)</span>
<span class="n">indexed</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>

<span class="k">val</span> <span class="n">inputColSchema</span> <span class="k">=</span> <span class="n">indexed</span><span class="o">.</span><span class="n">schema</span><span class="o">(</span><span class="n">indexer</span><span class="o">.</span><span class="n">getOutputCol</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">s&quot;StringIndexer will store labels in output column metadata: &quot;</span> <span class="o">+</span>
    <span class="s">s&quot;</span><span class="si">${</span><span class="nc">Attribute</span><span class="o">.</span><span class="n">fromStructField</span><span class="o">(</span><span class="n">inputColSchema</span><span class="o">).</span><span class="n">toString</span><span class="si">}</span><span class="s">\n&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">IndexToString</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;categoryIndex&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;originalCategory&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">converted</span> <span class="k">=</span> <span class="n">converter</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">indexed</span><span class="o">)</span>

<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Transformed indexed column &#39;</span><span class="si">${</span><span class="n">converter</span><span class="o">.</span><span class="n">getInputCol</span><span class="si">}</span><span class="s">&#39; back to original string &quot;</span> <span class="o">+</span>
    <span class="s">s&quot;column &#39;</span><span class="si">${</span><span class="n">converter</span><span class="o">.</span><span class="n">getOutputCol</span><span class="si">}</span><span class="s">&#39; using labels in metadata&quot;</span><span class="o">)</span>
<span class="n">converted</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;categoryIndex&quot;</span><span class="o">,</span> <span class="s">&quot;originalCategory&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala" in the Spark repo.</small></div>

            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/IndexToString.html">IndexToString Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.attribute.Attribute</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.IndexToString</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.StringIndexer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.StringIndexerModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;category&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">StringIndexerModel</span> <span class="n">indexer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StringIndexer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;category&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;categoryIndex&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">indexed</span> <span class="o">=</span> <span class="n">indexer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>

<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Transformed string column &#39;&quot;</span> <span class="o">+</span> <span class="n">indexer</span><span class="o">.</span><span class="na">getInputCol</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot;&#39; &quot;</span> <span class="o">+</span>
    <span class="s">&quot;to indexed column &#39;&quot;</span> <span class="o">+</span> <span class="n">indexer</span><span class="o">.</span><span class="na">getOutputCol</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot;&#39;&quot;</span><span class="o">);</span>
<span class="n">indexed</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>

<span class="n">StructField</span> <span class="n">inputColSchema</span> <span class="o">=</span> <span class="n">indexed</span><span class="o">.</span><span class="na">schema</span><span class="o">().</span><span class="na">apply</span><span class="o">(</span><span class="n">indexer</span><span class="o">.</span><span class="na">getOutputCol</span><span class="o">());</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;StringIndexer will store labels in output column metadata: &quot;</span> <span class="o">+</span>
    <span class="n">Attribute</span><span class="o">.</span><span class="na">fromStructField</span><span class="o">(</span><span class="n">inputColSchema</span><span class="o">).</span><span class="na">toString</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot;\n&quot;</span><span class="o">);</span>

<span class="n">IndexToString</span> <span class="n">converter</span> <span class="o">=</span> <span class="k">new</span> <span class="n">IndexToString</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;categoryIndex&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;originalCategory&quot;</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">converted</span> <span class="o">=</span> <span class="n">converter</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">indexed</span><span class="o">);</span>

<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Transformed indexed column &#39;&quot;</span> <span class="o">+</span> <span class="n">converter</span><span class="o">.</span><span class="na">getInputCol</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot;&#39; back to &quot;</span> <span class="o">+</span>
    <span class="s">&quot;original string column &#39;&quot;</span> <span class="o">+</span> <span class="n">converter</span><span class="o">.</span><span class="na">getOutputCol</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot;&#39; using labels in metadata&quot;</span><span class="o">);</span>
<span class="n">converted</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;categoryIndex&quot;</span><span class="o">,</span> <span class="s">&quot;originalCategory&quot;</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java" in the Spark repo.</small></div>

            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.IndexToString">IndexToString Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">IndexToString</span><span class="p">,</span> <span class="n">StringIndexer</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">)],</span>
    <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;category&quot;</span><span class="p">])</span>

<span class="n">indexer</span> <span class="o">=</span> <span class="n">StringIndexer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;category&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;categoryIndex&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">indexer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">indexed</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Transformed string column &#39;</span><span class="si">%s</span><span class="s2">&#39; to indexed column &#39;</span><span class="si">%s</span><span class="s2">&#39;&quot;</span>
      <span class="o">%</span> <span class="p">(</span><span class="n">indexer</span><span class="o">.</span><span class="n">getInputCol</span><span class="p">(),</span> <span class="n">indexer</span><span class="o">.</span><span class="n">getOutputCol</span><span class="p">()))</span>
<span class="n">indexed</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;StringIndexer will store labels in output column metadata</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">converter</span> <span class="o">=</span> <span class="n">IndexToString</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;categoryIndex&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;originalCategory&quot;</span><span class="p">)</span>
<span class="n">converted</span> <span class="o">=</span> <span class="n">converter</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">indexed</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Transformed indexed column &#39;</span><span class="si">%s</span><span class="s2">&#39; back to original string column &#39;</span><span class="si">%s</span><span class="s2">&#39; using &quot;</span>
      <span class="s2">&quot;labels in metadata&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">converter</span><span class="o">.</span><span class="n">getInputCol</span><span class="p">(),</span> <span class="n">converter</span><span class="o">.</span><span class="n">getOutputCol</span><span class="p">()))</span>
<span class="n">converted</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;categoryIndex&quot;</span><span class="p">,</span> <span class="s2">&quot;originalCategory&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/index_to_string_example.py" in the Spark repo.</small></div>

            </div>
        </div>

        <h2 id="onehotencoder-deprecated-since-230">OneHotEncoder (独热编码 从2.3.0开始弃用)</h2>

        <p>因为现有的<code>OneHotEncoder</code>
            是无状态变换器,所以它不能用于新数据，其中类别的数量可能与训练数据不同。为了解决这个问题，我们创建了一个新的
            <code>OneHotEncoderEstimator</code>
            拟合可以产生<code>OneHotEncoderModel</code> 有关详细信息，请参阅<a href="https://issues.apache.org/jira/browse/SPARK-13030">SPARK-13030</a>。</p>

        <p><code>OneHotEncoder</code>已在2.3.0中弃用，将在3.0.0中删除。请改用<a href="ml-features.html#onehotencoderestimator">OneHotEncoderEstimator</a>。</p>

        <h2 id="onehotencoderestimator">OneHotEncoderEstimator (独热编码模型学习器)</h2>

        <p><a href="http://en.wikipedia.org/wiki/One-hot">One-hot encoding</a>将类别索引列映射到二进制向量列;
            将表示为标签索引的分类特征映射到二进制向量，该二进制向量具有至多单个一个值，该值表示所有特征值集合中存在特定特征值。
            此编码允许期望连续特征（例如Logistic回归）的算法使用分类特征。对于字符串类型输入数据，通常首先使用
            <a href="ml-features.html#stringindexer">StringIndexer</a>对分类特征进行编码。 </p>

        <p><code>OneHotEncoderEstimator</code>
            可以转换多个列，为每个输入列返回一个热编码的输出向量列。通常使用
            <a href="ml-features.html#vectorassembler">VectorAssembler</a>将这些向量合并为单个特征向量。</p>

        <p><code>OneHotEncoderEstimator</code> 支持 <code>handleInvalid</code>
            参数，以选择如何在转换数据的过程中处理无效输入。 可用选项包括 "保留" (任何无效输入都分配给额外的分类索引) 和 "错误" (抛出错误)。</p>

        <p><strong>示例</strong></p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.OneHotEncoderEstimator">OneHotEncoderEstimator Scala 文档</a>。</p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.OneHotEncoderEstimator</span>

<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;categoryIndex1&quot;</span><span class="o">,</span> <span class="s">&quot;categoryIndex2&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">encoder</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">OneHotEncoderEstimator</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;categoryIndex1&quot;</span><span class="o">,</span> <span class="s">&quot;categoryIndex2&quot;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">setOutputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;categoryVec1&quot;</span><span class="o">,</span> <span class="s">&quot;categoryVec2&quot;</span><span class="o">))</span>
<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>

<span class="k">val</span> <span class="n">encoded</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>
<span class="n">encoded</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
                <div><small>在Spark repo中的 "examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderEstimatorExample.scala" 中找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/OneHotEncoderEstimator.html">OneHotEncoderEstimator Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.OneHotEncoderEstimator</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.OneHotEncoderModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)</span>
<span class="o">);</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;categoryIndex1&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;categoryIndex2&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">OneHotEncoderEstimator</span> <span class="n">encoder</span> <span class="o">=</span> <span class="k">new</span> <span class="n">OneHotEncoderEstimator</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]</span> <span class="o">{</span><span class="s">&quot;categoryIndex1&quot;</span><span class="o">,</span> <span class="s">&quot;categoryIndex2&quot;</span><span class="o">})</span>
  <span class="o">.</span><span class="na">setOutputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]</span> <span class="o">{</span><span class="s">&quot;categoryVec1&quot;</span><span class="o">,</span> <span class="s">&quot;categoryVec2&quot;</span><span class="o">});</span>

<span class="n">OneHotEncoderModel</span> <span class="n">model</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">encoded</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>
<span class="n">encoded</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderEstimatorExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.OneHotEncoderEstimator">OneHotEncoderEstimator Python docs</a> for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">OneHotEncoderEstimator</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;categoryIndex1&quot;</span><span class="p">,</span> <span class="s2">&quot;categoryIndex2&quot;</span><span class="p">])</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">OneHotEncoderEstimator</span><span class="p">(</span><span class="n">inputCols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;categoryIndex1&quot;</span><span class="p">,</span> <span class="s2">&quot;categoryIndex2&quot;</span><span class="p">],</span>
                                 <span class="n">outputCols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;categoryVec1&quot;</span><span class="p">,</span> <span class="s2">&quot;categoryVec2&quot;</span><span class="p">])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">encoded</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">encoded</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/onehot_encoder_estimator_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="vectorindexer">VectorIndexer (向量索引转换)</h2>

        <p><code>VectorIndexer</code>
            可以帮助指定向量数据集中的分类特征.它可以自动确定哪些特征 (features)是类别，并将原始值转换为类别索引。具体来说，它执行以下操作：
        </p>

        <ol>
            <li>取一个<a href="api/scala/index.html#org.apache.spark.ml.linalg.Vector">Vector</a>类型的输入列和一个参数<code>maxCategories</code>。</li>
            <li>根据不同值的数量确定哪些功能应分类，其中最多 <code>maxCategories</code> 的特征被声明为分类。</li>
            <li>为每个分类特征计算基于0的类别索引。</li>
            <li>索引分类特征并将原始特征值转换为索引。</li>
        </ol>

        <p>
            索引分类功能允许诸如决策树和树组合之类的算法适当地处理分类特征，提高性能</p>

        <p><strong>示例</strong></p>

        <p>在下面的示例中，我们读取标注点的数据集，然后使用 <code>VectorIndexer</code>
            来确定哪些功能应被视为分类。我们将分类特征值转换为其索引。然后，该转换的数据可以传递给诸如
            <code>DecisionTreeRegressor</code> 之类的算法来处理分类特征。</p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.VectorIndexer">VectorIndexer Scala 文档</a>。
                    </p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.VectorIndexer</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;libsvm&quot;</span><span class="o">).</span><span class="n">load</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">indexer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">VectorIndexer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;indexed&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setMaxCategories</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>

<span class="k">val</span> <span class="n">indexerModel</span> <span class="k">=</span> <span class="n">indexer</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="k">val</span> <span class="n">categoricalFeatures</span><span class="k">:</span> <span class="kt">Set</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="n">indexerModel</span><span class="o">.</span><span class="n">categoryMaps</span><span class="o">.</span><span class="n">keys</span><span class="o">.</span><span class="n">toSet</span>
<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Chose </span><span class="si">${</span><span class="n">categoricalFeatures</span><span class="o">.</span><span class="n">size</span><span class="si">}</span><span class="s"> &quot;</span> <span class="o">+</span>
  <span class="s">s&quot;categorical features: </span><span class="si">${</span><span class="n">categoricalFeatures</span><span class="o">.</span><span class="n">mkString</span><span class="o">(</span><span class="s">&quot;, &quot;</span><span class="o">)</span><span class="si">}</span><span class="s">&quot;</span><span class="o">)</span>

<span class="c1">// Create new column &quot;indexed&quot; with categorical values transformed to indices</span>
<span class="k">val</span> <span class="n">indexedData</span> <span class="k">=</span> <span class="n">indexerModel</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="n">indexedData</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
                <div><small>在Spark repo中的 "examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala" 中找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/VectorIndexer.html">VectorIndexer Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Map</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.VectorIndexer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.VectorIndexerModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">read</span><span class="o">().</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;libsvm&quot;</span><span class="o">).</span><span class="na">load</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="o">);</span>

<span class="n">VectorIndexer</span> <span class="n">indexer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">VectorIndexer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;indexed&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setMaxCategories</span><span class="o">(</span><span class="mi">10</span><span class="o">);</span>
<span class="n">VectorIndexerModel</span> <span class="n">indexerModel</span> <span class="o">=</span> <span class="n">indexer</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">data</span><span class="o">);</span>

<span class="n">Map</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">Double</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">categoryMaps</span> <span class="o">=</span> <span class="n">indexerModel</span><span class="o">.</span><span class="na">javaCategoryMaps</span><span class="o">();</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">print</span><span class="o">(</span><span class="s">&quot;Chose &quot;</span> <span class="o">+</span> <span class="n">categoryMaps</span><span class="o">.</span><span class="na">size</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot; categorical features:&quot;</span><span class="o">);</span>

<span class="k">for</span> <span class="o">(</span><span class="n">Integer</span> <span class="n">feature</span> <span class="o">:</span> <span class="n">categoryMaps</span><span class="o">.</span><span class="na">keySet</span><span class="o">())</span> <span class="o">{</span>
  <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">print</span><span class="o">(</span><span class="s">&quot; &quot;</span> <span class="o">+</span> <span class="n">feature</span><span class="o">);</span>
<span class="o">}</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">();</span>

<span class="c1">// Create new column &quot;indexed&quot; with categorical values transformed to indices</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">indexedData</span> <span class="o">=</span> <span class="n">indexerModel</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">data</span><span class="o">);</span>
<span class="n">indexedData</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.VectorIndexer">VectorIndexer Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">VectorIndexer</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;libsvm&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="p">)</span>

<span class="n">indexer</span> <span class="o">=</span> <span class="n">VectorIndexer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;indexed&quot;</span><span class="p">,</span> <span class="n">maxCategories</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">indexerModel</span> <span class="o">=</span> <span class="n">indexer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">categoricalFeatures</span> <span class="o">=</span> <span class="n">indexerModel</span><span class="o">.</span><span class="n">categoryMaps</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Chose </span><span class="si">%d</span><span class="s2"> categorical features: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span>
      <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">categoricalFeatures</span><span class="p">),</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">categoricalFeatures</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>

<span class="c1"># Create new column &quot;indexed&quot; with categorical values transformed to indices</span>
<span class="n">indexedData</span> <span class="o">=</span> <span class="n">indexerModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">indexedData</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/vector_indexer_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="interaction">Interaction （相互作用）</h2>

        <p><code>Interaction</code> 是一个 <code>Transformer</code>
            它采用向量或double值列，并生成一个单个向量列，其中包含来自每个输入列的一个值的所有组合的乘积。
        </p>

        <p>
            例如，如果您有2个向量类型的列，每个列具有3个维度作为输入列，那么您将获得一个9维向量作为输出列。   </p>

        <p><strong>示例</strong></p>

        <p>
            假设我们有如下DataFrame，列为“id1”, “vec1” 和 “vec2”:
        </p>

        <pre><code>  id1|vec1          |vec2
  ---|--------------|--------------
  1  |[1.0,2.0,3.0] |[8.0,4.0,5.0] 
  2  |[4.0,3.0,8.0] |[7.0,9.0,8.0] 
  3  |[6.0,1.0,9.0] |[2.0,3.0,6.0] 
  4  |[10.0,8.0,6.0]|[9.0,4.0,5.0] 
  5  |[9.0,2.0,7.0] |[10.0,7.0,3.0]
  6  |[1.0,1.0,4.0] |[2.0,8.0,4.0]     
</code></pre>

        <p>对这些输入列<code></code>使用 <code>Interaction</code>,
            然后 <code>interactedCol</code> 作为交互后的输出列:</p>

        <pre><code>  id1|vec1          |vec2          |interactedCol
  ---|--------------|--------------|------------------------------------------------------
  1  |[1.0,2.0,3.0] |[8.0,4.0,5.0] |[8.0,4.0,5.0,16.0,8.0,10.0,24.0,12.0,15.0]            
  2  |[4.0,3.0,8.0] |[7.0,9.0,8.0] |[56.0,72.0,64.0,42.0,54.0,48.0,112.0,144.0,128.0]     
  3  |[6.0,1.0,9.0] |[2.0,3.0,6.0] |[36.0,54.0,108.0,6.0,9.0,18.0,54.0,81.0,162.0]        
  4  |[10.0,8.0,6.0]|[9.0,4.0,5.0] |[360.0,160.0,200.0,288.0,128.0,160.0,216.0,96.0,120.0]
  5  |[9.0,2.0,7.0] |[10.0,7.0,3.0]|[450.0,315.0,135.0,100.0,70.0,30.0,350.0,245.0,105.0] 
  6  |[1.0,1.0,4.0] |[2.0,8.0,4.0] |[12.0,48.0,24.0,12.0,48.0,24.0,48.0,192.0,96.0]       
</code></pre>

        <div class="codetabs">
            <div data-lang="scala">

                <p>有关API的更多详细信息，请参阅交互式<a href="api/scala/index.html#org.apache.spark.ml.feature.Interaction">Interaction Scala 文档</a>。
                    </p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.Interaction</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.VectorAssembler</span>

<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">8</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">5</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">8</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="mi">9</span><span class="o">,</span> <span class="mi">8</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mi">6</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">9</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">6</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="mi">8</span><span class="o">,</span> <span class="mi">6</span><span class="o">,</span> <span class="mi">9</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">5</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">9</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="mi">3</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">8</span><span class="o">,</span> <span class="mi">4</span><span class="o">)</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id1&quot;</span><span class="o">,</span> <span class="s">&quot;id2&quot;</span><span class="o">,</span> <span class="s">&quot;id3&quot;</span><span class="o">,</span> <span class="s">&quot;id4&quot;</span><span class="o">,</span> <span class="s">&quot;id5&quot;</span><span class="o">,</span> <span class="s">&quot;id6&quot;</span><span class="o">,</span> <span class="s">&quot;id7&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">assembler1</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">VectorAssembler</span><span class="o">().</span>
  <span class="n">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;id2&quot;</span><span class="o">,</span> <span class="s">&quot;id3&quot;</span><span class="o">,</span> <span class="s">&quot;id4&quot;</span><span class="o">)).</span>
  <span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;vec1&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">assembled1</span> <span class="k">=</span> <span class="n">assembler1</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>

<span class="k">val</span> <span class="n">assembler2</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">VectorAssembler</span><span class="o">().</span>
  <span class="n">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;id5&quot;</span><span class="o">,</span> <span class="s">&quot;id6&quot;</span><span class="o">,</span> <span class="s">&quot;id7&quot;</span><span class="o">)).</span>
  <span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;vec2&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">assembled2</span> <span class="k">=</span> <span class="n">assembler2</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">assembled1</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;id1&quot;</span><span class="o">,</span> <span class="s">&quot;vec1&quot;</span><span class="o">,</span> <span class="s">&quot;vec2&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">interaction</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Interaction</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;id1&quot;</span><span class="o">,</span> <span class="s">&quot;vec1&quot;</span><span class="o">,</span> <span class="s">&quot;vec2&quot;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;interactedCol&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">interacted</span> <span class="k">=</span> <span class="n">interaction</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">assembled2</span><span class="o">)</span>

<span class="n">interacted</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>
id1|vec1          |vec2          |interactedCol
  ---|--------------|--------------|------------------------------------------------------
  1  |[1.0,2.0,3.0] |[8.0,4.0,5.0] |[8.0,4.0,5.0,16.0,8.0,10.0,24.0,12.0,15.0]
  2  |[4.0,3.0,8.0] |[7.0,9.0,8.0] |[56.0,72.0,64.0,42.0,54.0,48.0,112.0,144.0,128.0]
  3  |[6.0,1.0,9.0] |[2.0,3.0,6.0] |[36.0,54.0,108.0,6.0,9.0,18.0,54.0,81.0,162.0]
  4  |[10.0,8.0,6.0]|[9.0,4.0,5.0] |[360.0,160.0,200.0,288.0,128.0,160.0,216.0
</pre></div>
                <div><small>在Spark repo中的"examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala"中查找完整示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/Interaction.html">Interaction Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">8</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">5</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">8</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="mi">9</span><span class="o">,</span> <span class="mi">8</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mi">6</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">9</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">6</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="mi">8</span><span class="o">,</span> <span class="mi">6</span><span class="o">,</span> <span class="mi">9</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">5</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">9</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="mi">3</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">8</span><span class="o">,</span> <span class="mi">4</span><span class="o">)</span>
<span class="o">);</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id1&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id2&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id3&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id4&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id5&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id6&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id7&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">VectorAssembler</span> <span class="n">assembler1</span> <span class="o">=</span> <span class="k">new</span> <span class="n">VectorAssembler</span><span class="o">()</span>
        <span class="o">.</span><span class="na">setInputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;id2&quot;</span><span class="o">,</span> <span class="s">&quot;id3&quot;</span><span class="o">,</span> <span class="s">&quot;id4&quot;</span><span class="o">})</span>
        <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;vec1&quot;</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">assembled1</span> <span class="o">=</span> <span class="n">assembler1</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>

<span class="n">VectorAssembler</span> <span class="n">assembler2</span> <span class="o">=</span> <span class="k">new</span> <span class="n">VectorAssembler</span><span class="o">()</span>
        <span class="o">.</span><span class="na">setInputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;id5&quot;</span><span class="o">,</span> <span class="s">&quot;id6&quot;</span><span class="o">,</span> <span class="s">&quot;id7&quot;</span><span class="o">})</span>
        <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;vec2&quot;</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">assembled2</span> <span class="o">=</span> <span class="n">assembler2</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">assembled1</span><span class="o">).</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;id1&quot;</span><span class="o">,</span> <span class="s">&quot;vec1&quot;</span><span class="o">,</span> <span class="s">&quot;vec2&quot;</span><span class="o">);</span>

<span class="n">Interaction</span> <span class="n">interaction</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Interaction</span><span class="o">()</span>
        <span class="o">.</span><span class="na">setInputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;id1&quot;</span><span class="o">,</span><span class="s">&quot;vec1&quot;</span><span class="o">,</span><span class="s">&quot;vec2&quot;</span><span class="o">})</span>
        <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;interactedCol&quot;</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">interacted</span> <span class="o">=</span> <span class="n">interaction</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">assembled2</span><span class="o">);</span>

<span class="n">interacted</span><span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="normalizer">Normalizer (范数p-norm规范化)</h2>

        <p><code>Normalizer</code>是一个 <code>Transformer</code> （转换器）
            它可以将一组特征向量（通过计算p-范数）规范化。
            参数为p（默认值：2）来指定规范化中使用的 <a href="http://en.wikipedia.org/wiki/Norm_%28mathematics%29#p-norm">p-norm</a>
            规范化操作可以使输入数据标准化，对后期机器学习算法的结果也有更好的表现。</p>

        <p><strong>示例</strong></p>

        <p>
            下面的例子展示如何读入一个libsvm格式的数据，然后将每一行转换为
            unit $L^1$ norm 和 unit $L^\infty$ norm.
        </p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>请参阅 <a href="api/scala/index.html#org.apache.spark.ml.feature.Normalizer">Normalizer Scala 文档</a>
                    了解相关的 API 的详细信息</p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.Normalizer</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="k">val</span> <span class="n">dataFrame</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.5</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="c1">// Normalize each Vector using $L^1$ norm.</span>
<span class="k">val</span> <span class="n">normalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Normalizer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;normFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setP</span><span class="o">(</span><span class="mf">1.0</span><span class="o">)</span>

<span class="k">val</span> <span class="n">l1NormData</span> <span class="k">=</span> <span class="n">normalizer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Normalized using L^1 norm&quot;</span><span class="o">)</span>
<span class="n">l1NormData</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>

<span class="c1">// Normalize each Vector using $L^\infty$ norm.</span>
<span class="k">val</span> <span class="n">lInfNormData</span> <span class="k">=</span> <span class="n">normalizer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">,</span> <span class="n">normalizer</span><span class="o">.</span><span class="n">p</span> <span class="o">-&gt;</span> <span class="nc">Double</span><span class="o">.</span><span class="nc">PositiveInfinity</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Normalized using L^inf norm&quot;</span><span class="o">)</span>
<span class="n">lInfNormData</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
Normalized using L^1 norm
+---+--------------+------------------+
| id|      features|      normFeatures|
+---+--------------+------------------+
|  0|[1.0,0.5,-1.0]|    [0.4,0.2,-0.4]|
|  1| [2.0,1.0,1.0]|   [0.5,0.25,0.25]|
|  2|[4.0,10.0,2.0]|[0.25,0.625,0.125]|
+---+--------------+------------------+

Normalized using L^inf norm
+---+--------------+--------------+
| id|      features|  normFeatures|
+---+--------------+--------------+
|  0|[1.0,0.5,-1.0]|[1.0,0.5,-1.0]|
|  1| [2.0,1.0,1.0]| [1.0,0.5,0.5]|
|  2|[4.0,10.0,2.0]| [0.4,1.0,0.2]|
+---+--------------+--------------+
</pre></div>
                <div><small>在Spark repo中 "examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala"里可以找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/Normalizer.html">Normalizer Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.Normalizer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">,</span> <span class="o">-</span><span class="mf">8.0</span><span class="o">)),</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">4.0</span><span class="o">)),</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">8.0</span><span class="o">))</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
    <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
    <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="c1">// Normalize each Vector using $L^1$ norm.</span>
<span class="n">Normalizer</span> <span class="n">normalizer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Normalizer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;normFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setP</span><span class="o">(</span><span class="mf">1.0</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">l1NormData</span> <span class="o">=</span> <span class="n">normalizer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">);</span>
<span class="n">l1NormData</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>

<span class="c1">// Normalize each Vector using $L^\infty$ norm.</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">lInfNormData</span> <span class="o">=</span>
  <span class="n">normalizer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">,</span> <span class="n">normalizer</span><span class="o">.</span><span class="na">p</span><span class="o">().</span><span class="na">w</span><span class="o">(</span><span class="n">Double</span><span class="o">.</span><span class="na">POSITIVE_INFINITY</span><span class="o">));</span>
<span class="n">lInfNormData</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.Normalizer">Normalizer Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">Normalizer</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>

<span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">]),)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="c1"># Normalize each Vector using $L^1$ norm.</span>
<span class="n">normalizer</span> <span class="o">=</span> <span class="n">Normalizer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;normFeatures&quot;</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">l1NormData</span> <span class="o">=</span> <span class="n">normalizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Normalized using L^1 norm&quot;</span><span class="p">)</span>
<span class="n">l1NormData</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Normalize each Vector using $L^\infty$ norm.</span>
<span class="n">lInfNormData</span> <span class="o">=</span> <span class="n">normalizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">,</span> <span class="p">{</span><span class="n">normalizer</span><span class="o">.</span><span class="n">p</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)})</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Normalized using L^inf norm&quot;</span><span class="p">)</span>
<span class="n">lInfNormData</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/normalizer_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="standardscaler">StandardScaler （标准化）</h2>

        <p><code>StandardScaler</code> 转换<code>Vector</code>行的数据集，通过使用对训练集中的样本的列汇总统计信息来消除平均值并缩放到单位方差，从而标准化特征。使每个要素标准化以具有单位标准偏差 和\或 零均值。它需要参数：
            </p>

        <ul>
            <li><code>withStd</code>: 默认为True。将数据缩放到单位标准偏差。</li>
            <li><code>withMean</code>: 默认为false。在缩放之前将数据中心为平均值。它将构建一个密集的输出，所以在应用于稀疏输入时要小心。</li>
        </ul>

        <p><code>StandardScaler</code> 是一个 <code>Estimator</code> 可以 <code>fit</code> 数据集产生 <code>StandardScalerModel</code>;
            这相当于计算汇总统计数据。  然后，模型可以将数据集中的向量列转换为具有单位标准偏差 和/或 零平均特征。</p>

        <p>
            请注意，如果特征的标准偏差为零，它将在该特征的向量中返回默认的0.0值。</p>

        <p><strong>示例</strong></p>

        <p>以下示例演示如何以libsvm格式加载数据集，然后将每个要素归一化以具有单位标准偏差。</p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.StandardScaler">StandardScaler Scala 文档</a>
                    了解相关的 API 的详细信息。</p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.StandardScaler</span>

<span class="k">val</span> <span class="n">dataFrame</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;libsvm&quot;</span><span class="o">).</span><span class="n">load</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">scaler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StandardScaler</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;scaledFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setWithStd</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setWithMean</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="c1">// Compute summary statistics by fitting the StandardScaler.</span>
<span class="k">val</span> <span class="n">scalerModel</span> <span class="k">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>

<span class="c1">// Normalize each feature to have unit standard deviation.</span>
<span class="k">val</span> <span class="n">scaledData</span> <span class="k">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>
<span class="n">scaledData</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
                <div><small>在Spark repo中路径"examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala"
                    里可以找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/StandardScaler.html">StandardScaler Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.StandardScaler</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.StandardScalerModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataFrame</span> <span class="o">=</span>
  <span class="n">spark</span><span class="o">.</span><span class="na">read</span><span class="o">().</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;libsvm&quot;</span><span class="o">).</span><span class="na">load</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="o">);</span>

<span class="n">StandardScaler</span> <span class="n">scaler</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StandardScaler</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;scaledFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setWithStd</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setWithMean</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>

<span class="c1">// Compute summary statistics by fitting the StandardScaler</span>
<span class="n">StandardScalerModel</span> <span class="n">scalerModel</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">);</span>

<span class="c1">// Normalize each feature to have unit standard deviation.</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">scaledData</span> <span class="o">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">);</span>
<span class="n">scaledData</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.StandardScaler">StandardScaler Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;libsvm&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="p">)</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;scaledFeatures&quot;</span><span class="p">,</span>
                        <span class="n">withStd</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">withMean</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Compute summary statistics by fitting the StandardScaler</span>
<span class="n">scalerModel</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">)</span>

<span class="c1"># Normalize each feature to have unit standard deviation.</span>
<span class="n">scaledData</span> <span class="o">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">)</span>
<span class="n">scaledData</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/standard_scaler_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="minmaxscaler">MinMaxScaler （最大-最小规范化）</h2>

        <p><code>MinMaxScaler</code> 转换Vector行的数据集，将每个特征的重新映射到特定范围
            （通常为[0，1]）。它需要参数：</p>

        <ul>
            <li><code>min</code>: 默认为0.0，转换后的下限</li>
            <li><code>max</code>: 默认为1.0，转换后的上限</li>
        </ul>

        <p><code>MinMaxScaler</code>
            计算数据集的统计信息，并生成
            <code>MinMaxScalerModel</code>。
            然后，模型可以单独转换每个特征，使其在给定的范围内。
        </p>

        <p>特征E的重新缩放值被计算为：
            <code>\begin{equation}
                Rescaled(e_i) = \frac{e_i - E_{min}}{E_{max} - E_{min}} * (max - min) + min
                \end{equation}</code>
            对于情况<code>$E_{max} == E_{min}$</code>, <code>$Rescaled(e_i) = 0.5 * (max + min)$</code></p>

        <p>
            请注意，由于零值可能会转换为非零值，即使对于稀疏输入，transformer 的输出也将为
            <code>DenseVector</code>。</p>

        <p><strong>示例</strong></p>

        <p>
            以下示例演示如何以libsvm格式加载数据集，然后将每个要素重新缩放为[0，1]。        </p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>请参阅 <a href="api/scala/index.html#org.apache.spark.ml.feature.MinMaxScaler">MinMaxScaler Scala 文档</a>
                    and the <a href="api/scala/index.html#org.apache.spark.ml.feature.MinMaxScalerModel">MinMaxScalerModel Scala 文档</a>
                    了解相关的 API 的详细信息。</p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.MinMaxScaler</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="k">val</span> <span class="n">dataFrame</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.1</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">3.0</span><span class="o">,</span> <span class="mf">10.1</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">scaler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MinMaxScaler</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;scaledFeatures&quot;</span><span class="o">)</span>

<span class="c1">// Compute summary statistics and generate MinMaxScalerModel</span>
<span class="k">val</span> <span class="n">scalerModel</span> <span class="k">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>

<span class="c1">// rescale each feature to range [min, max].</span>
<span class="k">val</span> <span class="n">scaledData</span> <span class="k">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Features scaled to range: [</span><span class="si">${</span><span class="n">scaler</span><span class="o">.</span><span class="n">getMin</span><span class="si">}</span><span class="s">, </span><span class="si">${</span><span class="n">scaler</span><span class="o">.</span><span class="n">getMax</span><span class="si">}</span><span class="s">]&quot;</span><span class="o">)</span>
<span class="n">scaledData</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;scaledFeatures&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
                <div><small>在Spark repo中路径 "examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala"
                    里可以找到完整的示例代码 。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/MinMaxScaler.html">MinMaxScaler Java docs</a>
                    and the <a href="api/java/org/apache/spark/ml/feature/MinMaxScalerModel.html">MinMaxScalerModel Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.MinMaxScaler</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.MinMaxScalerModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">)),</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.1</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)),</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">3.0</span><span class="o">,</span> <span class="mf">10.1</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">))</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
    <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
    <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">MinMaxScaler</span> <span class="n">scaler</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MinMaxScaler</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;scaledFeatures&quot;</span><span class="o">);</span>

<span class="c1">// Compute summary statistics and generate MinMaxScalerModel</span>
<span class="n">MinMaxScalerModel</span> <span class="n">scalerModel</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">);</span>

<span class="c1">// rescale each feature to range [min, max].</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">scaledData</span> <span class="o">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">);</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Features scaled to range: [&quot;</span> <span class="o">+</span> <span class="n">scaler</span><span class="o">.</span><span class="na">getMin</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot;, &quot;</span>
    <span class="o">+</span> <span class="n">scaler</span><span class="o">.</span><span class="na">getMax</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot;]&quot;</span><span class="o">);</span>
<span class="n">scaledData</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;scaledFeatures&quot;</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.MinMaxScaler">MinMaxScaler Python docs</a>
                    and the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.MinMaxScalerModel">MinMaxScalerModel Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>

<span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">10.1</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]),)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;scaledFeatures&quot;</span><span class="p">)</span>

<span class="c1"># Compute summary statistics and generate MinMaxScalerModel</span>
<span class="n">scalerModel</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">)</span>

<span class="c1"># rescale each feature to range [min, max].</span>
<span class="n">scaledData</span> <span class="o">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Features scaled to range: [</span><span class="si">%f</span><span class="s2">, </span><span class="si">%f</span><span class="s2">]&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">getMin</span><span class="p">(),</span> <span class="n">scaler</span><span class="o">.</span><span class="n">getMax</span><span class="p">()))</span>
<span class="n">scaledData</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="s2">&quot;scaledFeatures&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/min_max_scaler_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="maxabsscaler">MaxAbsScaler （绝对值标准化）</h2>

        <p><code>MaxAbsScaler</code> 转换Vector行的数据集，通过划分每个特征中的最大绝对值，将每个特征的重新映射到范围[-1,1]。 它不会使数据移动/居中，因此不会破坏任何稀疏性。</p>

        <p><code>MaxAbsScaler</code> 计算数据集的统计信息，并生成 <code>MaxAbsScalerModel</code>然后，模型可以将每个特征单独转换为范围[-1,1]。</p>

        <p><strong>示例</strong></p>

        <p>以下示例演示如何以libsvm格式加载数据集，然后将每个要素重新缩放为[-1,1]。</p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.MaxAbsScaler">MaxAbsScaler Scala 文档</a>
                    和 <a href="api/scala/index.html#org.apache.spark.ml.feature.MaxAbsScalerModel">MaxAbsScalerModel Scala 文档</a>
                    了解相关的 API 的详细信息。</p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.MaxAbsScaler</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="k">val</span> <span class="n">dataFrame</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">,</span> <span class="o">-</span><span class="mf">8.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">4.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">8.0</span><span class="o">))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">scaler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MaxAbsScaler</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;scaledFeatures&quot;</span><span class="o">)</span>

<span class="c1">// Compute summary statistics and generate MaxAbsScalerModel</span>
<span class="k">val</span> <span class="n">scalerModel</span> <span class="k">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>

<span class="c1">// rescale each feature to range [-1, 1]</span>
<span class="k">val</span> <span class="n">scaledData</span> <span class="k">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>
<span class="n">scaledData</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;scaledFeatures&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
+--------------+----------------+
|      features|  scaledFeatures|
+--------------+----------------+
|[1.0,0.1,-8.0]|[0.25,0.01,-1.0]|
|[2.0,1.0,-4.0]|  [0.5,0.1,-0.5]|
|[4.0,10.0,8.0]|   [1.0,1.0,1.0]|
+--------------+----------------+
</pre></div>
                <div><small>在Spark Repo中 "examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala" 里可以找到完整的示例代码 。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/MaxAbsScaler.html">MaxAbsScaler Java docs</a>
                    and the <a href="api/java/org/apache/spark/ml/feature/MaxAbsScalerModel.html">MaxAbsScalerModel Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.MaxAbsScaler</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.MaxAbsScalerModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">,</span> <span class="o">-</span><span class="mf">8.0</span><span class="o">)),</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">4.0</span><span class="o">)),</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">8.0</span><span class="o">))</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
    <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
    <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">MaxAbsScaler</span> <span class="n">scaler</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MaxAbsScaler</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;scaledFeatures&quot;</span><span class="o">);</span>

<span class="c1">// Compute summary statistics and generate MaxAbsScalerModel</span>
<span class="n">MaxAbsScalerModel</span> <span class="n">scalerModel</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">);</span>

<span class="c1">// rescale each feature to range [-1, 1].</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">scaledData</span> <span class="o">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">);</span>
<span class="n">scaledData</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;scaledFeatures&quot;</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.MaxAbsScaler">MaxAbsScaler Python docs</a>
                    and the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.MaxAbsScalerModel">MaxAbsScalerModel Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">MaxAbsScaler</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>

<span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">]),)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">MaxAbsScaler</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;scaledFeatures&quot;</span><span class="p">)</span>

<span class="c1"># Compute summary statistics and generate MaxAbsScalerModel</span>
<span class="n">scalerModel</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">)</span>

<span class="c1"># rescale each feature to range [-1, 1].</span>
<span class="n">scaledData</span> <span class="o">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">)</span>

<span class="n">scaledData</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="s2">&quot;scaledFeatures&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/max_abs_scaler_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="bucketizer">Bucketizer （分箱器）</h2>
        <p><code>Bucketizer</code>
            将一列连续的特征转换为特征 buckets（区间），buckets（区间）由用户指定。Bucketizer 需要一个参数：</p>

        <ul>
            <li><code>splits</code>:
                这是个将连续的特征转换为 buckets（区间）的参数. n+1次分割时，将产生n个 buckets（区间）。
                一个bucket（区间）通过范围 [x,y) 中 x , y 来定义除了最后一个 bucket 包含 y 值。
                Splits（分割）应该是严格递增的。 -inf, inf 之间的值必须明确提供来覆盖所有的 Double 值;
                另外,Double 值超出 splits（分割）指定的值将认为是错误的. 两个splits （拆分）的例子
                为 <code>Array(Double.NegativeInfinity, 0.0, 1.0, Double.PositiveInfinity)</code>
                以及<code>Array(0.0, 1.0, 2.0)</code>.</li>
        </ul>

        <p>请注意,如果你不知道目标列的上线和下限,则应将<code>Double.NegativeInfinity</code> 和 <code>Double.PositiveInfinity</code>
            添加为splits（分割）的边界,以防止 Bucketizer 界限出现异常。</p>

        <p>还请注意,你提供的 splits（分割）必须严格按照增加的顺序,即<code>s0 &lt; s1 &lt; s2 &lt; ... &lt; sn</code>.</p>

        <p>更多的细节可以查看 <a href="api/scala/index.html#org.apache.spark.ml.feature.Bucketizer">Bucketizer</a> 的API文档。</p>

        <p><strong>示例</strong></p>

        <p>下面这个例子演示了如何将包含 Doubles 的一列 bucketize （分箱）为另外一个索引列。</p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>请参阅 <a href="api/scala/index.html#org.apache.spark.ml.feature.Bucketizer">Bucketizer Scala 文档</a>
                    了解相关的 API 的详细信息。</p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.Bucketizer</span>

<span class="k">val</span> <span class="n">splits</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="nc">Double</span><span class="o">.</span><span class="nc">NegativeInfinity</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.5</span><span class="o">,</span> <span class="nc">Double</span><span class="o">.</span><span class="nc">PositiveInfinity</span><span class="o">)</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(-</span><span class="mf">999.9</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.3</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.2</span><span class="o">,</span> <span class="mf">999.9</span><span class="o">)</span>
<span class="k">val</span> <span class="n">dataFrame</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="nc">Tuple1</span><span class="o">.</span><span class="n">apply</span><span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">bucketizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Bucketizer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;bucketedFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setSplits</span><span class="o">(</span><span class="n">splits</span><span class="o">)</span>

<span class="c1">// Transform original data into its bucket index.</span>
<span class="k">val</span> <span class="n">bucketedData</span> <span class="k">=</span> <span class="n">bucketizer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>

<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Bucketizer output with </span><span class="si">${</span><span class="n">bucketizer</span><span class="o">.</span><span class="n">getSplits</span><span class="o">.</span><span class="n">length</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s"> buckets&quot;</span><span class="o">)</span>
<span class="n">bucketedData</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>

<span class="k">val</span> <span class="n">splitsArray</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span>
  <span class="nc">Array</span><span class="o">(</span><span class="nc">Double</span><span class="o">.</span><span class="nc">NegativeInfinity</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.5</span><span class="o">,</span> <span class="nc">Double</span><span class="o">.</span><span class="nc">PositiveInfinity</span><span class="o">),</span>
  <span class="nc">Array</span><span class="o">(</span><span class="nc">Double</span><span class="o">.</span><span class="nc">NegativeInfinity</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.3</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.3</span><span class="o">,</span> <span class="nc">Double</span><span class="o">.</span><span class="nc">PositiveInfinity</span><span class="o">))</span>

<span class="k">val</span> <span class="n">data2</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span>
  <span class="o">(-</span><span class="mf">999.9</span><span class="o">,</span> <span class="o">-</span><span class="mf">999.9</span><span class="o">),</span>
  <span class="o">(-</span><span class="mf">0.5</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="o">),</span>
  <span class="o">(-</span><span class="mf">0.3</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">0.2</span><span class="o">,</span> <span class="mf">0.4</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">999.9</span><span class="o">,</span> <span class="mf">999.9</span><span class="o">))</span>
<span class="k">val</span> <span class="n">dataFrame2</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="n">data2</span><span class="o">).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;features1&quot;</span><span class="o">,</span> <span class="s">&quot;features2&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">bucketizer2</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Bucketizer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;features1&quot;</span><span class="o">,</span> <span class="s">&quot;features2&quot;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">setOutputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;bucketedFeatures1&quot;</span><span class="o">,</span> <span class="s">&quot;bucketedFeatures2&quot;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">setSplitsArray</span><span class="o">(</span><span class="n">splitsArray</span><span class="o">)</span>

<span class="c1">// Transform original data into its bucket index.</span>
<span class="k">val</span> <span class="n">bucketedData2</span> <span class="k">=</span> <span class="n">bucketizer2</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataFrame2</span><span class="o">)</span>

<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Bucketizer output with [&quot;</span> <span class="o">+</span>
  <span class="s">s&quot;</span><span class="si">${</span><span class="n">bucketizer2</span><span class="o">.</span><span class="n">getSplitsArray</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">length</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s">, &quot;</span> <span class="o">+</span>
  <span class="s">s&quot;</span><span class="si">${</span><span class="n">bucketizer2</span><span class="o">.</span><span class="n">getSplitsArray</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">length</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s">] buckets for each input column&quot;</span><span class="o">)</span>
<span class="n">bucketedData2</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
                <div><small>在Spark repo中路径"examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala"
                    里可以找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/Bucketizer.html">Bucketizer Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.Bucketizer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="kt">double</span><span class="o">[]</span> <span class="n">splits</span> <span class="o">=</span> <span class="o">{</span><span class="n">Double</span><span class="o">.</span><span class="na">NEGATIVE_INFINITY</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.5</span><span class="o">,</span> <span class="n">Double</span><span class="o">.</span><span class="na">POSITIVE_INFINITY</span><span class="o">};</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(-</span><span class="mf">999.9</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(-</span><span class="mf">0.5</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(-</span><span class="mf">0.3</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">0.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">0.2</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">999.9</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">Bucketizer</span> <span class="n">bucketizer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Bucketizer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;bucketedFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setSplits</span><span class="o">(</span><span class="n">splits</span><span class="o">);</span>

<span class="c1">// Transform original data into its bucket index.</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">bucketedData</span> <span class="o">=</span> <span class="n">bucketizer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">);</span>

<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Bucketizer output with &quot;</span> <span class="o">+</span> <span class="o">(</span><span class="n">bucketizer</span><span class="o">.</span><span class="na">getSplits</span><span class="o">().</span><span class="na">length</span><span class="o">-</span><span class="mi">1</span><span class="o">)</span> <span class="o">+</span> <span class="s">&quot; buckets&quot;</span><span class="o">);</span>
<span class="n">bucketedData</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>

<span class="c1">// Bucketize multiple columns at one pass.</span>
<span class="kt">double</span><span class="o">[][]</span> <span class="n">splitsArray</span> <span class="o">=</span> <span class="o">{</span>
  <span class="o">{</span><span class="n">Double</span><span class="o">.</span><span class="na">NEGATIVE_INFINITY</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.5</span><span class="o">,</span> <span class="n">Double</span><span class="o">.</span><span class="na">POSITIVE_INFINITY</span><span class="o">},</span>
  <span class="o">{</span><span class="n">Double</span><span class="o">.</span><span class="na">NEGATIVE_INFINITY</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.3</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.3</span><span class="o">,</span> <span class="n">Double</span><span class="o">.</span><span class="na">POSITIVE_INFINITY</span><span class="o">}</span>
<span class="o">};</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data2</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(-</span><span class="mf">999.9</span><span class="o">,</span> <span class="o">-</span><span class="mf">999.9</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(-</span><span class="mf">0.5</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(-</span><span class="mf">0.3</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">0.2</span><span class="o">,</span> <span class="mf">0.4</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">999.9</span><span class="o">,</span> <span class="mf">999.9</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema2</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features1&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features2&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataFrame2</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data2</span><span class="o">,</span> <span class="n">schema2</span><span class="o">);</span>

<span class="n">Bucketizer</span> <span class="n">bucketizer2</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Bucketizer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]</span> <span class="o">{</span><span class="s">&quot;features1&quot;</span><span class="o">,</span> <span class="s">&quot;features2&quot;</span><span class="o">})</span>
  <span class="o">.</span><span class="na">setOutputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]</span> <span class="o">{</span><span class="s">&quot;bucketedFeatures1&quot;</span><span class="o">,</span> <span class="s">&quot;bucketedFeatures2&quot;</span><span class="o">})</span>
  <span class="o">.</span><span class="na">setSplitsArray</span><span class="o">(</span><span class="n">splitsArray</span><span class="o">);</span>
<span class="c1">// Transform original data into its bucket index.</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">bucketedData2</span> <span class="o">=</span> <span class="n">bucketizer2</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataFrame2</span><span class="o">);</span>

<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Bucketizer output with [&quot;</span> <span class="o">+</span>
  <span class="o">(</span><span class="n">bucketizer2</span><span class="o">.</span><span class="na">getSplitsArray</span><span class="o">()[</span><span class="mi">0</span><span class="o">].</span><span class="na">length</span><span class="o">-</span><span class="mi">1</span><span class="o">)</span> <span class="o">+</span> <span class="s">&quot;, &quot;</span> <span class="o">+</span>
  <span class="o">(</span><span class="n">bucketizer2</span><span class="o">.</span><span class="na">getSplitsArray</span><span class="o">()[</span><span class="mi">1</span><span class="o">].</span><span class="na">length</span><span class="o">-</span><span class="mi">1</span><span class="o">)</span> <span class="o">+</span> <span class="s">&quot;] buckets for each input column&quot;</span><span class="o">);</span>
<span class="n">bucketedData2</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.Bucketizer">Bucketizer Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">Bucketizer</span>

<span class="n">splits</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">),</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)]</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="o">-</span><span class="mf">999.9</span><span class="p">,),</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,),</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.0</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.2</span><span class="p">,),</span> <span class="p">(</span><span class="mf">999.9</span><span class="p">,)]</span>
<span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">bucketizer</span> <span class="o">=</span> <span class="n">Bucketizer</span><span class="p">(</span><span class="n">splits</span><span class="o">=</span><span class="n">splits</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;bucketedFeatures&quot;</span><span class="p">)</span>

<span class="c1"># Transform original data into its bucket index.</span>
<span class="n">bucketedData</span> <span class="o">=</span> <span class="n">bucketizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Bucketizer output with </span><span class="si">%d</span><span class="s2"> buckets&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">bucketizer</span><span class="o">.</span><span class="n">getSplits</span><span class="p">())</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">bucketedData</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/bucketizer_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="elementwiseproduct">ElementwiseProduct (Hadamard乘积)</h2>

        <p>ElementwiseProduct 将每个输入向量中乘以一个 weight（权重）向量，使用元素相乘的方法。 换句话来说,就是通过
            scalar multiplier （标量乘法）对数据集中的每一列进行缩放。这表示输入向量 v 和转换向量 w 通过 <a href="https://en.wikipedia.org/wiki/Hadamard_product_%28matrices%29">Hadamard product</a>
            （Hadamard积） 产生一个结果向量。</p>

        <p><code>\[ \begin{pmatrix}
            v_1 \\
            \vdots \\
            v_N
            \end{pmatrix} \circ \begin{pmatrix}
            w_1 \\
            \vdots \\
            w_N
            \end{pmatrix}
            = \begin{pmatrix}
            v_1 w_1 \\
            \vdots \\
            v_N w_N
            \end{pmatrix}
            \]</code></p>

        <p><strong>示例</strong></p>

        <p>下面例子展示如何通过转换向量的值来转换向量。</p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>请参阅 <a href="api/scala/index.html#org.apache.spark.ml.feature.ElementwiseProduct">ElementwiseProduct Scala 文档</a>
                    了解相关的 API 的详细信息。</p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.ElementwiseProduct</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="c1">// Create some vector data; also works for sparse vectors</span>
<span class="k">val</span> <span class="n">dataFrame</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">,</span> <span class="mf">6.0</span><span class="o">)))).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;vector&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">transformingVector</span> <span class="k">=</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">)</span>
<span class="k">val</span> <span class="n">transformer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ElementwiseProduct</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setScalingVec</span><span class="o">(</span><span class="n">transformingVector</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;vector&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;transformedVector&quot;</span><span class="o">)</span>

<span class="c1">// Batch transform the vectors to create new column:</span>
<span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
                <div><small>在Spark repo中 "examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala"
                    里可以找到完整的示例代码 。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/ElementwiseProduct.html">ElementwiseProduct Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.ArrayList</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.ElementwiseProduct</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="c1">// Create some vector data; also works for sparse vectors</span>
<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">,</span> <span class="mf">6.0</span><span class="o">))</span>
<span class="o">);</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">StructField</span><span class="o">&gt;</span> <span class="n">fields</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ArrayList</span><span class="o">&lt;&gt;(</span><span class="mi">2</span><span class="o">);</span>
<span class="n">fields</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">createStructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">));</span>
<span class="n">fields</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">createStructField</span><span class="o">(</span><span class="s">&quot;vector&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">));</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">createStructType</span><span class="o">(</span><span class="n">fields</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">Vector</span> <span class="n">transformingVector</span> <span class="o">=</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">);</span>

<span class="n">ElementwiseProduct</span> <span class="n">transformer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ElementwiseProduct</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setScalingVec</span><span class="o">(</span><span class="n">transformingVector</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;vector&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;transformedVector&quot;</span><span class="o">);</span>

<span class="c1">// Batch transform the vectors to create new column:</span>
<span class="n">transformer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.ElementwiseProduct">ElementwiseProduct Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">ElementwiseProduct</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>

<span class="c1"># Create some vector data; also works for sparse vectors</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]),),</span> <span class="p">(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">]),)]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;vector&quot;</span><span class="p">])</span>
<span class="n">transformer</span> <span class="o">=</span> <span class="n">ElementwiseProduct</span><span class="p">(</span><span class="n">scalingVec</span><span class="o">=</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">]),</span>
                                 <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;vector&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;transformedVector&quot;</span><span class="p">)</span>
<span class="c1"># Batch transform the vectors to create new column:</span>
<span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/elementwise_product_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="sqltransformer">SQLTransformer （SQL变换）</h2>

        <p><code>SQLTransformer</code> 实现由 SQL 语句定义的转换 。
            目前我们只支持SQL语法如 <code>"SELECT ... FROM __THIS__ ..."</code>
            其中 <code>"__THIS__"</code> 代表输入数据集的基础表。选择语句指定输出中展示的字段、元素和表达式，支持Spark SQL 中的所有选择语句。用户还可以使用 Spark SQL 内置函数和UDFs（自定义函数）来对这些选定的列进行操作。
            SQLTransformer 支持如下语句：
        </p>

        <ul>
            <li><code>SELECT a, a + b AS a_b FROM __THIS__</code></li>
            <li><code>SELECT a, SQRT(b) AS b_sqrt FROM __THIS__ where a &gt; 5</code></li>
            <li><code>SELECT a, b, SUM(c) AS c_sum FROM __THIS__ GROUP BY a, b</code></li>
        </ul>

        <p><strong>示例</strong></p>

        <p>假设我们有如下DataFrame包含 <code>id</code>, <code>v1</code> 和 <code>v2</code>:</p>

        <pre><code> id |  v1 |  v2
----|-----|-----
 0  | 1.0 | 3.0  
 2  | 2.0 | 5.0
</code></pre>

        <p>下面是使用 <code>"SELECT *, (v1 + v2) AS v3, (v1 * v2) AS v4 FROM __THIS__"</code>的 <code>SQLTransformer</code> 的输出：</p>

        <pre><code> id |  v1 |  v2 |  v3 |  v4
----|-----|-----|-----|-----
 0  | 1.0 | 3.0 | 4.0 | 3.0
 2  | 2.0 | 5.0 | 7.0 |10.0
</code></pre>

        <div class="codetabs">
            <div data-lang="scala">

                <p>请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.SQLTransformer">SQLTransformer Scala 文档</a>
                    了解相关的 API 的详细信息。</p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.SQLTransformer</span>

<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span>
  <span class="nc">Seq</span><span class="o">((</span><span class="mi">0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">))).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;v1&quot;</span><span class="o">,</span> <span class="s">&quot;v2&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">sqlTrans</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SQLTransformer</span><span class="o">().</span><span class="n">setStatement</span><span class="o">(</span>
  <span class="s">&quot;SELECT *, (v1 + v2) AS v3, (v1 * v2) AS v4 FROM __THIS__&quot;</span><span class="o">)</span>

<span class="n">sqlTrans</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
                <div><small>在Spark repo中路径 "examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala"
                    里可以找到完整的示例代码。 </small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/SQLTransformer.html">SQLTransformer Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.SQLTransformer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.*</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span> <span class="o">[]</span> <span class="o">{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;v1&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;v2&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">SQLTransformer</span> <span class="n">sqlTrans</span> <span class="o">=</span> <span class="k">new</span> <span class="n">SQLTransformer</span><span class="o">().</span><span class="na">setStatement</span><span class="o">(</span>
  <span class="s">&quot;SELECT *, (v1 + v2) AS v3, (v1 * v2) AS v4 FROM __THIS__&quot;</span><span class="o">);</span>

<span class="n">sqlTrans</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.SQLTransformer">SQLTransformer Python docs</a> for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">SQLTransformer</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;v1&quot;</span><span class="p">,</span> <span class="s2">&quot;v2&quot;</span><span class="p">])</span>
<span class="n">sqlTrans</span> <span class="o">=</span> <span class="n">SQLTransformer</span><span class="p">(</span>
    <span class="n">statement</span><span class="o">=</span><span class="s2">&quot;SELECT *, (v1 + v2) AS v3, (v1 * v2) AS v4 FROM __THIS__&quot;</span><span class="p">)</span>
<span class="n">sqlTrans</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/sql_transformer.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="vectorassembler">VectorAssembler （特征向量合并）</h2>

        <p><code>VectorAssembler</code> 将多个列或者和已经存储在的向量列按照顺序合并为一个向量列。
            <code>VectorAssembler</code> 可接受以下的输入列类型：所有数值型、布尔类型、向量类型。输入列的值将按指定顺序依次添加到一个向量中。</p>

        <p><strong>示例</strong></p>

        <p>假设我们有一个 DataFrame 包含<code>id</code>, <code>hour</code>, <code>mobile</code>, <code>userFeatures</code>,
            和 <code>clicked</code>列:</p>

        <pre><code> id | hour | mobile | userFeatures     | clicked
----|------|--------|------------------|---------
 0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0
</code></pre>

        <p><code>userFeatures</code> 是一个包含3个用户特征的向量列。
            我们希望将 <code>hour</code>, <code>mobile</code>, 和 <code>userFeatures</code>组合为一个单一特征向量叫做
            <code>features</code> ，并将其用于预测是否<code>clicked</code>。如果我们设置
            <code>VectorAssembler</code>&#8217;的输入列为<code>hour</code>, <code>mobile</code>, 和 <code>userFeatures</code> 输出列
            <code>features</code>, 转换后我们应该得到以下结果：</p>

        <pre><code> id | hour | mobile | userFeatures     | clicked | features
----|------|--------|------------------|---------|-----------------------------
 0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0     | [18.0, 1.0, 0.0, 10.0, 0.5]
</code></pre>

        <div class="codetabs">
            <div data-lang="scala">

                <p>请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.VectorAssembler">VectorAssembler Scala 文档</a>
                    了解相关的 API 的详细信息</p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.VectorAssembler</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="k">val</span> <span class="n">dataset</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span>
  <span class="nc">Seq</span><span class="o">((</span><span class="mi">0</span><span class="o">,</span> <span class="mi">18</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">0.5</span><span class="o">),</span> <span class="mf">1.0</span><span class="o">))</span>
<span class="o">).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="s">&quot;mobile&quot;</span><span class="o">,</span> <span class="s">&quot;userFeatures&quot;</span><span class="o">,</span> <span class="s">&quot;clicked&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">VectorAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="s">&quot;mobile&quot;</span><span class="o">,</span> <span class="s">&quot;userFeatures&quot;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">assembler</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Assembled columns &#39;hour&#39;, &#39;mobile&#39;, &#39;userFeatures&#39; to vector column &#39;features&#39;&quot;</span><span class="o">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;clicked&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
                <div><small>在Spark repo中路径"examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala"
                    里可以找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/VectorAssembler.html">VectorAssembler Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.VectorAssembler</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.*</span><span class="o">;</span>
<span class="kn">import static</span> <span class="nn">org.apache.spark.sql.types.DataTypes.*</span><span class="o">;</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="n">createStructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="n">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;mobile&quot;</span><span class="o">,</span> <span class="n">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;userFeatures&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;clicked&quot;</span><span class="o">,</span> <span class="n">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">});</span>
<span class="n">Row</span> <span class="n">row</span> <span class="o">=</span> <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">18</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">0.5</span><span class="o">),</span> <span class="mf">1.0</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="n">row</span><span class="o">),</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">VectorAssembler</span> <span class="n">assembler</span> <span class="o">=</span> <span class="k">new</span> <span class="n">VectorAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="s">&quot;mobile&quot;</span><span class="o">,</span> <span class="s">&quot;userFeatures&quot;</span><span class="o">})</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">assembler</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">);</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Assembled columns &#39;hour&#39;, &#39;mobile&#39;, &#39;userFeatures&#39; to vector column &quot;</span> <span class="o">+</span>
    <span class="s">&quot;&#39;features&#39;&quot;</span><span class="o">);</span>
<span class="n">output</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;clicked&quot;</span><span class="o">).</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.VectorAssembler">VectorAssembler Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">VectorAssembler</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]),</span> <span class="mf">1.0</span><span class="p">)],</span>
    <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="s2">&quot;mobile&quot;</span><span class="p">,</span> <span class="s2">&quot;userFeatures&quot;</span><span class="p">,</span> <span class="s2">&quot;clicked&quot;</span><span class="p">])</span>

<span class="n">assembler</span> <span class="o">=</span> <span class="n">VectorAssembler</span><span class="p">(</span>
    <span class="n">inputCols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="s2">&quot;mobile&quot;</span><span class="p">,</span> <span class="s2">&quot;userFeatures&quot;</span><span class="p">],</span>
    <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">assembler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Assembled columns &#39;hour&#39;, &#39;mobile&#39;, &#39;userFeatures&#39; to vector column &#39;features&#39;&quot;</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="s2">&quot;clicked&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/vector_assembler_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="vectorsizehint">VectorSizeHint</h2>

        <p>有时可以明确指定
            <code>VectorType</code>列的向量大小。例如， <code>VectorAssembler</code>
            使用其输入列中的大小信息来为其输出列生成大小信息和元数据。
            虽然在某些情况下可以通过检查列的内容来获得此信息， 但是在 streaming dataframe 在 streaming 启动之前内容不可用。
            <code>VectorSizeHint</code> 允许用户显式指定列的向量大小，以便<code>VectorAssembler</code>,
            或可能需要知道向量大小的其他 transformers (变换) 可以将该列用作输入。
        </p>

        <p>要使用<code>VectorSizeHint</code> ，用户必须设置 <code>inputCol</code> 和 <code>size</code> 参数。
            将此 transformer (转换)应用于 dataframe 会生成一个新的 dataframe(其中包含<code>inputCol</code>的更新元数据，用于指定矢量大小。)
            结果 dataframe 的下游操作可以使用meatadata获得此大小。</p>

        <p><code>VectorSizeHint</code>还可以使用一个可选的<code>handleInvalid</code> 参数，该参数在向量列包含空值或大小错误的向量时控制其行为。
            默认情况下，<code>handleInvalid</code>设置为“error”，表示应该抛出异常。 此参数也可以设置为“skip”，
            表示应该从结果数据帧中过滤掉包含无效值的行，或者“乐观”，表示不应检查列的无效值，并且应保留所有行。
            请注意，使用“optimistic”会导致生成的数据帧处于不一致状态，
            me：应用<code>VectorSizeHint</code>列的元数据与该列的内容不匹配。 用户应注意避免这种不一致的状态。
        </p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.VectorSizeHint">VectorSizeHint Scala 文档</a>
                    了解相关的 API 的详细信息</p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.</span><span class="o">{</span><span class="nc">VectorAssembler</span><span class="o">,</span> <span class="nc">VectorSizeHint</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="k">val</span> <span class="n">dataset</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span>
  <span class="nc">Seq</span><span class="o">(</span>
    <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">18</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">0.5</span><span class="o">),</span> <span class="mf">1.0</span><span class="o">),</span>
    <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">18</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">),</span> <span class="mf">0.0</span><span class="o">))</span>
<span class="o">).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="s">&quot;mobile&quot;</span><span class="o">,</span> <span class="s">&quot;userFeatures&quot;</span><span class="o">,</span> <span class="s">&quot;clicked&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">sizeHint</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">VectorSizeHint</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;userFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setHandleInvalid</span><span class="o">(</span><span class="s">&quot;skip&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setSize</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>

<span class="k">val</span> <span class="n">datasetWithSize</span> <span class="k">=</span> <span class="n">sizeHint</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Rows where &#39;userFeatures&#39; is not the right size are filtered out&quot;</span><span class="o">)</span>
<span class="n">datasetWithSize</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="n">assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">VectorAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="s">&quot;mobile&quot;</span><span class="o">,</span> <span class="s">&quot;userFeatures&quot;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="c1">// This dataframe can be used by downstream transformers as before</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">assembler</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">datasetWithSize</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Assembled columns &#39;hour&#39;, &#39;mobile&#39;, &#39;userFeatures&#39; to vector column &#39;features&#39;&quot;</span><span class="o">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;clicked&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
                <div><small>在Spark repo中路径 "examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala" 里可以找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/VectorSizeHint.html">VectorSizeHint Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.VectorAssembler</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.VectorSizeHint</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>
<span class="kn">import static</span> <span class="nn">org.apache.spark.sql.types.DataTypes.*</span><span class="o">;</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="n">createStructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="n">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;mobile&quot;</span><span class="o">,</span> <span class="n">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;userFeatures&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;clicked&quot;</span><span class="o">,</span> <span class="n">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">});</span>
<span class="n">Row</span> <span class="n">row0</span> <span class="o">=</span> <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">18</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">0.5</span><span class="o">),</span> <span class="mf">1.0</span><span class="o">);</span>
<span class="n">Row</span> <span class="n">row1</span> <span class="o">=</span> <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">18</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">),</span> <span class="mf">0.0</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="n">row0</span><span class="o">,</span> <span class="n">row1</span><span class="o">),</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">VectorSizeHint</span> <span class="n">sizeHint</span> <span class="o">=</span> <span class="k">new</span> <span class="n">VectorSizeHint</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;userFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setHandleInvalid</span><span class="o">(</span><span class="s">&quot;skip&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setSize</span><span class="o">(</span><span class="mi">3</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">datasetWithSize</span> <span class="o">=</span> <span class="n">sizeHint</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">);</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Rows where &#39;userFeatures&#39; is not the right size are filtered out&quot;</span><span class="o">);</span>
<span class="n">datasetWithSize</span><span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>

<span class="n">VectorAssembler</span> <span class="n">assembler</span> <span class="o">=</span> <span class="k">new</span> <span class="n">VectorAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="s">&quot;mobile&quot;</span><span class="o">,</span> <span class="s">&quot;userFeatures&quot;</span><span class="o">})</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">);</span>

<span class="c1">// This dataframe can be used by downstream transformers as before</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">assembler</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">datasetWithSize</span><span class="o">);</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Assembled columns &#39;hour&#39;, &#39;mobile&#39;, &#39;userFeatures&#39; to vector column &quot;</span> <span class="o">+</span>
    <span class="s">&quot;&#39;features&#39;&quot;</span><span class="o">);</span>
<span class="n">output</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;clicked&quot;</span><span class="o">).</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.VectorSizeHint">VectorSizeHint Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="p">(</span><span class="n">VectorSizeHint</span><span class="p">,</span> <span class="n">VectorAssembler</span><span class="p">)</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]),</span> <span class="mf">1.0</span><span class="p">),</span>
     <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">]),</span> <span class="mf">0.0</span><span class="p">)],</span>
    <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="s2">&quot;mobile&quot;</span><span class="p">,</span> <span class="s2">&quot;userFeatures&quot;</span><span class="p">,</span> <span class="s2">&quot;clicked&quot;</span><span class="p">])</span>

<span class="n">sizeHint</span> <span class="o">=</span> <span class="n">VectorSizeHint</span><span class="p">(</span>
    <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;userFeatures&quot;</span><span class="p">,</span>
    <span class="n">handleInvalid</span><span class="o">=</span><span class="s2">&quot;skip&quot;</span><span class="p">,</span>
    <span class="n">size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="n">datasetWithSize</span> <span class="o">=</span> <span class="n">sizeHint</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Rows where &#39;userFeatures&#39; is not the right size are filtered out&quot;</span><span class="p">)</span>
<span class="n">datasetWithSize</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">assembler</span> <span class="o">=</span> <span class="n">VectorAssembler</span><span class="p">(</span>
    <span class="n">inputCols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="s2">&quot;mobile&quot;</span><span class="p">,</span> <span class="s2">&quot;userFeatures&quot;</span><span class="p">],</span>
    <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">)</span>

<span class="c1"># This dataframe can be used by downstream transformers as before</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">assembler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">datasetWithSize</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Assembled columns &#39;hour&#39;, &#39;mobile&#39;, &#39;userFeatures&#39; to vector column &#39;features&#39;&quot;</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="s2">&quot;clicked&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/vector_size_hint_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="quantilediscretizer">QuantileDiscretizer （分位数离散化）</h2>

        <p><code>QuantileDiscretizer</code> 采用具有连续特征的列，并输出具有分箱分类特征的列。
            bin的数量由numBuckets参数设置。所使用的桶的数量可能小于该值，例如，如果输入的不同值太少而不能创建足够的不同分位数。</p>

        <p>NaN 值:
            在<code>QuantileDiscretizer</code>拟合期间，NaN值将从列中移除。这将产生用于进行预测的 <code>Bucketizer</code>模型。
            在转换过程中<code>Bucketizer</code>
            会在数据集中找到NaN值时引发错误，但用户也可以选择通过设置<code>handleInvalid</code>来保留或删除数据集中的NaN值。
            如果用户选择保留NaN值，它们将被专门处理并放入自己的桶中，例如，如果使用4个桶，那么非NaN数据将被放入桶[0-3]，
            但是NaN将是算在一个特殊的桶[4]。</p>

        <p>算法: 使用近似算法选择bin范围使用近似算法选择bin范围 (有关详细说明，请参阅
            <a href="api/scala/index.html#org.apache.spark.sql.DataFrameStatFunctions">approxQuantile</a>文档)
            可以使用
            <code>relativeError</code>参数控制近似的精度。设置为零时，计算精确分位数
            (<strong>注意:</strong> 计算精确分位数是一项昂贵的操作）)。 下边界和上边界将是<code>-Infinity</code> 和 <code>+Infinity</code>
            覆盖所有实际值。</p>

        <p><strong>示例</strong></p>

        <p>假设我们有一个 DataFrame 包含<code>id</code>, <code>hour</code>列:</p>

        <pre><code> id | hour
----|------
 0  | 18.0
----|------
 1  | 19.0
----|------
 2  | 8.0
----|------
 3  | 5.0
----|------
 4  | 2.2
</code></pre>

        <p><code>hour</code> 是一个<code>Double</code>类型的连续特征列。我们希望将连续特征变为分类特征。
            给定 <code>numBuckets = 3</code>，我们应该得到以下DataFrame：</p>

        <pre><code> id | hour | result
----|------|------
 0  | 18.0 | 2.0
----|------|------
 1  | 19.0 | 2.0
----|------|------
 2  | 8.0  | 1.0
----|------|------
 3  | 5.0  | 1.0
----|------|------
 4  | 2.2  | 0.0
</code></pre>

        <div class="codetabs">
            <div data-lang="scala">

                <p>请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.QuantileDiscretizer">QuantileDiscretizer Scala 文档</a>
                    了解相关的 API 的详细信息。</p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.QuantileDiscretizer</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">((</span><span class="mi">0</span><span class="o">,</span> <span class="mf">18.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mf">19.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mf">8.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="mf">2.2</span><span class="o">))</span>
<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;hour&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">discretizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">QuantileDiscretizer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;hour&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;result&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setNumBuckets</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>

<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">discretizer</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
+---+----+------+
|id |hour|result|
+---+----+------+
|0  |18.0|2.0   |
|1  |19.0|2.0   |
|2  |8.0 |1.0   |
|3  |5.0 |1.0   |
|4  |2.2 |0.0   |
+---+----+------+
</pre></div>
                <div><small>在Spark repo中路径"examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala" 里可以找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/QuantileDiscretizer.html">QuantileDiscretizer Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.QuantileDiscretizer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mf">18.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mf">19.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mf">8.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="mf">2.2</span><span class="o">)</span>
<span class="o">);</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">QuantileDiscretizer</span> <span class="n">discretizer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">QuantileDiscretizer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;hour&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;result&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setNumBuckets</span><span class="o">(</span><span class="mi">3</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">discretizer</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>
<span class="n">result</span><span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.QuantileDiscretizer">QuantileDiscretizer Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">QuantileDiscretizer</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">18.0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">19.0</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">)]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;hour&quot;</span><span class="p">])</span>

<span class="n">discretizer</span> <span class="o">=</span> <span class="n">QuantileDiscretizer</span><span class="p">(</span><span class="n">numBuckets</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;result&quot;</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">discretizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/quantile_discretizer_example.py" in the Spark repo.</small></div>
            </div>

        </div>

        <h2 id="imputer">Imputer (填补缺失值)</h2>

        <p><code>Imputer</code> 估算器使用缺失值所在的列的 平均值或中值 来填充数据集中的缺失值。输入列应为
            <code>DoubleType</code> 或者 <code>FloatType</code>。目前 <code>Imputer</code>
            不支持分类功能，并且可能为包含分类功能的列创建不正确的值。 Imputer 可以通过<code>.setMissingValue(custom_value)</code>
            将“NaN”以外的自定义值包括在内。 例如，<code>.setMissingValue(0)</code> 将计算所有出现的（0）。</p>

        <p><strong>注意</strong> 输入列中的所有 <code>null</code>
            都被视为缺失，因此也会被估算。</p>

        <p><strong>示例</strong></p>

        <p>假设我们有一个包含 <code>a</code> 和 <code>b</code>DataFrame:</p>

        <pre><code>      a     |      b
------------|-----------
     1.0    | Double.NaN
     2.0    | Double.NaN
 Double.NaN |     3.0   
     4.0    |     4.0   
     5.0    |     5.0   
</code></pre>

        <p>在此示例中, 将使用从相应列中的其他值计算的均值（默认插补策略）替换所有出现的<code>Double.NaN</code>
            （缺失值的缺省值）。 在此示例中，列a和b的代理值分别为3.0和4.0。 转换后，输出列中的缺失值将替换为相关列的代理值。</p>

        <pre><code>      a     |      b     | out_a | out_b
------------|------------|-------|-------
     1.0    | Double.NaN |  1.0  |  4.0 
     2.0    | Double.NaN |  2.0  |  4.0 
 Double.NaN |     3.0    |  3.0  |  3.0 
     4.0    |     4.0    |  4.0  |  4.0
     5.0    |     5.0    |  5.0  |  5.0 
</code></pre>

        <div class="codetabs">
            <div data-lang="scala">

                <p>请参阅 <a href="api/scala/index.html#org.apache.spark.ml.feature.Imputer">Imputer Scala 文档</a>
                    了解相关的 API 的详细信息。</p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.Imputer</span>

<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="nc">Double</span><span class="o">.</span><span class="nc">NaN</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="nc">Double</span><span class="o">.</span><span class="nc">NaN</span><span class="o">),</span>
  <span class="o">(</span><span class="nc">Double</span><span class="o">.</span><span class="nc">NaN</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">4.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">5.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">)</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">imputer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Imputer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">setOutputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;out_a&quot;</span><span class="o">,</span> <span class="s">&quot;out_b&quot;</span><span class="o">))</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
                <div><small>在Spark repo中路径 "examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala"里可以找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/Imputer.html">Imputer Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.Imputer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.ImputerModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.*</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="n">Double</span><span class="o">.</span><span class="na">NaN</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="n">Double</span><span class="o">.</span><span class="na">NaN</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Double</span><span class="o">.</span><span class="na">NaN</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">4.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">5.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="n">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="n">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">Imputer</span> <span class="n">imputer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Imputer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">})</span>
  <span class="o">.</span><span class="na">setOutputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;out_a&quot;</span><span class="o">,</span> <span class="s">&quot;out_b&quot;</span><span class="o">});</span>

<span class="n">ImputerModel</span> <span class="n">model</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>
<span class="n">model</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.Imputer">Imputer Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">Imputer</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;nan&quot;</span><span class="p">)),</span>
    <span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;nan&quot;</span><span class="p">)),</span>
    <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;nan&quot;</span><span class="p">),</span> <span class="mf">3.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">])</span>

<span class="n">imputer</span> <span class="o">=</span> <span class="n">Imputer</span><span class="p">(</span><span class="n">inputCols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">],</span> <span class="n">outputCols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;out_a&quot;</span><span class="p">,</span> <span class="s2">&quot;out_b&quot;</span><span class="p">])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/imputer_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h1 id="feature-selectors">Feature Selectors （特征选择）</h1>

        <h2 id="vectorslicer">VectorSlicer （向量切片机）</h2>

        <p><code>VectorSlicer</code>是一个(transformer) 转换器。
            它可以将一个特征向量输出为一个新的特征向量（是原始特征的子集）,
            从向量列中提取特征很有用。</p>

        <p><code>VectorSlicer</code> 接受具有指定索引的向量列，然后输出一个新的向量列，
            其值通过这些索引进行选择。有两种类型的指数：</p>

        <ol>
            <li>
                <p>代表向量中的索引的整数索引，setIndices()。<code>setIndices()</code>.</p>
            </li>
            <li>
                <p>表示向量中特征名称的字符串索引, <code>setNames()</code>.
                    <em>这就要求向量列有<code>AttributeGroup</code>; 因为实现在<code>Attribute</code>的name字段上匹配。</em></p>
            </li>
        </ol>

        <p>整数和字符串的规格都可以接受。此外，您可以同时使用整数索引和字符串名称。必须至少选择一个特征。重复的features是不允许的。
            所以选择的索引和名称之间不能有重叠。 请注意，如果选择了features的名称，则会遇到空的输入属性时会抛出异常。</p>

        <p>输出向量将首先（按照给定的顺序）对所选索引的特征进行排序，其次是所选择的名称（按照给定的顺序）。</p>

        <p><strong>示例</strong></p>

        <p>假设我们有一个含有<code>userFeatures</code>列的DataFrame：</p>

        <pre><code> userFeatures
------------------
 [0.0, 10.0, 0.5]
</code></pre>

        <p><code>userFeatures</code> 是一个包含三个用户特征的向量列。 假设<code>userFeatures</code>
            的第一列全部为0，因此我们要删除它并仅选择最后两列。
            <code>VectorSlicer</code> 使用 <code>setIndices(1, 2)</code> 选择最后两个元素;然后生成一个名为<code>features</code>的新向量列：</p>

        <pre><code> userFeatures     | features
------------------|-----------------------------
 [0.0, 10.0, 0.5] | [10.0, 0.5]
</code></pre>

        <p>假设我们对<code>userFeatures</code>具有潜在的输入属性，即
            <code>["f1", "f2", "f3"]</code>, 那么我们可以使用 <code>setNames("f2", "f3")</code> 来选择它们。</p>

        <pre><code> userFeatures     | features
------------------|-----------------------------
 [0.0, 10.0, 0.5] | [10.0, 0.5]
 ["f1", "f2", "f3"] | ["f2", "f3"]
</code></pre>

        <div class="codetabs">
            <div data-lang="scala">

                <p>请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.VectorSlicer">VectorSlicer Scala 文档</a>
                    了解相关的 API 的详细信息。</p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">java.util.Arrays</span>

<span class="k">import</span> <span class="nn">org.apache.spark.ml.attribute.</span><span class="o">{</span><span class="nc">Attribute</span><span class="o">,</span> <span class="nc">AttributeGroup</span><span class="o">,</span> <span class="nc">NumericAttribute</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.VectorSlicer</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.</span><span class="o">{</span><span class="nc">Row</span><span class="o">,</span> <span class="nc">SparkSession</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Arrays</span><span class="o">.</span><span class="n">asList</span><span class="o">(</span>
  <span class="nc">Row</span><span class="o">(</span><span class="nc">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">0</span><span class="o">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mf">2.3</span><span class="o">)))),</span>
  <span class="nc">Row</span><span class="o">(</span><span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(-</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">2.3</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">))</span>
<span class="o">)</span>

<span class="k">val</span> <span class="n">defaultAttr</span> <span class="k">=</span> <span class="nc">NumericAttribute</span><span class="o">.</span><span class="n">defaultAttr</span>
<span class="k">val</span> <span class="n">attrs</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="s">&quot;f1&quot;</span><span class="o">,</span> <span class="s">&quot;f2&quot;</span><span class="o">,</span> <span class="s">&quot;f3&quot;</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">defaultAttr</span><span class="o">.</span><span class="n">withName</span><span class="o">)</span>
<span class="k">val</span> <span class="n">attrGroup</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AttributeGroup</span><span class="o">(</span><span class="s">&quot;userFeatures&quot;</span><span class="o">,</span> <span class="n">attrs</span><span class="o">.</span><span class="n">asInstanceOf</span><span class="o">[</span><span class="kt">Array</span><span class="o">[</span><span class="kt">Attribute</span><span class="o">]])</span>

<span class="k">val</span> <span class="n">dataset</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="nc">StructType</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">attrGroup</span><span class="o">.</span><span class="n">toStructField</span><span class="o">())))</span>

<span class="k">val</span> <span class="n">slicer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">VectorSlicer</span><span class="o">().</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;userFeatures&quot;</span><span class="o">).</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="n">slicer</span><span class="o">.</span><span class="n">setIndices</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">)).</span><span class="n">setNames</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;f3&quot;</span><span class="o">))</span>
<span class="c1">// or slicer.setIndices(Array(1, 2)), or slicer.setNames(Array(&quot;f2&quot;, &quot;f3&quot;))</span>

<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">slicer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
                <div><small>在Spark repo中路径 "examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala"
                    里可以找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/VectorSlicer.html">VectorSlicer Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.attribute.Attribute</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.attribute.AttributeGroup</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.attribute.NumericAttribute</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.VectorSlicer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.*</span><span class="o">;</span>

<span class="n">Attribute</span><span class="o">[]</span> <span class="n">attrs</span> <span class="o">=</span> <span class="o">{</span>
  <span class="n">NumericAttribute</span><span class="o">.</span><span class="na">defaultAttr</span><span class="o">().</span><span class="na">withName</span><span class="o">(</span><span class="s">&quot;f1&quot;</span><span class="o">),</span>
  <span class="n">NumericAttribute</span><span class="o">.</span><span class="na">defaultAttr</span><span class="o">().</span><span class="na">withName</span><span class="o">(</span><span class="s">&quot;f2&quot;</span><span class="o">),</span>
  <span class="n">NumericAttribute</span><span class="o">.</span><span class="na">defaultAttr</span><span class="o">().</span><span class="na">withName</span><span class="o">(</span><span class="s">&quot;f3&quot;</span><span class="o">)</span>
<span class="o">};</span>
<span class="n">AttributeGroup</span> <span class="n">group</span> <span class="o">=</span> <span class="k">new</span> <span class="n">AttributeGroup</span><span class="o">(</span><span class="s">&quot;userFeatures&quot;</span><span class="o">,</span> <span class="n">attrs</span><span class="o">);</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">sparse</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">0</span><span class="o">,</span> <span class="mi">1</span><span class="o">},</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[]{-</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">2.3</span><span class="o">})),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(-</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">2.3</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">))</span>
<span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataset</span> <span class="o">=</span>
  <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="o">(</span><span class="k">new</span> <span class="n">StructType</span><span class="o">()).</span><span class="na">add</span><span class="o">(</span><span class="n">group</span><span class="o">.</span><span class="na">toStructField</span><span class="o">()));</span>

<span class="n">VectorSlicer</span> <span class="n">vectorSlicer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">VectorSlicer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;userFeatures&quot;</span><span class="o">).</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">);</span>

<span class="n">vectorSlicer</span><span class="o">.</span><span class="na">setIndices</span><span class="o">(</span><span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">1</span><span class="o">}).</span><span class="na">setNames</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;f3&quot;</span><span class="o">});</span>
<span class="c1">// or slicer.setIndices(new int[]{1, 2}), or slicer.setNames(new String[]{&quot;f2&quot;, &quot;f3&quot;})</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">vectorSlicer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">);</span>
<span class="n">output</span><span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.VectorSlicer">VectorSlicer Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">VectorSlicer</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">Row</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="n">Row</span><span class="p">(</span><span class="n">userFeatures</span><span class="o">=</span><span class="n">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="mf">2.3</span><span class="p">})),</span>
    <span class="n">Row</span><span class="p">(</span><span class="n">userFeatures</span><span class="o">=</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]))])</span>

<span class="n">slicer</span> <span class="o">=</span> <span class="n">VectorSlicer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;userFeatures&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">slicer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">output</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;userFeatures&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/vector_slicer_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="rformula">RFormula （R模型公式）</h2>

        <p><code>RFormula</code> 选择由<a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/formula.html">R model formula （R模型公式）</a>指定的列。
            目前，我们支持R运算符的有限子集，包括 &#8216;~&#8217;, &#8216;.&#8217;, &#8216;:&#8217;, &#8216;+&#8217;,
            以及 &#8216;-&#8216;.
            基本操作如下：</p>

        <ul>
            <li><code>~</code> 分隔目标和对象</li>
            <li><code>+</code> 合并对象, &#8220;+ 0&#8221; 表示删除截距</li>
            <li><code>-</code> 删除对象, &#8220;- 1&#8221; 表示删除截距</li>
            <li><code>:</code> 交互（数字乘法或二值化分类值）</li>
            <li><code>.</code> 除了目标外的全部列</li>
        </ul>

        <p>假定 <code>a</code> 和 <code>b</code> 都是 double类型的列, 我们使用以下简单的例子来说明<code>RFormula</code>的效果:</p>

        <ul>
            <li><code>y ~ a + b</code> 表示模型 <code>y ~ w0 + w1 * a + w2 * b</code> 其中 <code>w0</code> 是截距 <code>w1, w2</code> 为相关系数。</li>
            <li><code>y ~ a + b + a:b - 1</code> 表示模型 <code>y ~ w1 * a + w2 * b + w3 * a * b</code> 其中 <code>w1, w2, w3</code> 是相关系数。</li>
        </ul>

        <p><code>RFormula</code> 产生一个特征向量列和一个label(double或string类型)列。
            像R在线性回归中使用公式时，数值类被强制转为double类型。
            对于string输入列, 它们使用<code>stringOrderType</code>确定的排序使用 <a href="ml-features.html#stringindexer">StringIndexer</a>进行准换。
            并且排序后的最后一个类别将被删除, 然后双精度数字将进行one-hot encoded (独热编码)</p>

        <p>假定字符串特征列的值为 <code>{'b', 'a', 'b', 'a', 'c', 'b'}</code>,
           我么设置<code>stringOrderType</code>来控制编码:</p>
        <pre><code>stringOrderType | Category mapped to 0 by StringIndexer |  Category dropped by RFormula
----------------|---------------------------------------|---------------------------------
'frequencyDesc' | most frequent category ('b')          | least frequent category ('c')
'frequencyAsc'  | least frequent category ('c')         | most frequent category ('b')
'alphabetDesc'  | last alphabetical category ('c')      | first alphabetical category ('a')
'alphabetAsc'   | first alphabetical category ('a')     | last alphabetical category ('c')
</code></pre>

        <p>如果label列的类型为string，则首先使用<code>frequencyDesc</code>排序将其转换为使用
            <a href="ml-features.html#stringindexer">StringIndexer</a>的字符索引列（double类型）。
            如果DataFrame中不存在label列，则将从公式中的指定响应变量创建输出标签列。</p>

        <p><strong>注意:</strong> 排序选项<code>stringOrderType</code>不用于标签列。 标记列被索引时，
            它使用<code>StringIndexer</code>中的默认降序频率排序。
        </p>

        <p><strong>示例</strong></p>

        <p>假设我们有一个具有列<code>id</code>, <code>country</code>, <code>hour</code>, 和 <code>clicked</code>的DataFrame：</p>

        <pre><code>id | country | hour | clicked
---|---------|------|---------
 7 | "US"    | 18   | 1.0
 8 | "CA"    | 12   | 0.0
 9 | "NZ"    | 15   | 0.0
</code></pre>

        <p>如果我们使用具有<code>clicked ~ country + hour</code><code>RFormula</code>, 的公式字符串的RFormula，这表示我们想要基于
            <code>country</code>  和 <code>hour</code> 去预测 <code>clicked</code>
            转换后我们应该得到以下DataFrame：</p>

        <pre><code>id | country | hour | clicked | features         | label
---|---------|------|---------|------------------|-------
 7 | "US"    | 18   | 1.0     | [0.0, 0.0, 18.0] | 1.0
 8 | "CA"    | 12   | 0.0     | [0.0, 1.0, 12.0] | 0.0
 9 | "NZ"    | 15   | 0.0     | [1.0, 0.0, 15.0] | 0.0
</code></pre>

        <div class="codetabs">
            <div data-lang="scala">

                <p>请参阅 <a href="api/scala/index.html#org.apache.spark.ml.feature.RFormula">RFormula Scala 文档</a>
                    了解相关的 API 的详细信息。</p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.RFormula</span>

<span class="k">val</span> <span class="n">dataset</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">7</span><span class="o">,</span> <span class="s">&quot;US&quot;</span><span class="o">,</span> <span class="mi">18</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">8</span><span class="o">,</span> <span class="s">&quot;CA&quot;</span><span class="o">,</span> <span class="mi">12</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">9</span><span class="o">,</span> <span class="s">&quot;NZ&quot;</span><span class="o">,</span> <span class="mi">15</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;country&quot;</span><span class="o">,</span> <span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="s">&quot;clicked&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">formula</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RFormula</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setFormula</span><span class="o">(</span><span class="s">&quot;clicked ~ country + hour&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setFeaturesCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setLabelCol</span><span class="o">(</span><span class="s">&quot;label&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">formula</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">).</span><span class="n">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;label&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
                <div><small>在Spark repo中路径"examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala" 里可以找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/RFormula.html">RFormula Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.RFormula</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="kn">import static</span> <span class="nn">org.apache.spark.sql.types.DataTypes.*</span><span class="o">;</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="n">createStructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;country&quot;</span><span class="o">,</span> <span class="n">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="n">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;clicked&quot;</span><span class="o">,</span> <span class="n">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">});</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">7</span><span class="o">,</span> <span class="s">&quot;US&quot;</span><span class="o">,</span> <span class="mi">18</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">8</span><span class="o">,</span> <span class="s">&quot;CA&quot;</span><span class="o">,</span> <span class="mi">12</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">9</span><span class="o">,</span> <span class="s">&quot;NZ&quot;</span><span class="o">,</span> <span class="mi">15</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)</span>
<span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>
<span class="n">RFormula</span> <span class="n">formula</span> <span class="o">=</span> <span class="k">new</span> <span class="n">RFormula</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setFormula</span><span class="o">(</span><span class="s">&quot;clicked ~ country + hour&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setFeaturesCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setLabelCol</span><span class="o">(</span><span class="s">&quot;label&quot;</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">formula</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">).</span><span class="na">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">);</span>
<span class="n">output</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;label&quot;</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.RFormula">RFormula Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">RFormula</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[(</span><span class="mi">7</span><span class="p">,</span> <span class="s2">&quot;US&quot;</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
     <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="s2">&quot;CA&quot;</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
     <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="s2">&quot;NZ&quot;</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)],</span>
    <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;country&quot;</span><span class="p">,</span> <span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="s2">&quot;clicked&quot;</span><span class="p">])</span>

<span class="n">formula</span> <span class="o">=</span> <span class="n">RFormula</span><span class="p">(</span>
    <span class="n">formula</span><span class="o">=</span><span class="s2">&quot;clicked ~ country + hour&quot;</span><span class="p">,</span>
    <span class="n">featuresCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span>
    <span class="n">labelCol</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">formula</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/rformula_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h2 id="chisqselector">ChiSqSelector （卡方特征选择器）</h2>

        <p><code>ChiSqSelector</code> 代表卡方特征选择 ;它适用于带有类别特征的标签数据。ChiSqSelector 使用卡
            <a href="https://en.wikipedia.org/wiki/Chi-squared_test">Chi-Squared test of independence</a> to decide which
            来决定选择哪些特征。它支持三种选择方法： <code>numTopFeatures</code>, <code>percentile</code>, <code>fpr</code>, <code>fdr</code>, <code>fwe</code>:</p>
        <ul>
            <li><code>numTopFeatures</code> 根据chi-squared test 选择top features 的固定数。
                这类似于产生具有最强预测能力的特征。</li>
            <li><code>percentile</code> 类似于<code>numTopFeatures</code>
                但选择所有功能的一部分，而不是固定数量。</li>
            <li><code>fpr</code>fpr选择p值低于阈值的所有特征，从而控制选择的假阳性率。</li>
            <li><code>fdr</code> 使用
                <a href="https://en.wikipedia.org/wiki/False_discovery_rate#Benjamini.E2.80.93Hochberg_procedure">Benjamini-Hochberg procedure</a>
                来选择虚假发现率低于阈值的所有特征。</li>
            <li><code>fwe</code> 选择p值低于阈值的所有特征。 阈值按1 / numFeatures缩放，从而控制选择的family-wise的错误率。
                默认情况下，选择方法为<code>numTopFeatures</code>, 默认情况下的top features 设置为50。用户可以使用
                 <code>setSelectorType</code>选择选择方法。</li>
        </ul>

        <p><strong>示例</strong></p>

        <p>假设我们有一个具有列<code>id</code>, <code>features</code>, 和 <code>clicked</code>, 的DataFrame，这被用作我们预测的目标：</p>

        <pre><code>id | features              | clicked
---|-----------------------|---------
 7 | [0.0, 0.0, 18.0, 1.0] | 1.0
 8 | [0.0, 1.0, 12.0, 0.0] | 0.0
 9 | [1.0, 0.0, 15.0, 0.1] | 0.0
</code></pre>

        <p>如果我们使用<code>ChiSqSelector</code> 并设置 <code>numTopFeatures = 1</code>, 根据我们所有的特征，其中最后一列标签
            <code>clicked</code>  是认为最有用的<code>features</code>：</p>

        <pre><code>id | features              | clicked | selectedFeatures
---|-----------------------|---------|------------------
 7 | [0.0, 0.0, 18.0, 1.0] | 1.0     | [1.0]
 8 | [0.0, 1.0, 12.0, 0.0] | 0.0     | [0.0]
 9 | [1.0, 0.0, 15.0, 0.1] | 0.0     | [0.1]
</code></pre>

        <div class="codetabs">
            <div data-lang="scala">

                <p>请参阅 <a href="api/scala/index.html#org.apache.spark.ml.feature.ChiSqSelector">ChiSqSelector Scala 文档。</a>
                    了解相关的 API 的详细信息</p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.ChiSqSelector</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">7</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">18.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">8</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">12.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">9</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">15.0</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">),</span> <span class="mf">0.0</span><span class="o">)</span>
<span class="o">)</span>

<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataset</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;clicked&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">selector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChiSqSelector</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setNumTopFeatures</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setFeaturesCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setLabelCol</span><span class="o">(</span><span class="s">&quot;clicked&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;selectedFeatures&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>

<span class="n">println</span><span class="o">(</span><span class="s">s&quot;ChiSqSelector output with top </span><span class="si">${</span><span class="n">selector</span><span class="o">.</span><span class="n">getNumTopFeatures</span><span class="si">}</span><span class="s"> features selected&quot;</span><span class="o">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
                <div><small>在Spark repo中路径"examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala"
                    里可以找到完整的示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/ChiSqSelector.html">ChiSqSelector Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.ChiSqSelector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">7</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">18.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">8</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">12.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">9</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">15.0</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">),</span> <span class="mf">0.0</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;clicked&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">ChiSqSelector</span> <span class="n">selector</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ChiSqSelector</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setNumTopFeatures</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setFeaturesCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setLabelCol</span><span class="o">(</span><span class="s">&quot;clicked&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;selectedFeatures&quot;</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>

<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;ChiSqSelector output with top &quot;</span> <span class="o">+</span> <span class="n">selector</span><span class="o">.</span><span class="na">getNumTopFeatures</span><span class="o">()</span>
    <span class="o">+</span> <span class="s">&quot; features selected&quot;</span><span class="o">);</span>
<span class="n">result</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.ChiSqSelector">ChiSqSelector Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">ChiSqSelector</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">18.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),</span> <span class="mf">1.0</span><span class="p">,),</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]),</span> <span class="mf">0.0</span><span class="p">,),</span>
    <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]),</span> <span class="mf">0.0</span><span class="p">,)],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="s2">&quot;clicked&quot;</span><span class="p">])</span>

<span class="n">selector</span> <span class="o">=</span> <span class="n">ChiSqSelector</span><span class="p">(</span><span class="n">numTopFeatures</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">featuresCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span>
                         <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;selectedFeatures&quot;</span><span class="p">,</span> <span class="n">labelCol</span><span class="o">=</span><span class="s2">&quot;clicked&quot;</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;ChiSqSelector output with top </span><span class="si">%d</span><span class="s2"> features selected&quot;</span> <span class="o">%</span> <span class="n">selector</span><span class="o">.</span><span class="n">getNumTopFeatures</span><span class="p">())</span>
<span class="n">result</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/chisq_selector_example.py" in the Spark repo.</small></div>
            </div>
        </div>

        <h1 id="locality-sensitive-hashing">Locality Sensitive Hashing （局部敏感哈希）</h1>
        <p><a href="https://en.wikipedia.org/wiki/Locality-sensitive_hashing">Locality Sensitive Hashing (LSH)</a>
            是哈希技术中重要的一种，通常用于集群，近似最近邻搜索和大型数据集的孤立点检测。</p>

        <p>的大致思路是用一系列函数 (&#8220;LSH families&#8221;) 将数据哈希到桶中，
            这样彼此接近的数据点处于相同的桶中可能性就会很高，而彼此相距很远的数据点很可能处于不同的桶中。
            一个 LSH family 正式定义如下。
        </p>

        <p>在度量空间 <code>(M, d)</code>, 其中 <code>M</code> 是一个集合;  <code>d</code> 是 <code>M</code> 上的距离函数,
            LSH family 是一系列能满足以下属性的函数 <code>h</code>:
            <code>\[
                \forall p, q \in M,\\
                d(p,q) \leq r1 \Rightarrow Pr(h(p)=h(q)) \geq p1\\
                d(p,q) \geq r2 \Rightarrow Pr(h(p)=h(q)) \leq p2
                \]</code>
            满足以上条件的LSH family被称为 <code>(r1, r2, p1, p2)</code>-sensitive.</p>

        <p>在Spark中，不同的 LSH families 实现在不同的类中（例如, <code>MinHash</code>),
            并且在每个类中提供了用于特征变换的API，近似相似性连接和近似最近邻。</p>

        <p>In LSH, 我们将一个假阳性定义为一对相距大的输入特征(当 <code>$d(p,q) \geq r2$</code>)
            它们被哈希到同一个桶中，, 并且将一个假阴性定义为一对相邻的特征（当 <code>$d(p,q) \leq r1$</code>)
            它们被哈希到不同的桶中。</p>

        <h2 id="lsh-operations">LSH Operations （LSH运算）</h2>

        <p>我们称使用LSH的主要操作类型为LSH 运算。 一个合适的LSH模型对每一个操作中都有对应的方法。</p>

        <h3 id="feature-transformation">Feature Transformation （特征变换）</h3>
        <p>特征变换是将哈希值添加作为新列的基本功能。
            这可以有助于降低维数。 用户可以通过设置
            <code>inputCol</code>
            和 <code>outputCol</code>参数来指定输入和输出列名。</p>

        <p>LSH 还支持多个LSH哈希表。 用户可以通过设置  <code>numHashTables</code>来指定哈希表的数量。
            这也用于 approximate similarity join (近似相似性连接) 和 approximate nearest neighbor (近似最近邻的)
            <a href="https://en.wikipedia.org/wiki/Locality-sensitive_hashing#Amplification">OR-amplification</a>
            增加哈希表的数量将增加准确性，但也会增加通信成本和运行时间。

        </p>

        <p><code>outputCol</code> 类型是 <code>Seq[Vector]</code> 其中数组的维数等于 <code>numHashTables</code>,
            并且向量的维度当前设置为 1。
            在将来的版本中，我们将实现 AND-amplification 以便用户可以指定这些向量的维度 。</p>

        <h3 id="approximate-similarity-join">Approximate Similarity Join （近似相似度连接）</h3>
        <p>近似相似度连接采用两个数据集，并且近似返回距离小于用户定义阈值的数据集中的行对。 近似相似度连接支持两个不同的数据集连接和自连接。
            自连接）会产生一些重复的对。</p>

        <p>Approximate similarity join 接受 transformed 和 untransformed 的数据集作为输入。
            如果 untransformed 的数据集被使用, 他将被自动的转换, 在这种情况下，哈希签名将被创建为<code>outputCol</code>。</p>

        <p>在 joined后的 dataset中,可以在 datasetA</code> 和 <code>datasetB</code>查询原始数据集。
            距离列将被添加到输出数据集，以显示返回的每对行之间的真实距离。
        </p>

        <h3 id="approximate-nearest-neighbor-search">Approximate Nearest Neighbor Search （近似最邻近搜索）</h3>
        <p>Approximate nearest neighbor search  采用数据集 (特征向量) 和 ke y(密钥) (单个特征向量),
            并且它近似返回数据集中最接近向量的指定数量的行。</p>

        <p>近似最近邻搜索接受已转换和未转换的数据集作为输入。 如果使用未转换的数据集，它将自动转换。 在这种情况下，
            哈希签名将被创建为<code>outputCol</code>。</p>


        <p>距离列将被添加到输出数据集，以显示每个输出行和搜索的键之间的真实距离。</p>

        <p><strong>主要:</strong> 当哈希桶中没有足够的候选项时，近似最近邻搜索将返回少于 <code>k</code>  行。
            </p>

        <h2 id="lsh-algorithms">LSH Algorithms （LSH算法）</h2>

        <h3 id="bucketed-random-projection-for-euclidean-distance">Bucketed Random Projection for Euclidean Distance （ 欧几里得度量的随机投影）</h3>

        <p><a href="https://en.wikipedia.org/wiki/Locality-sensitive_hashing#Stable_distributions">Bucketed Random Projection</a>
            是用于 Euclidean distance （欧几里德距离）的 LSH family 。 欧氏度量的定义如下：
            <code>\[
                d(\mathbf{x}, \mathbf{y}) = \sqrt{\sum_i (x_i - y_i)^2}
                \]</code>
            LSH family 将向量 <code>$\mathbf{x}$</code> 特征向量映射到随机单位矢量 <code>$\mathbf{v}$</code>
            并将映射结果分为哈希桶中：
            <code>\[
                h(\mathbf{x}) = \Big\lfloor \frac{\mathbf{x} \cdot \mathbf{v}}{r} \Big\rfloor
                \]</code>
            其中 <code>r</code>
            是用户定义的桶长度，桶长度可用于控制哈希桶的平均大小（因此也可用于控制桶的数量）。 较大的桶长度（即，更少的桶）增加了将特征哈希到相同桶的概率（增加真实和假阳性的数量）。</p>

        <p>桶随机投影接受任意向量作为输入特征，并支持稀疏和密集向量。</p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>如需了解API中的更多详细信息，请参阅
                    <a href="api/scala/index.html#org.apache.spark.ml.feature.BucketedRandomProjectionLSH">BucketedRandomProjectionLSH Scala 文档</a>
                    </p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.BucketedRandomProjectionLSH</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.functions.col</span>

<span class="k">val</span> <span class="n">dfA</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">dfB</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">7</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">key</span> <span class="k">=</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)</span>

<span class="k">val</span> <span class="n">brp</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">BucketedRandomProjectionLSH</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setBucketLength</span><span class="o">(</span><span class="mf">2.0</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setNumHashTables</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;hashes&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">brp</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">dfA</span><span class="o">)</span>

<span class="c1">// Feature Transformation</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;The hashed dataset where hashed values are stored in the column &#39;hashes&#39;:&quot;</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dfA</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>

<span class="c1">// Compute the locality sensitive hashes for the input rows, then perform approximate</span>
<span class="c1">// similarity join.</span>
<span class="c1">// We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1">// `model.approxSimilarityJoin(transformedA, transformedB, 1.5)`</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Approximately joining dfA and dfB on Euclidean distance smaller than 1.5:&quot;</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">approxSimilarityJoin</span><span class="o">(</span><span class="n">dfA</span><span class="o">,</span> <span class="n">dfB</span><span class="o">,</span> <span class="mf">1.5</span><span class="o">,</span> <span class="s">&quot;EuclideanDistance&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">col</span><span class="o">(</span><span class="s">&quot;datasetA.id&quot;</span><span class="o">).</span><span class="n">alias</span><span class="o">(</span><span class="s">&quot;idA&quot;</span><span class="o">),</span>
    <span class="n">col</span><span class="o">(</span><span class="s">&quot;datasetB.id&quot;</span><span class="o">).</span><span class="n">alias</span><span class="o">(</span><span class="s">&quot;idB&quot;</span><span class="o">),</span>
    <span class="n">col</span><span class="o">(</span><span class="s">&quot;EuclideanDistance&quot;</span><span class="o">)).</span><span class="n">show</span><span class="o">()</span>

<span class="c1">// Compute the locality sensitive hashes for the input rows, then perform approximate nearest</span>
<span class="c1">// neighbor search.</span>
<span class="c1">// We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1">// `model.approxNearestNeighbors(transformedA, key, 2)`</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Approximately searching dfA for 2 nearest neighbors of the key:&quot;</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">approxNearestNeighbors</span><span class="o">(</span><span class="n">dfA</span><span class="o">,</span> <span class="n">key</span><span class="o">,</span> <span class="mi">2</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
                <div><small>在Spark repo 路径 "examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala" 中查找完整示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/BucketedRandomProjectionLSH.html">BucketedRandomProjectionLSH Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.BucketedRandomProjectionLSH</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.BucketedRandomProjectionLSHModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="kn">import static</span> <span class="nn">org.apache.spark.sql.functions.col</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataA</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">))</span>
<span class="o">);</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataB</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)),</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)),</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)),</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">7</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">))</span>
<span class="o">);</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dfA</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">dataA</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dfB</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">dataB</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">Vector</span> <span class="n">key</span> <span class="o">=</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">);</span>

<span class="n">BucketedRandomProjectionLSH</span> <span class="n">mh</span> <span class="o">=</span> <span class="k">new</span> <span class="n">BucketedRandomProjectionLSH</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setBucketLength</span><span class="o">(</span><span class="mf">2.0</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setNumHashTables</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;hashes&quot;</span><span class="o">);</span>

<span class="n">BucketedRandomProjectionLSHModel</span> <span class="n">model</span> <span class="o">=</span> <span class="n">mh</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">dfA</span><span class="o">);</span>

<span class="c1">// Feature Transformation</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;The hashed dataset where hashed values are stored in the column &#39;hashes&#39;:&quot;</span><span class="o">);</span>
<span class="n">model</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dfA</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>

<span class="c1">// Compute the locality sensitive hashes for the input rows, then perform approximate</span>
<span class="c1">// similarity join.</span>
<span class="c1">// We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1">// `model.approxSimilarityJoin(transformedA, transformedB, 1.5)`</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Approximately joining dfA and dfB on distance smaller than 1.5:&quot;</span><span class="o">);</span>
<span class="n">model</span><span class="o">.</span><span class="na">approxSimilarityJoin</span><span class="o">(</span><span class="n">dfA</span><span class="o">,</span> <span class="n">dfB</span><span class="o">,</span> <span class="mf">1.5</span><span class="o">,</span> <span class="s">&quot;EuclideanDistance&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="n">col</span><span class="o">(</span><span class="s">&quot;datasetA.id&quot;</span><span class="o">).</span><span class="na">alias</span><span class="o">(</span><span class="s">&quot;idA&quot;</span><span class="o">),</span>
    <span class="n">col</span><span class="o">(</span><span class="s">&quot;datasetB.id&quot;</span><span class="o">).</span><span class="na">alias</span><span class="o">(</span><span class="s">&quot;idB&quot;</span><span class="o">),</span>
    <span class="n">col</span><span class="o">(</span><span class="s">&quot;EuclideanDistance&quot;</span><span class="o">)).</span><span class="na">show</span><span class="o">();</span>

<span class="c1">// Compute the locality sensitive hashes for the input rows, then perform approximate nearest</span>
<span class="c1">// neighbor search.</span>
<span class="c1">// We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1">// `model.approxNearestNeighbors(transformedA, key, 2)`</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Approximately searching dfA for 2 nearest neighbors of the key:&quot;</span><span class="o">);</span>
<span class="n">model</span><span class="o">.</span><span class="na">approxNearestNeighbors</span><span class="o">(</span><span class="n">dfA</span><span class="o">,</span> <span class="n">key</span><span class="o">,</span> <span class="mi">2</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.BucketedRandomProjectionLSH">BucketedRandomProjectionLSH Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">BucketedRandomProjectionLSH</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span>

<span class="n">dataA</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),)]</span>
<span class="n">dfA</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">dataA</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">dataB</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">4</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">]),)]</span>
<span class="n">dfB</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">dataB</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">key</span> <span class="o">=</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>

<span class="n">brp</span> <span class="o">=</span> <span class="n">BucketedRandomProjectionLSH</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;hashes&quot;</span><span class="p">,</span> <span class="n">bucketLength</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
                                  <span class="n">numHashTables</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">brp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dfA</span><span class="p">)</span>

<span class="c1"># Feature Transformation</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;The hashed dataset where hashed values are stored in the column &#39;hashes&#39;:&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dfA</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Compute the locality sensitive hashes for the input rows, then perform approximate</span>
<span class="c1"># similarity join.</span>
<span class="c1"># We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1"># `model.approxSimilarityJoin(transformedA, transformedB, 1.5)`</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Approximately joining dfA and dfB on Euclidean distance smaller than 1.5:&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">approxSimilarityJoin</span><span class="p">(</span><span class="n">dfA</span><span class="p">,</span> <span class="n">dfB</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="n">distCol</span><span class="o">=</span><span class="s2">&quot;EuclideanDistance&quot;</span><span class="p">)</span>\
    <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;datasetA.id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;idA&quot;</span><span class="p">),</span>
            <span class="n">col</span><span class="p">(</span><span class="s2">&quot;datasetB.id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;idB&quot;</span><span class="p">),</span>
            <span class="n">col</span><span class="p">(</span><span class="s2">&quot;EuclideanDistance&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Compute the locality sensitive hashes for the input rows, then perform approximate nearest</span>
<span class="c1"># neighbor search.</span>
<span class="c1"># We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1"># `model.approxNearestNeighbors(transformedA, key, 2)`</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Approximately searching dfA for 2 nearest neighbors of the key:&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">approxNearestNeighbors</span><span class="p">(</span><span class="n">dfA</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/bucketed_random_projection_lsh_example.py" in the Spark repo.</small></div>
            </div>

        </div>

        <h3 id="minhash-for-jaccard-distance">MinHash for Jaccard Distance</h3>
        <p><a href="https://en.wikipedia.org/wiki/MinHash">MinHash</a>
            是一个用于Jaccard 距离的 LSH family，它的输入特征是自然数的集合。 两组的Jaccard距离由它们的交集和并集的基数定义：
            <code>\[
                d(\mathbf{A}, \mathbf{B}) = 1 - \frac{|\mathbf{A} \cap \mathbf{B}|}{|\mathbf{A} \cup \mathbf{B}|}
                \]</code>
            MinHash 将随机哈希函数g应用于集合中的每个元素，并取得所有哈希值中的最小值。
            <code>\[
                h(\mathbf{A}) = \min_{a \in \mathbf{A}}(g(a))
                \]</code></p>

        <p>MinHash 的输入集合表示为二进制向量，其中向量索引表示元素本身，向量中的非零值表示该元素在集合中存在。尽管支持稠密和稀疏向量，但通常推荐使用稀疏向量来提高效率。 例如，Vectors.sparse（10，Array [（2，1.0），（3，1.0），（5，1.0）]）表示空间中有10个元素。 该集合包含 elem 2，elem 3 和 elem 5。所有非零值都被视为二进制“1”值。</p>

        <p><strong>注意:</strong>
            空集不能被MinHash转换，这意味着任何输入向量必须至少有一个非零条目。</p>

        <div class="codetabs">
            <div data-lang="scala">

                <p>如需了解API中的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.MinHashLSH">MinHashLSH Scala 文档。</a>
                  </p>

                <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.MinHashLSH</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.functions.col</span>

<span class="k">val</span> <span class="n">dfA</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)))),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">2</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)))),</span>
  <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">))))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">dfB</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)))),</span>
  <span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">2</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)))),</span>
  <span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">))))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">key</span> <span class="k">=</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)))</span>

<span class="k">val</span> <span class="n">mh</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MinHashLSH</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setNumHashTables</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;hashes&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">mh</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">dfA</span><span class="o">)</span>

<span class="c1">// Feature Transformation</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;The hashed dataset where hashed values are stored in the column &#39;hashes&#39;:&quot;</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dfA</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>

<span class="c1">// Compute the locality sensitive hashes for the input rows, then perform approximate</span>
<span class="c1">// similarity join.</span>
<span class="c1">// We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1">// `model.approxSimilarityJoin(transformedA, transformedB, 0.6)`</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Approximately joining dfA and dfB on Jaccard distance smaller than 0.6:&quot;</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">approxSimilarityJoin</span><span class="o">(</span><span class="n">dfA</span><span class="o">,</span> <span class="n">dfB</span><span class="o">,</span> <span class="mf">0.6</span><span class="o">,</span> <span class="s">&quot;JaccardDistance&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">col</span><span class="o">(</span><span class="s">&quot;datasetA.id&quot;</span><span class="o">).</span><span class="n">alias</span><span class="o">(</span><span class="s">&quot;idA&quot;</span><span class="o">),</span>
    <span class="n">col</span><span class="o">(</span><span class="s">&quot;datasetB.id&quot;</span><span class="o">).</span><span class="n">alias</span><span class="o">(</span><span class="s">&quot;idB&quot;</span><span class="o">),</span>
    <span class="n">col</span><span class="o">(</span><span class="s">&quot;JaccardDistance&quot;</span><span class="o">)).</span><span class="n">show</span><span class="o">()</span>

<span class="c1">// Compute the locality sensitive hashes for the input rows, then perform approximate nearest</span>
<span class="c1">// neighbor search.</span>
<span class="c1">// We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1">// `model.approxNearestNeighbors(transformedA, key, 2)`</span>
<span class="c1">// It may return less than 2 rows when not enough approximate near-neighbor candidates are</span>
<span class="c1">// found.</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Approximately searching dfA for 2 nearest neighbors of the key:&quot;</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">approxNearestNeighbors</span><span class="o">(</span><span class="n">dfA</span><span class="o">,</span> <span class="n">key</span><span class="o">,</span> <span class="mi">2</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
                <div><small>在Spark repo 路径"examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala" 中查找完整示例代码。</small></div>
            </div>

            <div data-lang="java">

                <p>Refer to the <a href="api/java/org/apache/spark/ml/feature/MinHashLSH.html">MinHashLSH Java docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.MinHashLSH</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.MinHashLSHModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="kn">import static</span> <span class="nn">org.apache.spark.sql.functions.col</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataA</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">0</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">},</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[]{</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">})),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">},</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[]{</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">})),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">0</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">},</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[]{</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">}))</span>
<span class="o">);</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataB</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">1</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">5</span><span class="o">},</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[]{</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">})),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">5</span><span class="o">},</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[]{</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">})),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">},</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[]{</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">}))</span>
<span class="o">);</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dfA</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">dataA</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dfB</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">dataB</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="kt">int</span><span class="o">[]</span> <span class="n">indices</span> <span class="o">=</span> <span class="o">{</span><span class="mi">1</span><span class="o">,</span> <span class="mi">3</span><span class="o">};</span>
<span class="kt">double</span><span class="o">[]</span> <span class="n">values</span> <span class="o">=</span> <span class="o">{</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">};</span>
<span class="n">Vector</span> <span class="n">key</span> <span class="o">=</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="n">indices</span><span class="o">,</span> <span class="n">values</span><span class="o">);</span>

<span class="n">MinHashLSH</span> <span class="n">mh</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MinHashLSH</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setNumHashTables</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;hashes&quot;</span><span class="o">);</span>

<span class="n">MinHashLSHModel</span> <span class="n">model</span> <span class="o">=</span> <span class="n">mh</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">dfA</span><span class="o">);</span>

<span class="c1">// Feature Transformation</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;The hashed dataset where hashed values are stored in the column &#39;hashes&#39;:&quot;</span><span class="o">);</span>
<span class="n">model</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dfA</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>

<span class="c1">// Compute the locality sensitive hashes for the input rows, then perform approximate</span>
<span class="c1">// similarity join.</span>
<span class="c1">// We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1">// `model.approxSimilarityJoin(transformedA, transformedB, 0.6)`</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Approximately joining dfA and dfB on Jaccard distance smaller than 0.6:&quot;</span><span class="o">);</span>
<span class="n">model</span><span class="o">.</span><span class="na">approxSimilarityJoin</span><span class="o">(</span><span class="n">dfA</span><span class="o">,</span> <span class="n">dfB</span><span class="o">,</span> <span class="mf">0.6</span><span class="o">,</span> <span class="s">&quot;JaccardDistance&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="n">col</span><span class="o">(</span><span class="s">&quot;datasetA.id&quot;</span><span class="o">).</span><span class="na">alias</span><span class="o">(</span><span class="s">&quot;idA&quot;</span><span class="o">),</span>
    <span class="n">col</span><span class="o">(</span><span class="s">&quot;datasetB.id&quot;</span><span class="o">).</span><span class="na">alias</span><span class="o">(</span><span class="s">&quot;idB&quot;</span><span class="o">),</span>
    <span class="n">col</span><span class="o">(</span><span class="s">&quot;JaccardDistance&quot;</span><span class="o">)).</span><span class="na">show</span><span class="o">();</span>

<span class="c1">// Compute the locality sensitive hashes for the input rows, then perform approximate nearest</span>
<span class="c1">// neighbor search.</span>
<span class="c1">// We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1">// `model.approxNearestNeighbors(transformedA, key, 2)`</span>
<span class="c1">// It may return less than 2 rows when not enough approximate near-neighbor candidates are</span>
<span class="c1">// found.</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Approximately searching dfA for 2 nearest neighbors of the key:&quot;</span><span class="o">);</span>
<span class="n">model</span><span class="o">.</span><span class="na">approxNearestNeighbors</span><span class="o">(</span><span class="n">dfA</span><span class="o">,</span> <span class="n">key</span><span class="o">,</span> <span class="mi">2</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java" in the Spark repo.</small></div>
            </div>

            <div data-lang="python">

                <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.feature.MinHashLSH">MinHashLSH Python docs</a>
                    for more details on the API.</p>

                <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">MinHashLSH</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span>

<span class="n">dataA</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),)]</span>
<span class="n">dfA</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">dataA</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">dataB</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">3</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),)]</span>
<span class="n">dfB</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">dataB</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">key</span> <span class="o">=</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>

<span class="n">mh</span> <span class="o">=</span> <span class="n">MinHashLSH</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;hashes&quot;</span><span class="p">,</span> <span class="n">numHashTables</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">mh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dfA</span><span class="p">)</span>

<span class="c1"># Feature Transformation</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;The hashed dataset where hashed values are stored in the column &#39;hashes&#39;:&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dfA</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Compute the locality sensitive hashes for the input rows, then perform approximate</span>
<span class="c1"># similarity join.</span>
<span class="c1"># We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1"># `model.approxSimilarityJoin(transformedA, transformedB, 0.6)`</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Approximately joining dfA and dfB on distance smaller than 0.6:&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">approxSimilarityJoin</span><span class="p">(</span><span class="n">dfA</span><span class="p">,</span> <span class="n">dfB</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="n">distCol</span><span class="o">=</span><span class="s2">&quot;JaccardDistance&quot;</span><span class="p">)</span>\
    <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;datasetA.id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;idA&quot;</span><span class="p">),</span>
            <span class="n">col</span><span class="p">(</span><span class="s2">&quot;datasetB.id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;idB&quot;</span><span class="p">),</span>
            <span class="n">col</span><span class="p">(</span><span class="s2">&quot;JaccardDistance&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Compute the locality sensitive hashes for the input rows, then perform approximate nearest</span>
<span class="c1"># neighbor search.</span>
<span class="c1"># We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1"># `model.approxNearestNeighbors(transformedA, key, 2)`</span>
<span class="c1"># It may return less than 2 rows when not enough approximate near-neighbor candidates are</span>
<span class="c1"># found.</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Approximately searching dfA for 2 nearest neighbors of the key:&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">approxNearestNeighbors</span><span class="p">(</span><span class="n">dfA</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
                <div><small>Find full example code at "examples/src/main/python/ml/min_hash_lsh_example.py" in the Spark repo.</small></div>
            </div>
        </div>


    </div>

    <!-- /container -->
</div>

<script src="js/vendor/jquery-1.8.0.min.js"></script>
<script src="js/vendor/bootstrap.min.js"></script>
<script src="js/vendor/anchor.min.js"></script>
<script src="js/main.js"></script>

<!-- MathJax Section -->
<script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
<script>
    // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
    // We could use "//cdn.mathjax...", but that won't support "file://".
    (function(d, script) {
        script = d.createElement('script');
        script.type = 'text/javascript';
        script.async = true;
        script.onload = function(){
            MathJax.Hub.Config({
                tex2jax: {
                    inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                    displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                    processEscapes: true,
                    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                }
            });
        };
        script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
            'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
            '?config=TeX-AMS-MML_HTMLorMML';
        d.getElementsByTagName('head')[0].appendChild(script);
    }(document));
</script>
</body>
</html>
